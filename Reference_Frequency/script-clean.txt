The Language of Probability
Michael Hediger
University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
May 28, 2024
References: The given script is inspired by the books of Patrick Billingsley [1] and JeanFrançois Le Gall [2].

Contents
1 Introduction: Part I
1.1 Sets . . . . . . . . . . . .
1.2 The principle of induction
1.3 Order structure of the real
1.4 Solution to exercises . . .
1.5 Additional exercises . . .

. . . . . .
. . . . . .
numbers
. . . . . .
. . . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

4
. 4
. 7
. 8
. 12
. 13

2 Introduction: Part II
2.1 Functions . . . . . .
2.2 Cardinality of Sets .
2.3 Euclidean distance .
2.4 Solution to exercises
2.5 Additional exercises

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

15
15
18
19
21
22

. . . . . . . . . . .
and limit superior
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

23
23
26
30
31
31
33

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

3 Introduction: Part III
3.1 Real valued sequences . . .
3.2 Subsequences: Limit inferior
3.3 Vector-valued sequences . .
3.4 Sequences of Functions . . .
3.5 Solution to exercises . . . .
3.6 Additional exercises . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

4 Measurable sets: Part I
34
4.1 Measurable spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.2 Solution to exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
4.3 Additional exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
5 Measurable sets: Part II
5.1 Measure spaces . . . .
5.2 Semirings . . . . . . .
5.3 Solution to exercises .
5.4 Additional exercises .

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

1

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

42
42
47
48
49

6 Measurable sets: Part III
6.1 The Lebesgue measure . . . . . . . . . . . . . . .
6.2 Measure extensions . . . . . . . . . . . . . . . . .
6.3 The Lebesgue measure on real coordinate spaces
6.4 Solution to exercises . . . . . . . . . . . . . . . .
6.5 Additional exercises . . . . . . . . . . . . . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

50
50
50
53
54
55

. . . . . .
numbers .
. . . . . .
. . . . . .
. . . . . .
. . . . . .

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

56
56
59
59
61
62
63

8 Integration: Part I
8.1 The integral for nonnegative functions . . . . . . . . . . . . . .
8.2 Integrable functions . . . . . . . . . . . . . . . . . . . . . . . .
8.3 Fatou’s lemma and Lebesgue’s dominated convergence theorem
8.4 Integration over measurable sets . . . . . . . . . . . . . . . . .
8.5 Solution to exercises . . . . . . . . . . . . . . . . . . . . . . . .
8.6 Additional exercises . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

64
64
66
67
69
71
73

7 Measurable functions
7.1 The concept of measurable functions . . . .
7.2 Functions taking values in the extended real
7.3 Sequences of measurable functions . . . . .
7.4 Minimal measurability . . . . . . . . . . . .
7.5 Solution to exercises . . . . . . . . . . . . .
7.6 Additional exercises . . . . . . . . . . . . .

.
.
.
.
.

.
.
.
.
.

9 Integration: Part II
9.1 Pushforward measure . . . . . . . . . . .
9.2 Densities . . . . . . . . . . . . . . . . . .
9.3 Integration with respect to the Lebesgue
9.4 Change of variable . . . . . . . . . . . .
9.5 Integration on product spaces . . . . . .
9.6 Integration in polar coordinates . . . . .
9.7 Solution to exercises . . . . . . . . . . .
9.8 Additional exercises . . . . . . . . . . .

. . . . .
. . . . .
measure
. . . . .
. . . . .
. . . . .
. . . . .
. . . . .

. . . .
. . . .
on the
. . . .
. . . .
. . . .
. . . .
. . . .

. . . . .
. . . . .
real line
. . . . .
. . . . .
. . . . .
. . . . .
. . . . .

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

75
75
76
77
79
80
84
85
86

10 General notions in Probability
10.1 Probability spaces . . . . . . . . . . .
10.2 Random variables and random vectors
10.3 Discrete laws . . . . . . . . . . . . . .
10.4 Continuous laws . . . . . . . . . . . .
10.5 Expectation . . . . . . . . . . . . . . .
10.6 Distribution function . . . . . . . . . .
10.7 Variance and covariance . . . . . . . .
10.8 Characteristic function . . . . . . . . .
10.9 Solution to exercises . . . . . . . . . .
10.10Additional exercises . . . . . . . . . .

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

87
87
87
88
90
92
95
96
97
98
99

11 Collections of random vectors
11.1 Independence . . . . . . . . . . . . .
11.2 Sums of independent random vectors
11.3 Gauss vectors . . . . . . . . . . . . .
11.4 A note on conditional probabilities .
11.5 Solution to exercises . . . . . . . . .
11.6 Additional exercises . . . . . . . . .

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

101
101
106
109
110
111
112

2

.
.
.
.
.
.

12 Convergence of random vectors
12.1 General notions of Convergence . . . .
12.2 A note on convergence in distribution
12.3 Solution to exercises . . . . . . . . . .
12.4 Additional exercises . . . . . . . . . .

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

114
114
120
121
122

. . . . .
. . . . .
. . . . .
. . . . .
. . . . .
theorem
. . . . .

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

123
123
124
125
125
128
130
132

. . . . .
. . . . .
. . . . .
. . . . .
. . . . .
. . . . .
. . . . .
measure

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

135
135
136
141
142
147
155
156
161

C Probability
C.1 On the distribution function . . . . . . . . . . . . . . . . . . .
C.2 Second moments . . . . . . . . . . . . . . . . . . . . . . . . .
C.3 Uniqueness theorem of the characteristic function . . . . . . .
C.4 Results on independence . . . . . . . . . . . . . . . . . . . . .
C.5 Grouping of independent random vectors . . . . . . . . . . .
C.6 On the law of a Gauss vector . . . . . . . . . . . . . . . . . .
C.7 On Kolmogorov’s Zero-One law and the law of large numbers

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

163
163
164
165
169
170
171
173

A Results from analysis
A.1 On infima and suprema: arithmetic
A.2 On limit inferior and limit superior
A.3 On convergent sequences . . . . . .
A.4 Continuity . . . . . . . . . . . . . .
A.5 Limit points . . . . . . . . . . . . .
A.6 Differentiability in one variable and
A.7 Differentiability in several variables

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

set operations
. . . . . . . . .
. . . . . . . . .
. . . . . . . . .
. . . . . . . . .
the mean value
. . . . . . . . .

.
.
.
.

B Measure and integration
B.1 Inclusion-exclusion principle . . . . . . . . . . . . . .
B.2 On measure extensions . . . . . . . . . . . . . . . . .
B.3 π-λ theorem . . . . . . . . . . . . . . . . . . . . . . .
B.4 On measurable functions . . . . . . . . . . . . . . . .
B.5 The integral . . . . . . . . . . . . . . . . . . . . . . .
B.6 On the Riemann and the Lebesgue integral . . . . .
B.7 Fubini-Tonnelli-Lebesgue . . . . . . . . . . . . . . . .
B.8 Summation: Integration with respect to the counting

3

.
.
.
.

.
.
.
.

.
.
.
.

1

Introduction: Part I

The following gives a list of greek letters:
α
β
γ,Γ
δ,∆
ϵ,ε
ζ
η
θ,Θ
ι
κ
λ,Λ
µ

alpha
beta
gamma
delta
epsilon
zeta
eta
theta
iota
kappa
lambda
mu

ν
ξ,Ξ
o
π,Π
ρ
σ,Σ
τ
υ,Υ
ϕ,φ,Φ
χ
ψ,Ψ
ω,Ω

nu
xi
o, omicron
pi
rho
sigma
tau
upsilon
phi
chi
psi
omega

We clarify some logical operations on statements. If S1 and S2 are two statements, we
write S1 ⇒ S2 if S1 implies S2 . S1 if and only if S2 (S1 ⇔ S2 ) means that S1 implies S2
and S2 implies S1 . Further, the following logical operators are helpful:
: means such that
∀ means for all
∃ means there exists.

1.1

Sets

Sets can be defined by their elements A = {ω1 , ω2 , . . . , ωn } or upon a certain property
A = {ω : ω has property P }.
Let A be a set, then
ω ∈ A means that ω is an element of A,
ω∈
/ A means that ω is not an element of A.
Example 1.1. The set which contains the strictly positive integers 1, 2, 3, . . . is denoted
with N. If n ∈ N, then so is n + 1. It is a matter of convention whether 0 ∈ N or not. For
us, 0 ∈
/ N.
Example 1.2. The set of integers is denoted with Z, it contains 0, N, and the set of points
{−n : n ∈ N}.
Example 1.3. Q is the set of rational numbers:

n
Q = q : q = , n, m ∈ Z, m ̸= 0 .
m
Example
1.4. It can be shown that there does not exists q ∈ Q s.t. q 2 = 2. This shows that
√
2∈
/ Q. The same is true for π and Euler’s number e. The latter numbers belong to the
set of real numbers, denoted with R. In particular, R contains all the integers and rational
numbers.
Example 1.5. Let A1 , . . . , An , n ∈ N, be a family of sets. The Cartesian product of
A1 , . . . , An is given by
n
Y

Ai = A1 × · · · × An = {ω : ω = (ω1 , . . . , ωn ) : ωi ∈ Ai , i = 1, . . . , n}.

i=1

4

An element ω of A1 ×· · ·×An is referred to as a vector with coordinates ωi ∈ Ai , i = 1, . . . , n.
If Ai = A, i = 1, . . . , n, we write A1 × · · · × An = An . The space Rk is referred to as the
real coordinate space of dimension k.
Definition 1.1. Let A and B be two sets. Then, we define the following set operations for
A and B.
Equality of sets: A = B if and only if A and B contain the same elements. That is, any
element of A is also an element of B and any element if B is also an element of A.
Inclusion: A ⊂ B if and only if ω ∈ A implies that ω ∈ B. If A ⊂ B, we say that A is a
subset of B.
Intersection: The intersection of A and B is the set
A ∩ B = {ω : ω ∈ A and ω ∈ B}.
Union: The union of A and B is the set
A ∪ B = {ω : ω ∈ A or ω ∈ B}.
Set difference: The difference between A and B is the set
A \ B = {ω : ω ∈ A and ω ∈
/ B}.
It is often of interest to consider the intersection and union of more than just two sets.
Let {Ai : i ∈ I} be a family of sets where I is some set. Then, the intersection of Ai , i ∈ I,
is defined as the set
\
Ai = {ω : ω ∈ Ai ∀ i ∈ I}.
(1)
i∈I

The union of Ai , i ∈ I, is defined as
[
Ai = {ω : ∃ i ∈ I s.t. ω ∈ Ai }.

(2)

i∈I

As an example one could think of I = N or I = {1, . . . , N }, where N ∈ N.
We can apply Definition 1.1 to derive several elementary properties of set operations.
Proposition 1.1. Let A, B and C be some sets.
Properties of the inclusion:
(1.1) A ⊂ A, i.e., each set is a subset of itself;
(1.2) A ⊂ B and B ⊂ A if and only if A = B;
(1.3) A ⊂ B and B ⊂ C implies that A ⊂ C.
Associativity:
(2.1) (A ∪ B) ∪ C = A ∪ (B ∪ C);
(2.2) (A ∩ B) ∩ C = A ∩ (B ∩ C).
Commutativity:
(3.1) A ∪ B = B ∪ A;
(3.2) A ∩ B = B ∩ A.
Distributive law:
5

(4.1) A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C);
(4.2) A ∪ (B ∩ C) = (A ∪ B) ∩ (A ∪ C).
As an example, let us proof two items of the latter proposition.
Proof of (1.2) in Proposition 1.1. The strategy is to show that A ⊂ B and B ⊂ A implies
that A = B and A = B implies that A ⊂ B and B ⊂ A. Suppose that A ⊂ B and B ⊂ A.
By Definition 1.1, we need to show that this implies that A and B contain the same elements.
Let ω ∈ A, then ω ∈ B, since A ⊂ B. On the other hand, take any ω ∈ B. Since B ⊂ A,
ω ∈ A. Thus, any ω ∈ A is also an element of B and vice versa. This shows that A ⊂ B
and B ⊂ A implies that A = B. For the other direction, let us assume that A = B. Then,
given ω ∈ A, it is true that ω ∈ B as well, thus by Definition 1.1, A ⊂ B. Also if ω ∈ B,
since A = B, it follows that ω ∈ A. Thus again by Definition 1.1, B ⊂ A. Hence A = B
implies that A ⊂ B and B ⊂ A.
Proof of (4.1) in Proposition 1.1. We need to show that A∩(B ∪C) ⊂ (A∩B)∪(A∩C) and
(A ∩ B) ∪ (A ∩ C) ⊂ A ∩ (B ∪ C). Let ω ∈ A ∩ (B ∪ C). This implies that ω is an element of A
and an element of B ∪ C. By the definition of B ∪ C, that means that ω ∈ B or ω ∈ C. Still,
ω ∈ A, thus ω ∈ A and ω ∈ B or ω ∈ A and ω ∈ C. This shows that ω ∈ (A ∩ B) ∪ (A ∩ C)
and hence A∩(B ∪C) ⊂ (A∩B)∪(A∩C). For the other inclusion, let ω ∈ (A∩B)∪(A∩C).
Then, by the definition of (A ∩ B) ∪ (A ∩ C), ω ∈ A and ω ∈ B or ω ∈ A and ω ∈ C. This
means that ω is a member of B ∪ C and A. Hence, ω ∈ A ∩ (B ∪ C).
Exercise 1.1. Show (1.3) of Proposition 1.1.
Exercise 1.2. Let A and B be two sets. Show that A ∩ B ⊂ A and conclude that A ⊂ B
implies that A ∩ B = A.
Exercise 1.3. Let A and B be two sets. Show that B ⊂ A ∪ B and conclude that A ⊂ B
implies that A ∪ B = B.
Exercise 1.4. Let A and B be two sets. Show that A ∪ B = A ∪ (B \ A).
Example 1.6. The set which has no elements is called the empty set and denoted with ∅.
Proposition 1.2. Given any subset A, ∅ ⊂ A.
Proof. Notice that we have used the definition that two sets are equal A = B if and only if
each element of A is also an element of B and vice versa. Assume for the moment that it is
not true that for all subsets A, ∅ ⊂ A. That means that there exists a subset A such that
∅ is not a subset of A. By Definition 1.1 that means that the empty set must contain an
element which does not belong to A. This gives a contradiction and hence it is not true that
there exists a subset A such that ∅ is not a subset of A, i.e., for any subsets A, ∅ ⊂ A.
Using Exercises 1.2 and 1.3, the latter result shows that ∅ ∩ A = ∅ and ∅ ∪ A = A.
Definition 1.2. Let A and B be two sets. A and B are said to be disjoint if A ∩ B = ∅.
More generally, let {Ai : i ∈ I} be any family of sets. {Ai : i ∈ I} is said to be disjoint if
Ai ∩ Aj = ∅ for any i ̸= j.
Exercise 1.5. Let A and B be two sets. Is it possible that A ⊂ B (or vice versa) and A
and B are disjoint.
In the following, we list some properties of the difference between sets.
Proposition 1.3. Let A, B and C be sets. Then,
(i) C \ (A ∩ B) = (C \ A) ∪ (C \ B);

6

(ii) C \ (A ∪ B) = (C \ A) ∩ (C \ B);
(iii) (B \ A) ∩ C = (B ∩ C) \ A;
(iv) (B \ A) ∪ C = (B ∪ C) \ (A \ C).
Notice that Exercise 1.4 is just a special case of item (iv) in Proposition 1.3 if we set
C = A.
In what follows, it is often the case that a particular set Ω is given and one only considers
subsets A of Ω. In that case, we use the notation Ac = Ω \ A for the complement of A in Ω.
Proposition 1.4. Let A and B be subsets of Ω. Then,
• A ∪ Ac = Ω;
• A ∩ Ac = ∅;
• A \ B = A ∩ Bc;
• ∅c = Ω;
• Ωc = ∅;
• (A ⊂ B) ⇒ (B c ⊂ Ac );
• (Ac )c = A.
Further, it is true that
• (A ∩ B)c = Ac ∪ B c ;
• (A ∪ B)c = Ac ∩ B c .
With reference to (1) and (2), we remark that the last two properties can be extended
to unions and intersections of arbitrary families {Ai : i ∈ I} of subsets of Ω:
 \ c [
Ai =
Aci ,
i∈I

[

i∈I

c
Ai

=

i∈I

\

Aci .

i∈I

We remark that since {Ai : i ∈ I} consists only of subsets of Ω,
\
[
Ai = {ω ∈ Ω : ω ∈ Ai ∀ i ∈ I} and
Ai = {ω ∈ Ω : ∃ i ∈ I s.t. ω ∈ Ai }.
i∈I

1.2

i∈I

The principle of induction

Let for any n ∈ N, S(n) be a statement. In order to proof that S(n) is true for any n ∈ N
we can adapt the following strategy:
Principle of induction To verify that S(n) is true for any n ∈ N we check (I) and (II):
(I) S(n) is true for n = 1 (base case);
(II) S(n) ⇒ S(n + 1) for any n ∈ N (induction step).
We note that if one seeks to proof S(n) for n ≥ N , N ∈ N, then one needs to verify
(I) S(N ) is true (base case);
(II) S(n) ⇒ S(n + 1) for any n ≥ N (induction step).
7

Example 1.7. Let us use a proof by induction to verify that for any n ∈ N,
1 + 2 + 3 + ··· + n =

n(n + 1)
.
2

First we verify the statement in the base case. Clearly, if n = 1, 1 = (1(1 + 1))/2. For the
induction step, we let n ∈ N be arbitrary and assume that 1 + 2 + · · · + n = (n(n + 1))/2.
Therefore,
1 + 2 + ···n + n + 1 =

n(n + 1) + 2(n + 1)
(n + 1)(n + 1 + 1)
n(n + 1)
+n+1=
=
,
2
2
2

which verifies the induction step and completes the argument.
Definition 1.3. Given n ∈ N ∪ {0}, The number n! is called n-factorial and given by
n! = n(n − 1) · . . . · 1.
We use the convention that 0! = 1.
Example 1.8. We want to verify the following statement: Let n ∈ N, then,
∀ N ∈ N ∃ C > 0 s.t. n! ≥ CN n .
In words, the statement reads as follows: Given any n ∈ N it is true that for any N ∈ N
there exists a positive constant C s.t. n! is greater or equal to CN n . To proof it, let n ∈ N
and N ∈ N be given. There are two cases, either n ≤ N or n > N . In the first case, if
n ≤ N , we can pick C = 1/N N . Then,
n! ≥ 1 ≥

Nn
.
NN

Thus, in this case, no induction is needed. For the case n > N , we use a proof by induction
on the new statement at base n = N :
∃ C > 0 s.t. n! ≥ CN n for all n ≥ N .
By the first case, we have already verified the base step. Thus it remains to verify the
induction step. We thus assume that for any given n ≥ N , the latter statement is true.
Then,
(n + 1)! = (n + 1)n! ≥ (n + 1)CN n ≥ (N + 1)CN n = CN n+1 + CN n ≥ CN n+1 ,
which completes the induction step. In summary, we started with an arbitrary N ∈ N and
have shown that for both cases, n ≤ N and n > N , there exists C s.t. n! ≥ CN n . This
shows the original statement for any n ∈ N.
Exercise 1.6. Verify that for any n ∈ N,
n
X
k=1

1.3

k2 =

n(n + 1)(2n + 1)
.
6

Order structure of the real numbers

Definition 1.4. Let a < b, a, b ∈ R. Then,
• [a, b] = {x ∈ R : a ≤ x ≤ b} is called a closed interval;
• (a, b) = {x ∈ R : a < x < b} is called an open interval;
8

• [a, b) = {x ∈ R : a ≤ x < b} is called a right-open interval;
• (a, b] = {x ∈ R : a < x ≤ b} is called a left-open interval.
A set I ⊂ R is said to be an interval if it is either closed, open, right-open or left-open.
Definition 1.5. Let a, b ∈ R. The unbounded real intervals are given by the sets:
• [a, ∞) = {x ∈ R : a ≤ x < ∞}, (a, ∞) = {x ∈ R : a < x < ∞};
• (−∞, b] = {x ∈ R : − ∞ < x ≤ b}, (−∞, b) = {x ∈ R : − ∞ < x < b}.
Definition 1.6. Let A ⊂ R. An element s ∈ R is called an upper (resp. lower) bound of A,
if x ≤ s (resp. x ≥ s) for all x ∈ A. If A has an upper (resp. lower) bound then we say that
A is bounded from above (resp. below). If A is bounded from below and above, A is bounded.
Definition 1.7. Let A ⊂ R be a set. An element s ∈ R is called supremum of A (we
write s = sup A) if s is the smallest upper bound of A. That is, the following two items are
satisfied:
(i) s is an upper bound of A;
(ii) Every number s′ < s is not an upper bound of A.
Example 1.9. Let A = [0, 1). Then, 1 is an upper bound for [0, 1), since x < 1 ⇒ x ≤ 1 for
any x ∈ [0, 1). In order to show that sup[0, 1) = 1, we need to verify that 1 is the smallest
upper bound of [0, 1), i.e., any s′ < 1 can not be an upper bound of [0, 1). To show this, it is
sufficient to proof that there exists a real number q in [0, 1) ∩ (s′ , 1) (we provide an argument
later). Then, q ∈ [0, 1) with q > s′ and hence s′ can not be an upper bound for [0, 1). Thus,
sup[0, 1) = 1. Notice that sup[0, 1) ∈
/ [0, 1), i.e., the supremum must not be an element of
the set itself.
Definition 1.8. Let A ⊂ R be a set. An element s ∈ R is called infimum of A (we write
s = inf A) if s is the greatest lower bound of A. That is, the following two items are satisfied:
(i) s is a lower bound of A;
(ii) Every number s′ > s is not a lower bound of A.
Example 1.10. Let A = [0, 1). Since x ≥ 0 for any x ∈ [0, 1), 0 is a lower bound of [0, 1).
As 0 ∈ [0, 1), inf[0, 1) = 0.
Definition 1.9. Let A ⊂ R. If s = sup A ∈ A (resp. s = inf A ∈ A) we call s the maximum
(resp. the minimum) of A.
The following result is of general importance. It shows that for each nonempty subset of
the real line which has an upper (resp. lower) bound, the supremum (resp. infimum) exists.
Proposition 1.5. Let A ⊂ R s.t. A ̸= ∅. Suppose that there exists an upper (resp. lower)
bound for A. Then, sup A (resp. inf A) exists.
Example 1.11. Let A = [0, 1). We have seen that the minimum of [0, 1) exists. However,
the maximum of [0, 1) does not exist, since sup[0, 1) = 1 ∈
/ [0, 1). This makes sense, as [0, 1)
is right-open and there does not exist a maximal element of [0, 1).
In order to show that there exists a number in between any two distinct real numbers,
the rational numbers Q are helpful.
Proposition 1.6 (Q is dense in R). For any two real numbers x1 , x2 ∈ R (say x1 < x2 ),
there exists a rational number between x1 and x2 , i.e., there exists q ∈ Q s.t. x1 < q < x2 .
To proof the above result, we rely on two fundamental results.
9

Proposition 1.7. For any x ∈ R there exists n ∈ N s.t. n > x.
Proposition 1.8. Let A ⊂ Z s.t. A ̸= ∅. If A has an upper (resp. lower) bound, then A has
a maximum (resp. minimum).
Proof of Proposition 1.6. By Proposition 1.7, since x2 ̸= x1 , let n ∈ N s.t.
n>

1
.
x2 − x1

Thus, 1/n < x2 − x1 . Let us define the following set
A = {a ∈ Z : a > nx1 }.
By Proposition 1.7, A ̸= ∅ Further, for any a ∈ A, a > nx1 ⇒ a ≥ nx1 . Hence, nx1 is a
lower bound for A. By Proposition 1.8, there exists a minimum m of A. Then, we must
have that
m > nx1 (since m ∈ A) but m − 1 ≤ nx1 ,
since otherwise we have m − 1 ∈ A which contradicts that m is the smallest number which
is strictly greater than nx1 . It follows that
x1 <

m−1
1
1
m
=
+ ≤ x1 + < x1 + x2 − x1 = x2 .
n
n
n
n

Hence if we let q = m/n, the result follows.
Example 1.12. In Example 1.9, we have postponed an argument that there exists a real
number in [0, 1) ∩ (s′ , 1). Clearly, only the case s′ > 0 (i.e., [0, 1) ∩ (s′ , 1) = (s′ , 1)) is
of interest since otherwise s′ ≤ 0 and then s′ is clearly no upper bound for [0, 1). Using
Proposition 1.6 we find q ∈ Q ⊂ R s.t. q ∈ (s′ , 1) and the result follows.
Definition 1.10. Let A ⊂ R s.t. A ̸= ∅. We define,
(i) sup A = ∞ if A has no upper bound;
(ii) inf A = −∞ if A has no lower bound.
Proposition 1.9. Let A, B ⊂ R s.t. A ⊂ B (A, B ̸= ∅). Then,
inf A ≥ inf B

and

sup A ≤ sup B.

Proof. Let m = inf B. Then, m is s.t. m ≤ x for any x ∈ B. Since A ⊂ B, every element
of A is an element of B and thus m ≤ x for any x ∈ A. Then, by definition, inf A is the
greatest lower bound of A and m was found to be a lower bound of A, thus m ≤ inf A. Let
m = sup M . Then, x ≤ M for any x ∈ B. In particular, since A ⊂ B, x ≤ M for any x ∈ A.
By definition, sup A is the smallest upper bound of A, thus sup A ≤ M .
Proposition 1.10. Let A ⊂ R be a nonempty set. Then,
• if inf A > −∞, for any δ > 0, there exists x ∈ A s.t. x < inf A + δ;
• sup A < ∞, for any δ > 0, there exists x ∈ A s.t. x > sup A − δ;
Proof. Suppose that there exists δ > 0 s.t. for any x ∈ A, x ≥ inf A + δ. Then, inf A + δ is a
lower bound for A which is greater than inf A. This is not possible. Similarly, suppose that
there exists δ > 0 s.t. for any x ∈ A x ≤ sup A − δ. Then, sup A − δ is an upper bound for
A which is smaller than sup A. Again, this is not possible.

10

Remark 1.1. Clearly R is not bounded and hence inf R = −∞ and sup R = ∞. Sometimes,
it is convenient to adjoin R with the objects −∞ and ∞, i.e., consider the set
R ∪ {−∞, ∞}.
This set is referred to as the extended real numbers (sometimes also written as [−∞, ∞]). We
use the notation R = R ∪ {−∞, ∞}. It is important to note that by definition, −∞, ∞ ∈
/ R,
i.e., these objects are not numbers. However, for any real number x ∈ R, x > −∞ and
x < ∞. Therefore, we assume that −∞ and ∞ satisfy the relation −∞ < ∞. With that
relation between −∞ and ∞, we have that for any x ∈ R, −∞ ≤ x ≤ ∞. By now we have
seen that −∞ and ∞ appear in the context of unbounded sets. We will see latter, that −∞
and ∞ also appear in the definition of diverging sequences. For future references, we also
write R+ = [0, ∞) ∪ {∞}.
Example 1.13. Let a, b ∈ R and assume that for any ε > 0, a ≤ b + ε. Then, a ≤ b. To see
it, let B = {x + ε : ε > 0, x ≥ b} and A = {x : x ≥ a}. We have that inf B = b and inf A = a.
Clearly, B ⊂ A. Hence, by the latter proposition, inf A = a ≤ b = inf B. Similarly, if for
any ε > 0, a ≥ b − ε, we must have a ≥ b. To see it, take B = {x − ε : ε > 0, x ≤ b} and
A = {x : x ≤ a}. Then sup B = b and sup A = a. Hence, by the latter proposition, since
B ⊂ A we have that b ≤ a. Notice, that the latter results do not change if we allow for
a = ∞ or b = ∞, i.e., a, b ∈ R (cf. Remark 1.1). For example, in the case where a ≤ b + ε,
if a = ∞, then b = ∞ and hence a = b. If b = ∞, then either a = b or a < b. Finally, we
remark that if for any ε > 0, a < b + ε, then, a ≤ b as well (resp. a ≥ b if for any ε > 0
a > b − ε). This is because the statement a < b + ε (resp. a > b − ε) implies that a ≤ b + ε
(resp. a ≥ b − ε).
Exercise 1.7. For each of the following sets, identify its infimum and supremum. Deduce
whether the sets have a minimum or maximum.
(a) A = {1/n : n ∈ N};
(b) B = Q ∩ [0, 2);
(c) C = Z ∩ (−∞, 0].
Up to now inf A and sup A were only defined for A ⊂ R. We extend the notions of
infimum and supremum to the extended real numbers as follows:
Definition 1.11.
• If A ⊂ R s.t. A ⊂ R and A is bounded, then sup A and inf A are defined as in
Definitions 1.7 and 1.8, respectively.
• If A ⊂ R s.t. there exists no real number s which is s.t. for any x ∈ A, x ≤ s, then
sup A = ∞. In particular, this is the case if ∞ ∈ A.
• If there exists s ∈ R s.t. x ≤ s for any x ∈ A, then sup A is defined as follows: If
A ⊂ R, then sup A is defined as in Definition 1.7. Otherwise, A = {−∞} ∪ A∗ ,
A∗ ⊂ R, and we define
(
sup A∗ , if A∗ ̸= ∅,
sup A =
−∞,
otherwise.
In particular, with this definition, sup A is the smallest upper bound of A.
• If A ⊂ R s.t. there exists no real number s which is s.t. for any x ∈ A, x ≥ s, then
inf A = −∞. In particular, this is the case if −∞ ∈ A.

11

• If there exists s ∈ R s.t. x ≥ s for any x ∈ A, then inf A is defined as follows: If
A ⊂ R, then inf A is defined as in Definition 1.8. Otherwise, A = A∗ ∪ {∞}, A∗ ⊂ R,
and we define
(
inf A∗ , if A∗ ̸= ∅,
inf A =
∞,
otherwise.
In particular, with this definition, inf A is the greatest lower bound of A.
Proposition 1.11. sup ∅ = −∞ and inf ∅ = ∞.
Proof. Suppose that there exists s ∈ R which is not an upper bound for ∅. Then, there
exists a ∈ ∅, s.t. a > s. Which is clearly not possible, since ∅ contains not a single element.
Therefore, any s ∈ R is in fact an upper bound for ∅. Therefore, sup ∅ = min(R) = −∞,
the smallest upper bound of ∅. Similarly, inf ∅ = max(R) = ∞, the largest lower bound of
∅.

1.4

Solution to exercises

Solution 1.1 (Solution to Exercise 1.1). We need to show that ω ∈ A ⇒ ω ∈ C. Thus, let
ω ∈ A. Since A ⊂ B, that implies that ω ∈ B. Further, since B ⊂ C, any member of B is a
member of C. In particular, ω ∈ C. Since ω was an arbitrary element of A, this completes
the argument.
Solution 1.2 (Solution to Exercise 1.2). Let ω ∈ A ∩ B. By Definition 1.1, this means that
ω ∈ A and ω ∈ B. In particular, ω ∈ A. Hence A ∩ B ⊂ A. In order to verify the second
claim, let us assume that A ⊂ B. We want to show that in this case A ∩ B = A. Let ω ∈ A,
then since A ⊂ B, ω ∈ B. In particular, ω ∈ A and ω ∈ B. This shows that A ⊂ A ∩ B.
We already knwo that it is generally true that A ∩ B ⊂ A. Thus, by (1.2) of Proposition 1.1,
A ⊂ B ⇒ A ∩ B = A.
Solution 1.3 (Solution to Exercise 1.3). By Definition 1.1, A ∪ B must contain all the
elements from B. To see this, suppose by contradiction that there exists ω ∈ B s.t. ω ∈
/ A∪B.
ω∈
/ A ∪ B means ω is an element that is not in A and also not in B (otherwise it would be
in one or the other). This is not true since ω ∈ B. Hence B ⊂ A ∪ B. Let us verify that
if A ⊂ B ⇒ A ∪ B = B. We have shown that in general B ⊂ A ∪ B. Thus, it remains to
show that if A ⊂ B, A ∪ B ⊂ B. That is clear, since if ω ∈ A ∪ B, then ω ∈ A or ω ∈ B. If
ω ∈ B, we are done. If ω ∈ A, we know that ω ∈ B as well, since A ⊂ B was assumed.
Solution 1.4 (Solution to Exercise 1.4). We show that A∪B ⊂ A∪(B \A) and A∪(B \A) ⊂
A ∪ B. Since B \ A ⊂ B ⊂ A ∪ B and A ⊂ A ∪ B, it is clear that A ∪ (B \ A) ⊂ A ∪ B. Let
ω ∈ A ∪ B, then ω ∈ A or ω ∈ B. If ω ∈ A, since A ⊂ A ∪ (B \ A), ω ∈ A ∪ (B \ A). If
ω ∈ B, then either ω ∈
/ A, hence ω ∈ B \ A ⊂ A ∪ (B \ A). Or ω ∈ A ∩ B ⊂ A and hence
ω ∈ A ∪ (B \ A) as well.
Solution 1.5 (Solution to Exercise 1.5). Yes, take A = ∅ and B any arbitrary set.
Solution 1.6 (Solution to Exercise 1.6). We proof the claim be induction. The base step is
clear. In order to verify the induction step, we choose n ∈ N, and assume that
n
X
k=1

k2 =

n(n + 1)(2n + 1)
.
6

12

We have that
n+1
X

k2 =

k=1

=
=
=
=
=
=
=
=
=

n(n + 1)(2n + 1)
+ (n + 1)2
6
n(n + 1)(2n + 1) + 6(n + 1)2
6
(n + 1)(n(2n + 1) + 6(n + 1))
6
(n + 1)(2n2 + 7n + 6)
6
(n + 1)(2n2 + 2n + 5n + 6)
6
(n + 1)((n + 2)(2n + n) − n2 − 4n + 5n + 6)
6
(n + 1)((n + 2)(2(n + 1) + 1 + n − 3) − n2 + n + 6)
6
(n + 1)((n + 2)(2(n + 1) + 1) + (n + 2)(n − 3) − n2 + n + 6)
6
(n + 1)((n + 2)(2(n + 1) + 1) + n2 − 3n + 2n − 6 − n2 + n + 6)
6
(n + 1)(n + 2)(2(n + 1) + 1)
.
6

Solution 1.7 (Solution to Exercise 1.7).
(a) We have that x ≤ 1 for any x ∈ A. Thus, 1 is an upper bound for A. Further,
sup A = 1, i.e., 1 is the smallest upper bound of A. This is because 1 ∈ A and hence
s′ < 1 can not be a smaller upper bound of A. In particular, as 1 ∈ A, the maximum
of A is 1. It is true that x ≥ 0 for any x ∈ A. Thus, 0 is a lower bound for A. Further,
0 is the largest lower bound of A. This is because for any s′ > 0 there exists n ∈ N
s.t. 1/n < s′ (Proposition 1.7). Thus, it can not be the case that there exists a larger
lower bound than 0. This shows that inf A = 0. Notice that 0 ∈
/ A, hence A has no
minimum.
(b) First, 0 = inf B and in particular, 0 ∈ B. Hence 0 is the minimum of B. Further, for
any x ∈ B, x ≤ 2. That is, 2 is an upper bound for B. By Proposition 1.6, 2 must be
the smallest upper bound of B. Hence sup B = 2. We note that since 2 ∈
/ B, B does
not have a maximum.
(c) Clearly, there does not exists s ∈ R s.t. x ≥ s for any x ∈ C. This shows that
inf B = −∞. In particular, C does not have a minimum. On the other hand, x ≤ 0
for any x ∈ C. Thus, because 0 ∈ C, sup C = 0 and in particular, 0 is the maximum
of C.

1.5

Additional exercises

Exercise 1.8. Let I be an arbitrary set and {Ai : i ∈ I} be a collection of subsets of a set
Ω. Let A ⊂ Ω. Show that
\
A ⊂ Ai ∀ i ∈ I ⇔ A ⊂
Ai .
i∈I

Exercise 1.9. Prove the following items of Proposition 1.4:
13

• A \ B = A ∩ Bc;
• (A ⊂ B) ⇒ (B c ⊂ Ac );
• (A ∩ B)c = Ac ∪ B c ;
• (A ∪ B)c = Ac ∩ B c .
Exercise 1.10. Let n ∈ N and Ai , i = 1, . . . , n, be a collection of subsets of a set Ω. Show
that
[
c \
n
n
Ai =
Aci .
i=1

i=1

Exercise 1.11. Let A be a set with n elements. Show that
• the number of permutations of the elements from A is n!;
• for any 0 ≤ k ≤ n, the number of subsets of A having k elements is given by
n!
.
(n − k)!k!
Note 1: If A = {ω1 , . . . , ωn }, then the vector (ωn1 , . . . , ωnn ), n1 , . . . , nn ∈ {1, . . . , n},
ni ̸= nj , i ̸= j, represents a permutation of the elementsfrom A.
Note 2: The number n!/((n − k)!k!) is denoted with nk .
Exercise 1.12. Verify that


n+1
k+1



  

n
n
=
+
.
k
k+1

14

2
2.1

Introduction: Part II
Functions

Definition 2.1. Let A and B be two sets. A function f : A → B is a rule which assigns to
each element a ∈ A exactly one element f (a) ∈ B.
Definition 2.2. Let f : A → B be a function.
Image: The image of f under C ⊂ A is the set
f (C) = {f (a) : a ∈ C}.

(3)

Preimage: If D ⊂ B, the preimage of f under D is the set
f −1 (D) = {a ∈ A : f (a) ∈ D}.
Example 2.1. Let f (x) = x2 , x ∈ R. We have that
f (R) = {y : y ∈ [0, ∞)}.
To see it, it is clear that f (R) ⊂ {y : y ∈ [0, ∞)}. For the other inclusion, take y ∈ {y : y ∈
√
[0, ∞)}. If we set x = y, then x2 = y. Thus, y ∈ f (R). Thus also {y : y ∈ [0, ∞)} ⊂ f (R).
Example 2.2. A function f : A → Rk assigns to each element a ∈ A, a vector f (a) ∈ Rk .
We use the notation f (a) = (f1 (a), . . . , fk (a)) for the value of f at a, where fi (a), i =
1, . . . , k, are referred to as the coordinate functions of f .
To indicate that an element a is assigned to an element f (a) we often use the notation
a 7→ f (a) to define the assignment, i.e., the function.
Definition 2.3. Let f : A → B be a function.
Surjective: f is called surjective, if f (A) = B.
Injective: f is called injective, if a1 ̸= a2 ⇒ f (a1 ) ̸= f (a2 ).
Bijective: f is called bijective if it is surjective and injective.
Example 2.3. Let f : R → [0, ∞), f (x) = x2 . We already know that f is surjective.
However, it is not injective, since for x1 = −1 and x2 = 1, f (x1 ) = f (x2 ) = 1. This shows
that x 7→ x2 is not bijective.
Definition 2.4. Let f : A → B be a function and E ⊂ A. The restriction of f to E is the
function f |E : E → B given by f |E (a) = f (a) for any a ∈ E.
Example 2.4. The function f : R → [0, ∞), f (x) = x2 is not bijective. However, its
restriction to [0, ∞) is.
Definition 2.5. Let f : A → B and g : B → C be two functions. The composition g ◦ f or
g(f ) is defined pointwise, i.e.,
(g ◦ f )(a) = g(f )(a) = g(f (a)).
Thus, g ◦ f : A → C.
Definition 2.6. Let f : A → B be a function. A function g : B → A is called an inverse of
f if
g(f (a)) = a ∀ a ∈ A

and

If f has an inverse it is called invertible.
15

f (g(b)) = b ∀ b ∈ B.

Proposition 2.1. Let f : A → B be a function. If f is bijective, then it is invertible.
Proof. Since f is surjective, f (A) = B. In particular, for any b ∈ B, there exists a ∈ A,
s.t. f (a) = b. Thus, we can assign to each b ∈ B, a respective element a ∈ A via the
assignment b 7→ g(b) = a, b = f (a). Clearly, g assigns elements from B to elements from
A. In order to show that the latter assignment is a function, the assignment rule must be
unique in the sense that if b = f (a) ∈ f (A) then g assigns b to exactly one element g(b) of
A. Suppose that this assignment rule is not unique, i.e., there exists a∗ ∈ A, a∗ ̸= a s.t.
g(b) = a∗ , b = f (a) (two outputs for the same input). This can only happen if f (a) = f (a∗ ),
since if f (a) ̸= f (a∗ ), g(f (a∗ )) = a∗ ̸= a = g(f (a)) = g(b), i.e., g(b) ̸= a∗ . But the case
f (a) = f (a∗ ) for a∗ ̸= a is not possible since f is surjective. Hence, it can not happen that
there exists a∗ ∈ A, a∗ ̸= a s.t. g(b) = a∗ .
Example 2.5. Let f (x) = ex , x ∈ R, i.e., f is the (natural) exponential function (e = e1 is
Euler’s number). One can show that f : R → (0, ∞) is bijective where the inverse is given
by the natural logarithm log(y) : (0, ∞) → R.
Exercise 2.1. Let f (x) = 1 − e−x , x ∈ [0, ∞). Is f : [0, ∞) → [0, 1) invertible? If yes, what
is its inverse?
Example 2.6. The trigonometric functions sin, cos : R → R are clearly not bijective. However, sin |[−π/2,π/2] : [−π/2, π/2] → [0, 1] and cos |[0,π] : [0, π] → [−1, 1] are bijective with
inverse arcsin : [−1, 1] → [−π/2, π/2] and arccos : [−1, 1] → [0, π]. In general, sin and cos
satisfy the following addition formulas: Given any θ1 , θ2 ∈ R,
sin(θ1 + θ2 ) = sin(θ1 ) cos(θ2 ) + sin(θ2 ) cos(θ1 )
sin(θ1 − θ2 ) = sin(θ1 ) cos(θ2 ) − sin(θ2 ) cos(θ1 )
cos(θ1 + θ2 ) = cos(θ1 ) cos(θ2 ) − sin(θ2 ) sin(θ1 )
cos(θ1 − θ2 ) = cos(θ1 ) cos(θ2 ) + sin(θ2 ) sin(θ1 ).
As a further example, the cotangent cot(θ) = cos(θ)/ sin(θ), θ ∈ (0, π) is s.t. cot : (0, π) → R
is bijective with inverse arccot : R → (0, π).
Example 2.7. Let
U = {(ρ, θ) ∈ R2 : ρ > 0, 0 < θ < 2π} = (0, ∞) × (0, 2π).
Define the function
T (ρ, θ) = (ρ cos(θ), ρ sin(θ)),

(ρ, θ) ∈ U.

Set V = R2 \ ([0, ∞) × {0}), i.e., V is R2 with the ray [0, ∞) × {0} removed. We notice
that T (U ) ⊂ V , since if (x, y) ∈ T (U ), then x = ρ cos(θ) and y = ρ sin(θ) for some ρ > 0
and θ ∈ (0, 2π). Thus, if (x, y) ∈ V c , then, by definition of V , sin(θ) = 0 and hence, θ = π.
This is not possible as it implies that x = −ρ and then (x, y) = (−ρ, 0) ∈ V . We verify
that T : U → V is bijective, i.e., injective and surjective. To see that T is injective we show
that for any two elements x1 = (ρ1 , θ1 ) and x2 = (ρ2 , θ2 ) in U , T (x1 ) = T (x2 ) implies that
x1 = x2 . We note that T (x1 ) = T (x2 ) implies that
ρ1 cos(θ1 ) − ρ2 cos(θ2 ) = 0

(4)

ρ1 sin(θ1 ) − ρ2 sin(θ2 ) = 0.

(5)

Assume by contradiction that x1 ̸= x2 . If ρ1 ̸= ρ2 but θ1 = θ2 , we use (5) and conclude
that sin(θ1 ) = sin(θ2 ) = 0. Since θ1 , θ2 ∈ (0, 2π), this implies that θ1 = θ2 = π. Upon
(4), we get that −(ρ1 − ρ2 ) = 0, which is a contradiction. For the remaining case assume
that θ1 ̸= θ2 (and either ρ1 = ρ2 or ρ1 ̸= ρ2 ). Notice first that it is not possible that
16

sin(θ1 ) = sin(θ2 ) = 0, since this would imply that θ1 = θ2 = π. Further, it is not possible
that cos(θ1 ) = cos(θ2 ) = 0, since then either θ1 = π/2 and θ2 = (3π)/2 or vice versa. This
implies that either ρ1 + ρ2 = 0 or −(ρ1 + ρ2 ) = 0. Thus, as a first case, we assume that
sin(θ1 ) ̸= 0 and cos(θ2 ) ̸= 0. Then, by (4) and (5),
ρ2 = ρ1

cos(θ1 )
cos(θ2 )

and

ρ1 = ρ2

sin(θ2 )
.
sin(θ1 )

The latter display is equivalent to
sin(θ1 ) cos(θ2 ) = sin(θ2 ) cos(θ1 ).
Upon the identity sin(θ1 − θ2 ) = sin(θ1 ) cos(θ2 ) − sin(θ2 ) cos(θ1 ), we conclude that sin(θ1 −
θ2 ) = 0. Since θ1 ̸= θ2 , this implies that θ1 = θ2 + π. Since sin(θ2 + π) = − sin(θ2 ), we
deduce from (5) that
−ρ1 sin(θ2 ) − ρ2 sin(θ2 ) = − sin(θ2 )(ρ1 + ρ2 ) = 0.
Thus, θ2 = π. This is not possible as it implies that θ1 = 2π and we have assumed that
θ1 < 2π. The remaining cases are similar and we thus conclude that T is indeed injective.
In order to verify that T is also surjective we need to show that T (U ) = V . We already know
that T (U ) ⊂ V , hence it remains to show the opposite inclusion. Let (x, y) ∈ V . First, it is
not possiblepthat x = y = 0, since y = 0 implies that x < 0. Assume first that y ̸= 0. We
define ρ = x2 + y 2 and θ = arccot(x/y) (cf. Example 2.6). With this
pchoice, (ρ, θ) ∈ U
and ρ cos(θ) = x and ρ sin(θ) = y. If y = 0, then again we define ρ = x2 + y 2 = |x| > 0
and θ = π. Again, (ρ, θ) ∈ U and ρ cos(θ) = x and ρ sin(θ) = y.
Definition 2.7. Let f : I → R, I ⊂ R be a function. f is called increasing (resp. decreasing)
if x1 ≤ x2 ⇒ f (x1 ) ≤ f (x2 ) (resp. x1 ≤ x2 ⇒ f (x2 ) ≤ f (x1 )). f is strictly increasing (resp.
strictly decreasing) if x1 < x2 ⇒ f (x1 ) < f (x2 ) (resp. x1 < x2 ⇒ f (x2 ) < f (x1 )). f
is called monotonic (resp. strictly monotonic) if it is either increasing or decreasing (resp.
strictly increasing or decreasing).
Proposition 2.2. Let f : I → R, I ⊂ R be a strictly monotonic function. Then, f : I → f (I)
is a bijection. Further, if f is strictly increasing (resp. strictly decreasing) on I, then an
inverse of f is strictly increasing (resp. strictly decreasing) on f (I).
Example 2.8. Let f : [0, ∞) → [0, ∞) be the function f (x) = x2 . Then, using the same
argument as in Example 2.1, we readily see that f ([0, ∞)) = [0, ∞). Further, if x < y, then
f (x) = x2 < y 2 = f (y). Thus, f is strictly increasing. By Proposition 2.2, we know that f
has inverse f −1 (y), y ∈ [0, ∞), which is also strictly increasing. Actually, in this case, we
√
know that f −1 (y) = y, y ∈ [0, ∞), is the unique inverse of f , since y = x2 has only one
non-negative solution.
Exercise 2.2. Let x, y ≥ 0. Show that x < y ⇒ x2 < y 2 .
In order to verify whether a function f is monotone, the following proposition is helpful.
Proposition 2.3. Let a, b ∈ R and f : (a, b) → R be a function that is differentiable on
(a, b). That is, the derivative f ′ of f exists on (a, b). Then:
• f ′ (x) ≥ 0 ∀ x ∈ (a, b) ⇒ f is increasing on (a, b);
• f ′ (x) > 0 ∀ x ∈ (a, b) ⇒ f is strictly increasing on (a, b);
• f ′ (x) ≤ 0 ∀ x ∈ (a, b) ⇒ f is decreasing on (a, b);
• f ′ (x) < 0 ∀ x ∈ (a, b) ⇒ f is strictly decreasing on (a, b).
17

Remark 2.1. Upon the latter proposition, the claim of Exercise 2.2 follows readily.
Exercise 2.3. Are the following functions monotone. If yes, are they increasing or decreasing (resp. strictly increasing or decreasing).
(a) f : (0, ∞) → (0, ∞), f (x) = 1/x;
(b) g : (0, ∞) → R, g(x) = log(x);
(c) h : R → [0, ∞), h(x) = x4 .
Definition 2.8. Let f, g : A → R be two real-valued functions.
Sum: f + g is the function a 7→ (f + g)(a) = f (a) + g(a);
Product: f g is the function a 7→ (f g)(a) = f (a)g(a);
Quotient: If g(a) ̸= 0 ∀ a ∈ A, then f /g is the function a 7→ (f /g)(a) = f (a)/g(a).
Proposition 2.4. Let f : A → B be a function. Let B∗ ⊂ B. Then,
(a) f −1 (B∗c ) = f −1 (B∗ )c .
Let I and J be some sets and Ai ⊂ A, i ∈ I, and Bj ⊂ B, j ∈ J, be a collection of sets from
A and B, respectively. Then,
(b) f (∪i∈I Ai ) = ∪i∈I f (Ai );
(c) f −1 (∪j∈J Bj ) = ∪j∈J f −1 (Bj );
(d) f −1 (∩j∈J Bj ) = ∩j∈J f −1 (Bj ).
Definition 2.9. Let f : A → R be a function and E ⊂ A. We use the notation
sup f (E) = sup{f (e) : e ∈ E} = sup f (e),
e∈E

for the supremum of f (E). Similarly, we write
inf f (E) = inf{f (e) : e ∈ E} = inf f (e).
e∈E

for the infimum of f (E).

2.2

Cardinality of Sets

Definition 2.10. Let A be a set. A is said to be finite if it contains a finite number
of elements. Otherwise, if the number of elements in A is not finite, A is referred to as
infinite.
Example 2.9. The sets N, Z, Q and R are all infinite. There does not exist a number
which counts the number of elements within the latter sets.
Definition 2.11. Let A and B be two arbitrary sets. A and B are said to have the same
cardinality (#A = #B) if and only if there exists a bijection f : A → B.
In terms of a visual interpretation, if #A = #B, then we can draw a line from each
element of A to an element of B (surjectivity) and it is not possible that a line emerges from
two different elements of A to the same element of B.
Example 2.10. If A and B are finite, then #A = #B precisely means that A and B have
the same number of elements (#A is given by the number of connecting lines between A and
B). In particular, if we let A = B, #A gives the number of elements in A. This shows that
#∅ = 0, since ∅ is clearly finite.
18

Definition 2.12. Let A and B be two sets and C ⊂ B.
• If there exists a bijection g : A → C we write #A ≤ #B;
• If there exists a bijection g : A → C but there exists no bijection f : A → B, we write
#A < #B.
Example 2.11. Let A and B be two sets. According to Definition 2.12, if A ⊂ B, #A ≤
#B. This is because the identity map g : A → A, g(a) = a, a ∈ A, is a bijection.
Proposition 2.5. We have that
• #N = #Z = #Q;
• #R > #N;
• any interval I ⊂ R is s.t. #I > #N.
Definition 2.13. Let A be a set. If
• #A ≤ #N, then A is countable;
• #A > #N, then A is uncountable.
Proposition 2.6. Let A be a set. If A is countable but not finite, then #A = #N and A is
said to be countably infinite.
Proposition 2.7. Let {Ai : i ∈ N} be a collection of sets s.t. for any i ∈ N, Ai is countable.
Then the union ∪i∈N Ai is countable as well.
Proposition
2.8. Let Ai , i = 1, . . . , n, be countable sets. Then, their Cartesian product,
Qn
A
is
countable.
i
i=1
We remark that if {Ai : i ∈ I} is some collection of sets, where I is some set, then if I is
countable we might always set I = N or I = {1, . . . , n}, n ∈ N.
To conclude this section we state the following result:
Proposition 2.9. Let [a, b], a < b ∈ R, be any closed interval. Let I be some countable set
(#I ≤ N ) and assume that there exists a family of open intervals (ai , bi ), ai , bi , i ∈ I, s.t.,
[a, b] ⊂ ∪i∈I (ai , bi ). Then, there exists N ∈ N and i1 , . . . , iN ∈ I, s.t. [a, b] ⊂ ∪N
j=1 (aij , bij ).
The latter result is known as the Heine-Borel theorem for intervals, it shows that any
closed interval on the real line which is covered by a countable collection of open intervals
can be covered by a finite sub-collection.

2.3

Euclidean distance

Definition 2.14. Given two points x, y ∈ Rk , the Euclidean distance between x and y is
given by
p
∥x − y∥ = (x1 − y1 )2 + · · · (xk − yk )2 , x = (x1 , . . . , xk ), y = (y1 , . . . , yk ).
Example 2.12. If k = 1, then we write ∥x − y∥ = |x − y|, where the function x 7→ |x| maps
x ∈ R to its absolute value
(
x,
if x ≥ 0,
|x| =
−x, if x < 0.
Proposition 2.10. For any x, y, z ∈ Rk , The Euclidean distance satisfies:
(i) ∥x − y∥ ≥ 0 and ∥x − y∥ = 0 ⇔ x = y;
19

(ii) ∥x − y∥ = ∥y − x∥ (symmetry);
(iii) ∥x + y∥ ≤ ∥x∥ + ∥y∥ (triangular inequality);
(iv) ∥x − y∥ ≥ ∥x∥ − ∥y∥ (reverse triangular inequality).
Notice that we use the notation 0 for the vector in Rk , k ∈ N, with all of its coordinates
equal to zero.
Example 2.13. In Proposition 1.6 of Example 1.4 we saw that there exists a rational number
in between any two distinct real numbers. Let ε > 0 and x ∈ R. Chose n ∈ N s.t. 1/n < ε.
Then, y = x + 1/n is s.t. |x − y| = 1/n < ε. Still, x ̸= y and hence by Proposition 1.6 we
find q ∈ Q s.t. x < q < y. In particular, 0 < q − x < y − x and hence |q − x| < ε. Since
ε > 0 and x ∈ R were arbitrary, we can conclude that for any ε > 0 and x ∈ R, there exists
q ∈ Q s.t. |x − q| < ε.
Definition 2.15. An open (resp. closed) ball of radius r > 0 with center y ∈ Rk is denoted
with
Br (y) = {x ∈ Rk : ∥y − x∥ < r} (resp. Br [y] = {x ∈ Rk : ∥y − x∥ ≤ r})
Definition 2.16. A set U ⊂ Rk is called open if for any point x ∈ U , there exists ε > 0,
s.t. Bε (x) ⊂ U . That is any point in U is the center of an open Ball contained in U .
Example 2.14. If U1 and U2 are two open subsets of Rk , then U1 ∩U2 is open. By definition,
if x ∈ U1 ∩ U2 , there exist Bε1 (x) and Bε2 (x) s.t. Bε1 (x) ⊂ U1 and Bε2 (x) ⊂ U2 . Thus, set
ε = min{ε1 , ε2 } and we obtain that Bε (x) ⊂ U1 ∩ U2 .
Example 2.15. Let a, b ∈ R. Then, the open interval (a, b) is an open set of R. Let
x ∈ (a, b), i.e., a < x < b. Let ε < min{|x − a|, |x − b|}. Then, take any y ∈ (x − ε, x + ε) =
Bε (x). It follows that x − y ≤ |x − y| < |x − a| = x − a and hence, y > a. Also,
y − x ≤ |x − y| < |x − b| = b − x, i.e., y < b. Therefore, y ∈ (a, b).
Example 2.16. An open ball Br (y) ⊂ Rk is an open set. This is a consequence of the
triangular inequality. Let x ∈ Br (y) be an arbitrary point and set δ = ∥x − y∥. Then, by
definition of Br (y), δ < r. Let ε = r − δ. Then, Bε (x) ⊂ Br (y), since for any z ∈ Bε (x),
∥z − y∥ ≤ ∥z − x∥ + ∥x − y∥ = ε + δ = r. Since x ∈ Br (y) was arbitrary, the result follows.
Qk
Exercise 2.4. Show that the open rectangle i=1 (ai , bi ), ai , bi , i = 1, . . . , k, is an open set
of Rk .
We remark that continuous functions on Euclidean spaces are characterized in terms of
open sets.
Definition 2.17. A function f : Rm → Rk is continuous if for any open set U ⊂ Rk , the
set f −1 (U ) is open in Rm .
Example 2.17. Let f (x) = x, x ∈ R. Then, f : R → R is continuous. Take any U ⊂ R
open. Then, f −1 (U ) = U . Hence, f −1 (U ) is an open subset of R.
A motivation for Definition 2.17 is given in the appendix (Section A.4). In terms of
functions defined on subsets of Rm , continuity is characterized as follows (a proof is given
in Section A.4):
Proposition 2.11. Let E ⊂ Rm , E ̸= ∅. A function f : E → Rk is continuous if and only
if for any open set U ⊂ Rk ,
f −1 (U ) ∈ {G ∩ E : G open in Rm }.
We recall some classical examples of continuous functions.
20

Proposition 2.12. The following functions are continuous:
Pk
• f : Rk → R, f (x) = i=1 xk , x = (x1 , . . . , xk );
Qk
• g : Rk → R, g(x) = i=1 xk , x = (x1 , . . . , xk );
• h : R \ {0} → R \ {0}, h(x) = 1/x.
For more details on the notion of continuity we refer to Section A.4.
Definition 2.18. A set V ⊂ Rk is said to be closed if V c is open.
Example 2.18. Given r > 0 and y ∈ Rk , a closed ball Br [y] ⊂ Rk is closed. To see it,
we show that Br [y]c = Rk \ Br [y] is open in Rk . Let x ∈ Br [y]c , i.e., ∥x − y∥ > r. Set
δ = ∥x−y∥−r. Then, δ > 0. Consider the open ball Bδ (x). If we show that Bδ (x) ⊂ Br [y]c ,
we are done. Hence, let z ∈ Bδ (x). Using the reverse triangular inequality (item (iv) of
Proposition 2.10),
∥z − y∥ ≥ ∥x − y∥ − ∥z − x∥ > ∥x − y∥ − δ = r,
i.e., z ∈ Br [y]c and we are done.
Example 2.19. The set V = {(x, y) ∈ R2 : x ≥ 0, y = 0} is a closed set of R2 . We show
that V c is open. Let v = (v1 , v2 ) ∈ V c . If v2 = 0, then v1 < 0 otherwise v ∈ V . Hence, if
v2 = 0, v ∈ V c implies that Br (v) ⊂ V c with r = |v1 |. To see it, it is sufficient to verify
that z = (a, b) ∈ Br (v) implies that a < 0 (this implies that (a, b) ∈ V c ). We notice that
z ∈ Br (v) implies that
(a − v1 )2 + b2 < v12 ⇔ a2 + b2 < 2av1 .
Hence, by the previous inequality, since v1 < 0 it can not be the case that a ≥ 0. The
remaining case is that v2 ̸= 0. Set r = |v2 |. We verify that Br (v) ⊂ V c . Let z = (a, b) ∈
Br (v). We verify that b ̸= 0 (this shows that (a, b) ∈ V c ). We note that z ∈ Br (v) implies
that (a − v1 )2 + (b − v2 )2 < v22 . But then, b = 0 is not possible, as it would imply that
(a − v1 )2 < 0. Hence, the set V c is open and thus V is closed.
Definition 2.19. A set A ⊂ Rk is said to be bounded if there exists r > 0 and y ∈ A s.t.
A ⊂ Br [y], i.e., A is contained in a closed ball.
Definition 2.20. Let f : A → R be a function and E ⊂ A, where A is some set. The
function f is said to be bounded on E if there exists 0 ≤ M < ∞, s.t. |f (a)| ≤ M for any
a ∈ E.

2.4

Solution to exercises

Solution 2.1 (Solution to Exercise 2.1). Yes, f is invertible. The inverse of f is the function
g : [0, 1) → [0, ∞), g(y) = − log(1 − y).
Solution 2.2 (Solution to Exercise 2.2). We show first that if a ∈ R s.t. a > 1, then,
for any z ∈ (0, ∞), az > z. Write a = 1 + ε with ε = a − 1 > 0. Then, az = z + εz.
Since ε, z > 0, az > z. Since x < y, 0 < (x − y)2 = x2 + y 2 − 2xy. Then, since x < y,
2xy ≥ 2x2 . Notice that this is because x ≥ 0. If x = 0, then 2xy = 0 = 2x2 . Otherwise,
if x > 0, then, since x < y, y/x > 1. Hence, 2xy = 2x2 x−1 y > 2x2 . In particular,
0 < x2 + y 2 − 2xy < x2 + y 2 − 2x2 = y 2 − x2 . This solves the exercises.
Solution 2.3 (Solution to Exercise 2.3).

21

(a) Given any 0 < a < b < ∞, f ′ (x) = −1/x2 , x ∈ (a, b). Thus, f ′ (x) < 0 for any
x ∈ (a, b) ⊂ (0, ∞). Since a and b were arbitrary, we easily verify that f must be
strictly decreasing on (0, ∞). If not, there exists x1 , x2 ∈ (0, ∞) with x1 < x2 and
f (x2 ) > f (x1 ). This is not possible, since we always find a < x1 < x2 < b, and
upon Proposition 2.3, since f has strictly negative derivative on (a, b), f is strictly
decreasing on (a, b), in particular f (x2 ) < f (x1 ).
(b) Given a, b ∈ R, we calculate g ′ (x) = 1/x, x ∈ (0, ∞). Then, using the same reasoning
as in (a), we conclude that g is strictly increasing.
(c) h is not monotone. To see it, we notice that h(−1) ≥ h(x) for any x ∈ [−1, 1] but
h(x) > h(−1) for any x ∈ (1, 2).
Qk
Solution 2.4 (Solution to Exercise 2.4). We need to show that for any x ∈ i=1 (ai , bi ),
Qk
there exists ε > 0, s.t. Bε (x) ⊂ i=1 (ai , bi ) (cf. Definition 2.16). Let x = (x1 , . . . , xk ) ∈
Qk
i=1 (ai , bi ) and set mi = min{|xi − ai |, |xi − bi |}, i = 1, . . . , k. Then, since for any i =
1, . . . , k, mi > 0, choose ε < min{mi : i = 1, . . . , k}. Then, let y = (y1 , . . . , yk ) ∈ Bε (x).
For any i = 1, . . . , k, we have that
|yi − xi | ≤ ∥y − x∥ < ε < mi .
In particular, xi − yi ≤ |yi − xi | < |xi − ai | = xi − ai and therefore, yi > ai . Also,
yi − xi ≤ |yi − xi | < |xi − bi | = bi − xi and hence yi < bi . This shows that yi ∈ (ai , bi ) for
any i = 1, . . . , k.

2.5

Additional exercises

Exercise 2.5. Show that for any x, y ∈ R and n ∈ N, (x + y)n =

Pn

k=0

n
k



xk y n−k .

Exercise 2.6. Prove Proposition 2.4.
Exercise 2.7. Let f : N → Z be defined as follows:
(
n
if n is even,
2,
f (n) = 1−n
2 , if n is odd.
Show that f is bijective.
Note: This shows that #N = #Z.
Exercise 2.8. Let A and B be two sets. Show that if A and B are countable, then, A ∪ B
is countable.
Exercise 2.9. Show that,
(a) if f : A → B and g : B → C are two functions s.t. f and g are bijective, then, the
composition g ◦ f : A → C is bijective as well;
(b) #R = #(0, 1).

22

3

Introduction: Part III

3.1

Real valued sequences

Definition 3.1. A real-valued sequence is a function f : N → R, i.e., f (n) ∈ R for any
n ∈ N. We use the notation f = (an )n∈N for a real-valued sequence and f (n) = an for the
values of f at n.
This section only treats real-valued sequences. Thus, for now, a sequence is a real-valued
sequence.
Definition 3.2. Let (an )n∈N be a sequence. (an )n∈N is said to be convergent if there exists
a number a ∈ R s.t. for any ε > 0 there exists N ∈ N s.t. |an − a| < ε for any n ≥ N .
The number a in Definition 3.2 is called the limit of (an )n∈N .
Example 3.1. Let an = 1/n, n ∈ N. We show that (an )n∈N is convergent with limit 0. Let
ε > 0 be an arbitrary strictly positive real number. According to Proposition 1.7, we pick
N ∈ N s.t. N > 1/ε. Then, for any n ≥ N ,
|an − 0| =

1
1
≤
< ε.
n
N

Exercise 3.1. If an = c for any n ∈ N then (an )n∈N is convergent with limit c
Exercise 3.2. Let an = (−1)n , n ∈ N. Is (an )n∈N convergent? Try to only use Definition 3.2.
Proposition 3.1. If (an )n∈N is convergent, then its limit a is unique and we write
lim an = a

n→∞

or

n→∞

an −−−−→ a.

In the following, we list some important results on real valued sequences.
Definition 3.3. A sequence (an )n∈N is said to be bounded if there exists M > 0 s.t. for
any n ∈ N, |an | ≤ M . (an )n∈N is said to be bounded from below (resp. above) if there exists
M ∈ R s.t. an ≥ M (resp. an ≤ M ) for any n ∈ N.
Proposition 3.2. If (an )n∈N is convergent, then it is bounded.
Definition 3.4. Let (an )n∈N be a sequence. (an )n∈N is increasing (resp. decreasing) if
an ≤ an+1 ∀ n ∈ N (resp. an ≥ an+1 ∀ n ∈ N). (an )n∈N is said to be monotonic if it is either
increasing or decreasing.
Definition 3.5. If (an )n∈N is increasing (resp. decreasing) with limit a, we write an ↑ a
(resp. an ↓ a).
Proposition 3.3. A bounded and monotonic sequence (an )n∈N is convergent.
Example 3.2. Let |r| < 1, and consider an = |r|n , n ∈ N. For any n ∈ N, an < 1 and
|r|n+1 = |r|n |r| ≤ |r|n .
Thus, (an )n∈N is bounded and decreasing. By Proposition 3.3, there exists L s.t.,
lim an = L.

n→∞

n→∞

Proposition 3.4. Let (an )n∈N and (bn )n∈N be two convergent sequences s.t. an −−−−→ a
n→∞
and bn −−−−→ b. Then,
23

n→∞

(i) an + bn −−−−→ a + b;
n→∞

(ii) an bn −−−−→ ab;
n→∞

(iii) an /bn −−−−→ a/b, if b ̸= 0.
n→∞

Proposition 3.5. Let (an )n∈N and (bn )n∈N be two convergent sequences s.t. an −−−−→ a
n→∞
and bn −−−−→ b. Assume that an ≤ bn (resp. an ≥ bn ) for any n ∈ N, then a ≤ b (resp.
a ≥ b).
Proposition 3.6. Let (an )n∈N and (bn )n∈N be two convergent sequences that converge to
n→∞
n→∞
the same limit, i.e., an −−−−→ a and bn −−−−→ a. Let (cn )n∈N be another sequence which is
n→∞
s.t. for any n ∈ N, an ≤ cn ≤ bn . Then, cn −−−−→ a.
Example 3.3. Let |r| < 1, and consider an = rn , n ∈ N. We show that (an )n∈N is
convergent with limit 0. To do so, we consider (bn )n∈N , with bn = |r|n , n ∈ N as in
Example 3.2. We have that
(
rn ,
r ∈ [0, 1),
n
r =
n
n
(−1) |r| , r ∈ (−1, 0).
In particular, for any n ∈ N,
−|r|n ≤ rn ≤ |r|n .
Thus, by Propositions 3.4 and 3.6, it is sufficient to show that (bn )n∈N converges to zero.
We already know (see Example 3.2) that there exists L s.t.,
lim bn = L.

n→∞

Now we have that
L = lim bn = lim bn+1 = |r| lim bn = |r|L.
n→∞

n→∞

n→∞

Thus, since r ∈
/ {−1, 1}, it must be the case that L = 0. In conclusion, limn→∞ an = 0.
Example 3.4. In Example 2.13 we have seen that for any real number x, the Euclidean
distance between x and elements from Q can be made arbitrary small. Let us show that for
any x ∈ R, there exists a sequence of rational numbers (qn )n∈N , qn ∈ Q, n ∈ N, s.t. qn ↑ x.
By Proposition 1.6, for any ε > 0, there exists q ∈ Q, s.t. x − ε < q ≤ x. For n = 1, choose
q1 ∈ (x − 1, x] \ (x − 1/2, x]. For n = 2, choose q2 ∈ (x − 1/2, x] \ (x − 1/3, x] and so on
until we choose qn in
x−


1
1 
,x \ x −
,x .
n
n+1

Then, qn < qn+1 and for any n ∈ N and
x−

1
< qn ≤ x.
n

Using Proposition 3.6, this shows that qn ↑ x. A similar argument shows there exists a
sequence (qn∗ )n∈N , qn∗ ∈ Q, n ∈ N, s.t. qn∗ ↓ x.
Exercise 3.3. Let
an =

n2 + 3n3 + n
,
1 + n4

Is (an )n∈N convergent? If yes, what is its limit?
24

n ∈ N.

Exercise 3.4. Let an = n!/nn , n ∈ N. Is (an )n∈N convergent? If yes, what is its limit?
Definition 3.6. Let (an )n∈N be a sequence. We write:
n→∞

(i) an −−−−→ ∞ (or limn→∞ an = ∞) if ∀ M ∈ R ∃ N ∈ N s.t. an ≥ M ∀ n ≥ N .
n→∞

(ii) an −−−−→ −∞ (or limn→∞ an = −∞) if ∀ M ∈ R ∃ N ∈ N s.t. an ≤ M ∀ n ≥ N .
If limn→∞ an = ∞ (resp. limn→∞ an = −∞) we say that (an )n∈N diverges to ∞ (resp.
−∞). We say that (an )n∈N diverges if it either diverges to ∞ or −∞.
Remark 3.1. Let (an )n∈N be a sequence. For now, if limn→∞ an is well defined, i.e.,
limn→∞ an ∈ R (i.e., (an )n∈N converges) or (an )n∈N diverges, we understand limn→∞ an as
an element of the extended real line R (cf. Remark 1.1). We write that limn→∞ an exists, if
limn→∞ an ∈ R. Further, if limn→∞ an exists, then it is unique.
Proposition 3.7. Let (an )n∈N be a monotone sequence. Then, limn→∞ an exists. If (an )n∈N
is increasing and (an )n∈N diverges, then it diverges to ∞. If (an )n∈N is decreasing and
(an )n∈N diverges, then it diverges to −∞.
We notice that for increasing (resp. decreasing) sequences, Proposition 3.5 remains true
even if the sequences do not converge.
Proposition 3.8. Let (an )n∈N and (bn )n∈N be two increasing (resp. decreasing) sequences.
Then, if for any n ∈ N, an ≤ bn , limn→∞ an ≤ limn→∞ bn .
Exercise 3.5. Prove Proposition 3.8.
Definition 3.7. Let (ai )i∈N be a sequence. The series
X

ai =

∞
X

ai ,

i=1

i∈N

Pn
is understood as theP
sequence (sn )n∈N , where sn = i=1 ai , n ∈ N. If limn→∞ sn exists we
∞
write limn→∞ sn = i=1 ai for the limit.
P
Proposition 3.9.
i∈N ai be a series where ai ≥ 0 for any i ∈ N. Then, either
P
P Let
a
<
∞
or
a
=
∞.
i∈N i
i∈N i
Proof. This follows from
3.7. Notice that since ai ≥ 0 for any i ∈ N, the
PProposition
n
sequence (sn )n∈N , sn = i=1 ai , is increasing.
Example 3.5. We have that
X1
i∈N

i.e., the sequence (sn )n∈N , sn =
next section.

Pn

i=1 (1/i),

i

= ∞,

diverges to ∞. We will give an argument in the

Example 3.6. We have that
X
i∈N

1
= 1.
i(i + 1)

We notice that
1
1
1
−
=
.
i
i+1
i(i + 1)
25

Then, for any n ∈ N,
sn =

n
X
i=1

n

X
1
=
i(i + 1)
i=1



1
1
−
i
i+1



1
1
1
1
1
1
1
1
+ −
+ −
+ ··· −
+ −
1+1 2 2+1 3 3+1
n−1+1 n n+1
1
=1−
.
n+1
P
Therefore, since limn→∞ sn = 1, we have that i∈N 1/(i(i + 1)) = 1.
=1−

Example 3.7. The functions x 7→ ex , x 7→ sin(x) and x 7→ cos(x) are all defined in terms
of a series:
P∞ k
• ex = k=0 xk! , x ∈ R;
(−1)k
2k+1
,
k=0 (2k+1)! x

• sin(x) =

P∞

• cos(x) =

P∞

(−1)k 2k
k=0 (2k)! x ,

x ∈ R;

x ∈ R.

To conclude this section, we list two useful results for series.
P
P
Proposition
3.10. Let i∈N ai be a series and i∈N bi be a series
P
P s.t. bi ≥ 0 for any i ∈ N
and i∈N bi < ∞. Suppose that |ai | ≤ bi for any i ∈ N. Then i∈N ai < ∞.
Proposition 3.11. Let I, J ⊂ N and f : I × J → R. For any i, j ∈ N, set aij = f (i, j).
Thus, we obtain a doubly indexed sequence
of real numbers (aij )P
(i,j)∈I×J . Suppose that either
P
aij ≥ 0 for any (i, j) ∈ I × J or (i,j)∈I×J |aij | < ∞. Then, (i,j)∈I×J aij is well defined
and
X
XX  XX 
aij =
aij =
aij .
(6)
(i,j)∈I×J

i∈I

j∈J

j∈J

i∈I

That
allowed to change the order of summation. If I = J, we use the notation
P is, we areP
2
a
=
(i,j)∈I 2 ij
i,j∈I aij for the sum over all the pairs (i, j) ∈ I .

3.2

Subsequences: Limit inferior and limit superior

We remain in the setting of the previous Section, i.e., any sequence (an )n∈N is a real-valued
sequence according to Definition 3.1.
Definition 3.8. Let f = (an )n∈N be a sequence (cf. Definition 3.1). A subsequence of
(an )n∈N is a new sequence g = (bn )n∈N , where g = f ◦ s, with s : N → N s.t. s(n) < s(n + 1),
i.e., for any k ∈ N, bn = g(n) = f (s(n)) = as(n) .
Example 3.8. Let an = 1/n, n ∈ N. Then, (a2n )n∈N , is a subsequence of (an )n∈N .
The following result is known as the Bolzano–Weierstrass theorem.
Proposition 3.12. Let (an )n∈N be a sequence. If (an )n∈N is bounded, then there exists a
subsequence of (an )n∈N which is convergent.
Example 3.9. Let an = (−1)n , n ∈ N. We have seen that (an )n∈N is not convergent.
However, (a2n )n∈N is a subsequence of (an )n∈N with limit 1.
An application of Proposition 3.12 is the following result (a proof is given in Section A.4).
Proposition 3.13. Let f : [a, b] → R be continuous, then there exists xM , xm ∈ [a, b] s.t.
f (xM ) = supx∈[a,b] f (x) = maxx∈[a,b] f (x) and f (xm ) = inf x∈[a,b] f (x) = minx∈[a,b] f (x),
i.e., f attains its maximum and minimum in [a, b]. In particular, f is bounded.
26

Definition 3.9. Let (an )n∈N be a sequence and (as(n) )n∈N be a subsequence of (an )n∈N s.t.
limn→∞ as(n) = a. Then, a is said to be an accumulation point of (an )n∈N .
Example 3.10. Let an = (−1)n , n ∈ N. Then, (an )n∈N has two accumulation points, −1
and 1.
Proposition 3.14. Let a be an accumulation point of (an )n∈N . Then, for any ε > 0, there
are infinitely an s.t. an ∈ (a − ε, a + ε).
Proof. Since a = limn→∞ as(n) , it follows that for any ε > 0, there exists N ∈ N, s.t. for any
n ≥ N , |as(n) − a| < ε ⇒ as(n) ∈ (a − ε, a + ε).
Proposition 3.15. Let (an )n∈N be a sequence. If (an )n∈N is convergent with limit a, then
every subsequence of (an )n∈N converges to a. That is, a convergent sequence has only one
accumulation point.
Proof. Clearly a is an accumulation point of (an )n∈N . Suppose by contradiction that b ̸= a
is another accumulation point of (an )n∈N . Set δ = (a − b)/2. Then δ > 0 and hence, there
exists N ∈ N s.t. |an − a| < δ for any n ≥ N . Then,
|an − b| = |an − a + a − b| ≥ |an − a| − |a − b| ,
by the reverse triangular inequality (cf. Proposition 2.10). Therefore, for any n ≥ N ,
|an − b| ≥ |an − a| − 2δ = 2δ − |an − a| > δ.
This shows that there exists ε > 0 (ε = δ) s.t. |an − b| > ε for any n ≥ N . Thus, for that
particular ε, only at most finitely many an , are s.t. an ∈ (b − ε, b + ε). This contradicts
Proposition 3.14. Hence, b is not an accumulation point of (an )n∈N .
Proposition 3.16. Let (an )n∈N be an increasing (resp. decreasing) sequence. Suppose that
there exists a subsequence (as(n) )n∈N which is s.t. limn→∞ as(n) = ∞ (resp. limn→∞ as(n) =
−∞). Then, limn→∞ an = ∞ (resp. limn→∞ an = −∞).
Proof. Using Proposition 3.7, this follows directly from Proposition 3.15. If limn→∞ an ̸=
∞ (resp. limn→∞ an ̸= −∞) it means that (an )n∈N converges (cf. Proposition 3.7). In
particular, there exists a < ∞ s.t. any accumulation point of (an )n∈N is equal to a (cf.
Proposition 3.15). This gives a contradiction with the assumption that limn→∞ as(n) = ∞
(resp. limn→∞ as(n) = −∞).
P
Pn
Example 3.11. We show that i∈N (1/i) = ∞ (cf. Example 3.5). Set, sn = i=1 (1/i),
n ∈ N. Then, (sn )n∈N is increasing. Define the subsequence (s(2n −1) )n∈N . Let n ∈ N and
k ∈ {2, . . . , n}. We have that
k

s(2n −1)


−1
n  2X
X
1
.
=1+
i
k−1
k=2

n

i=2

∪nk=2 {2k−1 , . . . , 2k − 1}.

This is because, {2, . . . , 2 − 1} =
We can use induction to see it. If
n = 2, then {2, 3} = {22−1 , 22 − 1}. Suppose that {2, . . . , 2n − 1} = ∪nk=2 {2k−1 , . . . , 2k − 1}.
Then,
{2, . . . , 2n+1 − 1} = {2, . . . , 2n − 1} ∪ {2n , . . . , 2n+1 − 1}
= ∪nk=2 {2k−1 , . . . , 2k − 1} ∪ {2n , . . . , 2n+1 − 1}
n+1 k−1
= ∪k=2
{2
, . . . , 2k − 1}.

For any n ∈ N, the cardinality of {2k−1 , . . . , 2k − 1} is 2k − 1 − (2k−1 − 1) = 2k − 2k−1 =
P2k −1
2k−1 (2 − 1) = 2k−1 . Hence, for any n ∈ N, i=2k−1 (1/i) ≥ 2k−1 (1/2k − 1) ≥ 1/2. Thus, for
any n ∈ N, s(2n −1) ≥ 1 + (n − 1)/2. Therefore, (s(2n −1) )n∈N can not be convergent and we
conclude that limn→∞ s(2n −1) = ∞. Using Proposition 3.16, this shows that limn→∞ sn = ∞
as well.
27

Proposition 3.17. Suppose that (an )n∈N is not bounded from below (resp. bounded from
above). Then, inf n∈N an = −∞ (resp. supn∈N an = ∞).
Exercise 3.6. Prove Proposition 3.17.
Exercise 3.7. Let (an )n∈N be a sequence bounded from below. Define the sequence
mn = inf{ak : k ≥ n} = inf ak ,
k≥n

n ∈ N.

Show that (mn )n∈N is increasing.
Exercise 3.8. Let (an )n∈N be a sequence bounded from above. Define the sequence
Mn = sup{ak : k ≥ n} = sup ak ,

n ∈ N.

k≥n

Show that (Mn )n∈N is decreasing.
Proposition 3.18. Let (an )n∈N and (mn )n∈N be as in Exercise 3.7. Then,
lim mn = sup mn = sup inf ak .

n→
−∞

n∈N

n∈N k≥n

Exercise 3.9. Prove Proposition 3.18.
Similarly, we have the following result.
Proposition 3.19. Let (an )n∈N and (Mn )n∈N be as in Exercise 3.8. Then,
lim Mn = inf Mn = inf sup ak .

n→
−∞

n∈N

n∈N k≥n

Example 3.12. Let an = (−1)n , n ∈ N, then mn = −1 and Mn = 1 for any n ∈ N. In
particular, limn→∞ mn = −1 and limn→∞ Mn = 1.
We are in place to make the following definition:
Definition 3.10. Let (an )n∈N be a sequence. We define:
(
supn∈N inf k≥n ak , if (an )n∈N is bounded or bounded from below,
lim inf an =
n→
−∞
−∞,
otherwise,
and
(
inf n∈N supk≥n ak ,
lim sup an =
∞,
n→
−∞

if (an )n∈N is bounded or bounded from above,
otherwise.

lim inf n→
− ∞ an and lim supn→
− ∞ an are referred to as limit inferior and limit superior of
(an )n∈N .
Exercise 3.10. Suppose that limn→∞ an = −∞ (resp. limn→∞ an = ∞), then,
lim inf an = −∞ = lim sup an (resp. lim inf an = ∞ = lim sup an ).
n→
−∞
n→
−∞
n→
−∞
n→
−∞
Proposition 3.20. Let (an )n∈N be a sequence. We have that
lim inf an ≤ lim sup an .
n→
−∞
n→
−∞

28

Proof. Given any n ∈ N, inf k≥n ak ≤ supk≥n ak . Assume that (an )n∈N is bounded. Then,
(inf k≥n ak )n∈N and (supk≥n ak )n∈N converge (cf. Proposition 3.3). We use Propositions 3.18
and 3.19 and obtain,
lim inf an = lim inf ak ≤ lim sup ak = inf sup ak = lim sup an .
n→
−∞
n→∞ k≥n
n→∞ k≥n
n∈N k≥n
n→
−∞
Clearly, by Definition 3.10, lim inf n→
− ∞ an ≤ lim supn→
− ∞ an in all the other cases.
The following result gives another characterization of convergence:
Proposition 3.21. Let (an )n∈N be a bounded sequence. Then, (an )n∈N is convergent with
limit a if and only if
lim inf an = a = lim sup an .
n→
−∞
n→
−∞
We use the following result to proof the latter proposition.
Proposition 3.22. Assume that (an )n∈N is a bounded sequence and define the set
A = {a : a is an accumulation point of (an )n∈N }.
Then, min A = lim inf n→
− ∞ an and max A = lim supn→
− ∞ an .
Proof of Proposition 3.21. Assume that (an )n∈N is convergent with limit a. It follows by
Proposition 3.15 that the set of accumulation points of (an )n∈N is given by {a}. Using
Proposition 3.22, this shows that lim inf n→
− ∞ an = a = lim supn→
− ∞ an . For the other
direction, assume that (an )n∈N is s.t. lim inf n→
− ∞ an = a = lim supn→
− ∞ an . Then, we have
that for any n ∈ N,
mn = inf ak ≤ an ≤ sup ak = Mn
k≥n

k≥n

Therefore, using Propositions 3.6, 3.18 and 3.19 we conclude that (an )n∈N has limit a.
A more general statement is the following.
Proposition 3.23. limn→∞ an exists if and only if
lim inf an = lim an = lim sup an .
n→
−∞
n→∞
n→
−∞
Proof. Using Proposition 3.21 and Exercise 3.10 it remains to show that if
lim inf an = −∞ = lim sup an (or lim inf an = ∞ = lim sup an ),
n→
−∞
n→
−∞
n→
−∞
n→
−∞
then limn→∞ an exists. Actually, if
lim inf an = −∞ = lim sup an ,
n→
−∞
n→
−∞
then limn→∞ an = −∞ as well. To see it we first notice that (an )n∈N must be bounded from
above, otherwise, lim supn→
− ∞ an = ∞, by definition. Hence, (Mn )n∈N with Mn = supk≥n ak
is decreasing (cf. Exercise 3.8). Also since lim inf n→
− ∞ an = −∞, (an )n∈N is not bounded
from below. Therefore, for any M ∈ R, there exists N ∈ N, s.t. for any n ≥ N , Mn ≤ M .
Further, for any n ∈ N, an ≤ supk≥n ak . In conclusion, we have shown that for any M ∈ R,
there exists N ∈ N, s.t. an ≤ M for any n ≥ N . This shows that (an )n∈N diverges to −∞
(cf. Definition 3.6). A similar argument shows that if
lim inf an = ∞ = lim sup an ,
n→
−∞
n→
−∞
then limn→∞ an = ∞.
29

Example 3.13. Let an = (−1)n , n ∈ N, then, lim inf n→
− ∞ an = −1 and lim supn→
− ∞ an = 1
(cf. Example 3.12). Hence, using Proposition 3.21, (an )n∈N can not be convergent (cf.
Exercise 3.2).
Exercise 3.11. Let an = cos(nπ), n ∈ N. Find lim inf n→
− ∞ an and lim supn→
− ∞ an .
We note that the following proposition gives another useful characterization of convergence in terms of subsequences — it states that if for an arbitrary subsequence of a realvalued sequence one can extract a subsequence that converges to some real number, then
the original sequence converges with limit given by the aforementioned number:
Proposition 3.24. Let (an )n∈N be a real-valued sequence. Consider the follwong assumption:
(A) for any subsequence (as(n) )n∈N of (an )n∈N there exists a subsequence (at(s(n)) )n∈N of
n→∞
(as(n) )n∈N s.t. at(s(n)) −−−−→ a.
n→∞

Then, if (A) holds, an −−−−→ a.
The latter is known as the subsequence criterion for convergent sequences – for a proof
we refer to Section A.3 of the appendix.

3.3

Vector-valued sequences

The previous section on real-valued sequences can easily be extended to the notion of vectorvalued sequences.
Definition 3.11. An Rk -valued sequence is a function f : N → Rk , where we write
f (n) = (f1 (n), . . . , fk (n)) = (an1 , . . . , ank ),

n ∈ N,

We use the notation f = (an )n∈N for a Rk -valued sequence.
We notice that the coordinate functions of an Rk -valued sequence (an )n∈N are real-valued
sequences (cf. Definition 3.1). The space of all Rk -valued sequences is denoted with (Rk )N ,
k ∈ N. If k = 1, then (an )n∈N is a real-valued sequence. In p
particular, Definition 3.11 contains Definition 3.1. Upon the Euclidean metric ∥x − y∥ = (x1 − y1 )2 + · · · + (xk − yk )2 ,
x = (x1 , . . . , xk ), y = (y1 , . . . , yk ), we can introduce the notion of convergence for Rk -valued
sequence.
Definition 3.12. Let (an )n∈N ∈ (Rk )N . (an )n∈N is said to be convergent if there exists a
number a = (a1 , . . . , ak ) ∈ Rk s.t. for any ε > 0 there exists N ∈ N s.t. ∥an − a∥ < ε for
any n ≥ N .
n→∞

If (an )n∈N ∈ (Rk )N , we write an −−−−→ a (resp. limn→∞ an = a) to indicate that (an )n∈N
converges to a. The following result shows that in order to proof that an Rk -valued sequence
converges, it is enough to study the convergence of the individual coordinates.
Proposition 3.25. Let (an )n∈N ∈ (Rk )N . Then,
n→∞

n→∞

(an1 , . . . , ank ) = an −−−−→ a = (a1 , . . . , ak ) ⇔ ani −−−−→ ai ∀ i = 1, . . . , k.
The following result is called the sequence criterion for continuous functions (a proof is
given in the appendix, Section A.4).
Proposition 3.26. Let f : E → Rk , E ⊂ Rm and x ∈ E. Then, the following two statements are equivalent:
(i) f is continuous at x;
(ii) ∀ (xn )n∈N ⊂ E with limn→∞ xn = x it follows that limn→∞ f (xn ) = f (x).
In the following, we will use the term sequence for (an )n∈N ∈ (Rk )N , k ∈ N, and it will
be clear from the context whether k = 1 or k > 1.
30

3.4

Sequences of Functions

Definition 3.13. In general, a sequence of functions, taking values in the extended real
numbers, defined on some common set A, is a collection of functions gn : A → R, n ∈ N.
Then, given E ⊂ N, the quantities inf n∈E gn and supn∈E gn are defined pointwise on A, i.e.,
( inf gn )(x) = inf gn (x) and (sup gn )(x) = sup gn (x),
n∈E

n∈E

n∈E

x ∈ A.

n∈E

Hence, for any x ∈ A, (inf n∈E gn )(x), (supn∈E gn )(x) ∈ R. Additionally, if for any x ∈ A,
limn→∞ gn (x) ∈ R, then also limn→∞ gn is defined pointwise, i.e.,
( lim gn )(x) = lim gn (x),
n→∞

n→∞

x ∈ A.

We say that the sequence of functions gn , n ∈ N, converges pointwise to a function g : A → R,
if for any x ∈ A, limn→∞ gn (x) = g(x).
Example 3.14. Given x ∈ [0, π], let gn (x) = cos(nx), n ∈ N. Then, gn , n ∈ N, is a sequence of functions. We have seen that (lim inf n→
− ∞ gn )(π) = −1 and (lim supn→
− ∞ gn )(π) =
1. Therefore, using Proposition 3.21 it is not true that x 7→ cos(nx), n ∈ N, converges pointwise on [0, π]. Notice that for any x ∈ [0, 2π], (lim inf n→
− ∞ gn )(x) = supn∈N (inf k≥n gk )(x).

3.5

Solution to exercises

Solution 3.1 (Solution to Exercise 3.1). Let ε > 0 and a = c. Then, for any n ∈ N,
|an − c| = 0 < ε. Thus, (an )n∈N is convergent with limit c.
Solution 3.2 (Solution to Exercise 3.2). The sequence (an )n∈N is not convergent. To see it,
assume by contradiction that (an )n∈N is convergent with limit a. Suppose that a ∈
/ {−1, 1}.
Then, since a ̸= 1 and a ̸= −1, it follows that |1−a| > 0. Thus, if ε < |1−a|, for any N ∈ N,
|an − a| = |1 − a| > ε for infinitely many n. Hence, it must be the case that a ∈ {−1, 1}.
Again, this not possible, since if for example a = 1, we have that |an − a| = 2 for infinitely
many n. A similar argument shows that a = −1 is also not possible. Hence, there is no
chance that (an )n∈N can be convergent.
Solution 3.3 (Solution to Exercise 3.3). Yes, (an )n∈N is convergent with limit 0. To see it,
we write
n2 + 3n3 + n
=
1 + n4

n2 +3n3 +n
n4
1+n4
n4

=

1
n2

We then remark that for any k ∈ N,
0≤

1
1
≤ .
nk
n

Thus, using Propositions 3.6 and 3.4,
lim an =

n→∞

0
= 0.
1

Solution 3.4 (Solution to Exercise 3.4). Since
0≤

n!
1
≤ ,
nn
n

it follows from Proposition 3.6 that limn→∞ an = 0.

31

+
1
n4

3
n

+ n13
.
+1

Solution 3.5 (Solution to Exercise 3.5). Let us first consider the case where (an )n∈N and
(bn )n∈N are both increasing. If both sequences converge, this is Proposition 3.5. The case
where (bn )n∈N converges but (an )n∈N does not is not possible by Proposition 3.7 and Proposition 3.2. If (bn )n∈N does not converge, it diverges to ∞ and we are left with two cases,
either (an )n∈N converges or it does not. In both cases it is clearly true that limn→∞ an ≤
limn→∞ bn , where we have equality when both series diverge (cf. Remark 3.1). The other
case, i.e., when (an )n∈N and (bn )n∈N are both decreasing is proved similarly. Here, it is
not possible that (an )n∈N converges but (bn )n∈N does not (cf. Propositions 3.7 and 3.2). If
both sequences diverge, we have equality in the limit and if (bn )n∈N converges but (an )n∈N
diverges, we have strict inequality in the limit, i.e., a < b.
Solution 3.6 (Solution to Exercise 3.6). Suppose by contradiction that inf{an : n ∈ N} >
−∞, i.e., there exists a real number M > 0 s.t. inf{an : n ∈ N} > −M . Since (an )n∈N is not
bounded from below, then, for any integer N ∈ N, there exists n(N ) ∈ N s.t. an(N ) < −N (cf.
Definition 3.3). Define the subsequence an(N ) , N ∈ N, where for any N ∈ N, an(N ) < −N .
Clearly, {an(N ) : N ∈ N} ⊂ {an : n ∈ N}, hence, by Proposition 1.9, for any integer k ∈ N,
−M < inf{an : n ∈ N} ≤ inf{an(N ) : n ∈ N} ≤ an(k) < −k.
Hence, we have deduced that there exists a real number M > 0 s.t. for any integer k ∈ N,
−M < −k. This gives a contradiction with Proposition 1.7. Hence, inf{an : n ∈ N} = −∞.
A similar argument shows that if (an )n∈N is not bounded from above, then sup{an : n ∈ N} =
∞.
Solution 3.7 (Solution to Exercise 3.7). Let n ∈ N. Write, {ak : k ≥ n} = {an } ∪ {ak : k ≥
n + 1}. Hence, {ak : k ≥ n + 1} ⊂ {ak : k ≥ n}. It follows that mn ≤ mn+1 (cf. Proposition 1.9).
Solution 3.8 (Solution to Exercise 3.8). Since {ak : k ≥ n + 1} ⊂ {ak : k ≥ n}, it follows
that Mn+1 ≤ Mn (cf. Proposition 1.9).
Solution 3.9 (Solution to Exercise 3.9). If S = supn∈N mn < ∞, define bn = S for any
n ∈ N. Then, mn ≤ bn for any n ∈ N and by Proposition 3.8, limn→∞ mn ≤ S. If S = ∞,
clearly, limn→
− ∞ mn ≤ S. For the other inequality, if S < ∞, by definition of supn∈N mn (cf.
Proposition 1.10), there exists n ∈ N, s.t. mn ≥ S − ε for any ε > 0. Thus we can again use
Proposition 3.8 to conclude that limn→
− ∞ mn ≥ S (take for example bn = S −(1/n)). For the
final case, suppose by contradiction that S = ∞ and limn→∞ mn < ∞. By Proposition 3.2,
this means that (mn )n∈N is bounded, i.e., there exists an upper bound for {mn : n ∈ N}.
This is not the case, as S = sup{mn : n ∈ N} = ∞ (cf. Definition 1.10). Hence, if S = ∞,
then limn→∞ mn = ∞.
Solution 3.10 (Solution to Exercise 3.10). If limn→∞ an = −∞, then (an )n∈N can not be
bounded from below. Therefore, by Definition 3.10, lim inf n→
− ∞ an = −∞. Further, (an )n∈N
must be bounded from above, since there exists N ∈ N, s.t. an ≤ 0 for any n ≥ N (cf. Definition 3.6) and for any n < N , we have that an ≤ max{ai : i = 1, . . . , N − 1} = M . In particular, an ≤ max{0, M }. Therefore, by Definition 3.10, lim supn→
− ∞ an = inf n∈N supk≥n ak .
We know that (Mn )n∈N = (supk≥n ak )n∈N is decreasing and limn→∞ Mn = lim supn→
− ∞ an
(cf. Proposition 3.19). Suppose by contradiction that (Mn )n∈N converges. Then, (Mn )n∈N is
bounded. That is, there exists L ∈ R s.t. Mn > L for any n ∈ N. Since limn→∞ an = −∞,
let N ∈ N s.t. an ≤ L for any n ≥ N (cf. Definition 3.6). Then, supk≥N ak = MN ≤ L.
This gives a contradiction, hence, (Mn )n∈N must diverge and hence by Proposition 3.9,
limn→∞ Mn = lim supn→
− ∞ an = −∞. Similarly, one can show that if limn→∞ an = ∞,
then lim inf n→
a
=
∞
= lim supn→
−∞ n
− ∞ an .
Solution 3.11 (Solution to Exercise 3.11). We have that |an | ≤ 1 for any n ∈ N. Thus,
(an )n∈N is bounded. Given any n ∈ N, inf k≥n ak = −1 and hence lim inf n→
− ∞ an = −1.
Further, for any n ∈ N, supk≥n ak = 1. Therefore, lim supn→
a
=
1
−∞ n
32

3.6

Additional exercises

Exercise 3.12. Let (an )n∈N ∈ RN be a convergent sequence. Show that limn→∞ an is
unique, i.e., if limn→∞ an = a and limn→∞ an = b, then a = b.
Exercise 3.13. Let (an )n∈N ∈ RN be a sequence. Show that:
n→∞

n→∞

n→∞

n→∞

(i) If an > 0 for any n ∈ N, then if an −−−−→ 0 it follows that 1/an −−−−→ ∞;
(ii) If an < 0 for any n ∈ N, then if an −−−−→ 0 it follows that 1/an −−−−→ −∞.
Exercise 3.14. Let a ∈ R and |r| < 1. We consider the sequence
sn =

n
X

ark = a + ar + ar2 + · · · + arn ,

n ∈ N.

k=0

Show that (sn )n∈N is convergent with limit a/(1 − r).
Hint: Compare sn and rsn .
Exercise 3.15. Let (an )n∈N ∈ RN be a bounded sequence. Show that
min{a : a is an accumulation point of (an )n∈N } = lim inf an .
n→
−∞
Exercise 3.16. Prove Proposition 3.25.

33

4

Measurable sets: Part I

4.1

Measurable spaces

Definition 4.1 (σ-field). Let Ω be a nonempty set. A family of subsets F of Ω is called a
σ-field on Ω if the following three items are satisfied:
(i) Ω ∈ F;
(ii) A ∈ F ⇒ Ac ∈ F;
(iii) if {Ai : i ∈ N} is a collection of sets s.t. Ai ∈ F for any i ∈ N, then ∪i∈N Ai ∈ F.
Example 4.1. Let Ω ̸= ∅ be an arbitrary set. Let
F = {∅, Ω}.
Then, F is a σ-field on Ω. Clearly, Ω ∈ F. Further, let A ∈ F. Then, there are only
two cases, either A = ∅ or A = Ω. In each case, Ac ∈ F. Consider a countable collection
{Ai : i ∈ N} ⊂ F. This collection is composed only of the sets Ai = ∅ or Ai = Ω, i ∈ N.
Thus (recall Exercise 1.3),
(
[
Ω, if ∃ i s.t. Ai = Ω,
Ai =
∅, otherwise.
i∈N
This, items (i), (ii) and (iii) of Definition 4.1 are satisfied and hence F is a σ-field. We
remark that F is referred to as the trivial σ-field. It is the smallest possible σ-field on Ω.
Example 4.2. Let Ω ̸= ∅ be an arbitrary set. Let F be the family which consists of all
possible subsets of Ω, i.e.,
F = {A : A ⊂ Ω}.
Then, F is a σ-field on Ω. Since Ω ⊂ Ω, Ω ∈ F. Let A ∈ F, then by definition, Ac =
Ω \ A ⊂ Ω and hence Ac ∈ F. Let {Ai : i ∈ N} ⊂ F. Then, by definition,
[
Ai = {ω ∈ Ω : ∃ i s.t. ω ∈ Ai } ⊂ Ω.
i∈N

Hence, F is a σ-field. The given σ-field F is referred to as the power set of Ω and denoted
with P(Ω) (or 2Ω ). It is the largest possible σ-field on Ω.
Example 4.3. Let Ω be an uncountable set. We consider the family
F = {A : A ⊂ Ω s.t. A is countable or Ac is countable}.
Then, F is a σ-field on Ω. We have that Ωc = ∅. We know that #∅ = 0, in particular ∅
is countable. Thus, Ω ∈ F. Let A ∈ F. Thus, A is countable or Ac is countable. Since
(Ac )c = A, Ac ∈ F. Let {Ai : i ∈ N} ⊂ F. If there exists j ∈ N s.t. Aj is not countable, we
have that
 [ c \
\
Ai =
Aci =
Aci ∩ Acj ⊂ Acj .
i∈N

i∈N

i∈N
i̸=j

Thus,
#

[

c
Ai

≤ #Acj ≤ #N,

i∈N

34

since Acj is countable. Hence (∪i∈N Ai )c is countable as well and therefore an element of
F. If for any i ∈ N, Ai is countable we rely on Proposition 2.7 and conclude that ∪i∈N Ai
must be countable as well and hence, ∪i∈N Ai ∈ F. Notice that since Ω is uncountable it is
not true that F = P(Ω) (cf. Example 4.2). As a simple example consider Ω = [0, 1), then
A = [0, 1/2) and Ac = [1/2, 0) are not countable.
Exercise 4.1. Let Ω ̸= ∅ be countable and define F as in Example 4.3. Is it true that
F = P(Ω)?
Exercise 4.2. Let Ω be a non empty set an F be a σ-field on Ω. Show that
(a) if {Ai : i ∈ N} ⊂ F, then ∩i∈N Ai ∈ F.
(b) if A ∈ F and B ∈ F then A \ B ∈ F;
Exercise 4.3. Let A ⊂ Ω, Ω ̸= ∅. Show that
{∅, A, Ac , Ω},
is a σ-field on Ω.
Example 4.4. Let Ω be a non empty set an F be a σ-field on Ω. Let Ω0 ⊂ Ω s.t. Ω0 ̸= ∅.
Then, the collection F ∩ Ω0 defined by
F ∩ Ω0 = {A ∩ Ω0 : A ∈ F},
is a σ-field on Ω0 . Clearly, Ω0 = Ω ∩ Ω0 ∈ F ∩ Ω0 . If B ∈ F ∩ Ω0 , then B = A ∩ Ω0 for
some A ∈ F. Then,
Ω0 \ B = (Ω0 \ A) ∪ (Ω0 \ Ω0 ) = Ω0 \ A = Ac ∩ Ω0 ∈ F ∩ Ω0 .
Suppose that {Bi : i ∈ N} ⊂ F ∩ Ω0 . Therefore, for any i ∈ N, Bi = Ai ∩ Ω0 for some
Ai ∈ F. Then, since ∪i∈N Bi = (∪i∈N Ai ) ∩ Ω0 , it follows that ∪i∈N Bi ∈ F ∩ Ω0 .
Example 4.5. Let Ω be an infinite set. Define the family
G = {A : A ⊂ Ω s.t. A is finite or Ac is finite}.
Then, G is not a σ-field on Ω. To see this, let {ωi : i ∈ N} be a countably infinite sequence of
distinct points of Ω. This is possible, since Ω is not finite. Define the set A = {ω2i : i ∈ N}.
Let Ai = {ω2i }, i ∈ N, be the singleton sets of A. Thus, A = ∪i∈N Ai . It is clear that
Ai ∈ G for any i ∈ N. It is also true that A ∈
/ G since A and Ac are both not finite
c
({ω2i+1 : i ∈ N} ⊂ A ). Therefore, G is not a σ-field on Ω.
Exercise 4.4. Let Ω ̸= ∅ be finite and define G as in Example 4.5. Is it true that G is a
σ-field on Ω?
Example 4.6. Let Ω = R and consider the family
R = {A : A = (a, b], a, b ∈ R} ∪ {∅}.
That is, the members of R are either the empty set or a left-open interval. The family R
is not a σ-field on R. To see it, if A = (a, b] ∈ R, then Ac = (−∞, a] ∪ (b, ∞) ∈
/ R. For
another way to see it, let x ∈ R. Then (cf. Exercise 4.1) we must have
\

x − n−1 , x ∈ R.
n∈N

But, we readily see that
\


x − n−1 , x = {x} ∈
/ R.

n∈N

35

(7)

In order to verify (7), we notice first that {x} ⊂ ∩n∈N (x − n−1 , x]. For the other inclusion,
let y ∈ ∩n∈N (x − n−1 , x]. Then y ∈ (x − n−1 , x] for any n ∈ N. That is, for any n ∈ N,
x−

1
< y ≤ x.
n

If we let an = x − n−1 , n ∈ N, and bn = x, n ∈ N, using Proposition 3.5, we have that
lim an = x ≤ y ≤ x.

n→∞

Hence, y = x and therefore ∩n∈N (x − n−1 , x] ⊂ {x}.
The next result is of general importance as it shows that even though a family of subsets
G might not be σ-field, one can always find a σ-filed which is the smallest possible σ-filed
that contains G.
Proposition 4.1. Let Ω ̸= ∅ and G be a family of subsets of Ω. Then, there exists a σ-field
σ(G) which satisfies:
(i) G ⊂ σ(G);
(ii) If G ⊂ U and U is a σ-field, then σ(G) ⊂ U.
To prove Proposition 4.1 we rely on the following result:
Proposition 4.2. Let Ω ̸= ∅ be a set. Let Fi , i ∈ I, be a collection of σ-fields on Ω over
an arbitrary set I. Then,
\
F=
Fi ,
i∈I

is a σ-field on Ω.
Exercise 4.5. Prove Proposition 4.2.
Proof of Proposition 4.1. We know that there exists at least one σ-field which contains G,
namely P(Ω). Thus, we define
\
σ(G) =
Fi ,
i∈I

where
{Fi : i ∈ I} = {U : U is a σ-field on Ω s.t. G ⊂ U}
Notice that the set I might not be countable. By Proposition 4.2, σ(G) is a σ-field. It
remains to show (i) and (ii) of Proposition 4.1. Since for each i ∈ I, G ⊂ Fi , it is not
possible that G is not a subset of σ(G) (see Exercise 1.8). With regard to (ii), let g ∈ σ(G)
and U be any σ-field which is s.t. G ⊂ U. Then, there exists j ∈ I s.t. U = Fj . Since
g ∈ σ(G), g ∈ Fi for any i ∈ I. In particular, g ∈ Fj . Thus, σ(G) ⊂ U.
The σ-field σ(G) of Proposition 4.1 is referred to as the σ-field generated by G.
Proposition 4.3. Let σ(G) be the σ-field generated by a family of subsets G of Ω. Let A be
another family of subsets of Ω. Then,
(a) if A is a σ-field s.t. G ⊂ A and A ⊂ σ(G), then A = σ(G).
(b) A ⊂ G ⇒ σ(A) ⊂ σ(G);
(c) A ⊂ G ⊂ σ(A) ⇒ σ(A) = σ(G);
36

Example 4.7. Let Ω ̸= ∅ and let G = {∅}. Then, σ(G) = {∅, Ω}, the trivial σ-field on Ω
(cf. Example 4.1). By (a) of Proposition 4.3 it is enough to show that {∅, Ω} ⊂ σ(G) since
{∅, Ω} is a σ-field that contains G. It is clear that {∅, Ω} ⊂ σ(G) since σ(G) is a σ-field,
hence it must contain Ω.
Example 4.8. Let Ω = {1, 2, 3} and define G = {{1}}. Clearly, σ(G) must contain {1}.
Since σ(G) is a σ-field, it must contain Ω and its complement ∅. Further, it must contain
the complement of {1}, i.e., it contains {1}c = {2, 3}. Thus, we claim that

σ(G) = ∅, {1}, {2, 3}, Ω .

By (a) of Proposition 4.3, if ∅, {1}, {2, 3}, Ω is a σ-field on Ω, the claim is true. This is
the case (cf. Exercise 4.3). Generally, upon Exercise 4.3, if A ⊂ Ω, then,
σ({A}) = {∅, A, Ac , Ω}.
We often omit the braces and use the notation σ(A) = σ({A}).
Example 4.9. Let Ω ̸= ∅ and
F = {A : A ⊂ Ω s.t. A is countable or Ac is countable},
i.e., F is the σ-field introduced in Example 4.3. We show that
F = σ(G),
where

G = {ω}, ω ∈ Ω .
Clearly G ⊂ F since each set {ω}, ω ∈ Ω, has cardinality one. Thus, it remains to show that
F ⊂ σ(G). Let A ∈ F. Then either A or Ac is countable. Suppose that A is countable, then
A = {ωi : i ∈ N},
for some collection of singletons ωi ∈ Ω, i ∈ N. Therefore, A = ∪i∈N {ωi } and thus A ∈ σ(G)
since {ωi } ∈ σ(G) for any i ∈ N and σ(G) is a σ-field. If Ac is countable, by the latter
argument, Ac ∈ σ(G). But then, (Ac )c = A ∈ σ(G). The set G is referred to as the pointpartition on Ω.
Exercise 4.6. Let Ω ̸= ∅ and
G = {A : A ⊂ Ω s.t. A is finite or Ac is finite},

i.e., G is the family introduced in Example 4.5. Let A = {ω} : ω ∈ Ω . Show that
(a) G ⊂ σ(A);
(b) σ(A) = G if Ω is finite.
Proposition 4.4. Let Ω be a non empty set an F be a σ-field on Ω. Let Ω0 ⊂ Ω s.t. Ω0 ̸= ∅.
Define F ∩ Ω0 as in Example 4.4 and assume F = σ(G) for some family G of subsets of Ω.
Then,
F ∩ Ω0 = σ({G ∩ Ω0 : G ∈ G}).
Proof. Given any G ∈ G, since F = σ(G), it follows that G ∩ Ω0 ∈ F ∩ Ω0 . That is F ∩ Ω0
is a σ-field on Ω0 that contains {G ∩ Ω0 : G ∈ G}. Since σ({G ∩ Ω0 : G ∈ G}) is the smallest
such σ-field, it follows that σ({G ∩ Ω0 : G ∈ G}) ⊂ F ∩ Ω0 . To make the notation easier, we
37

write σ({G ∩ Ω0 : G ∈ G}) = F0 . Hence, it remains to show that F ∩ Ω0 ⊂ F0 . Suppose
that A ∈ F implies that A ∈ {A ⊂ Ω : A ∩ Ω0 ∈ F0 }. Then, given any B ∈ F ∩ Ω0 , i.e.,
B = A ∩ Ω0 for A ∈ F, it follows that B ∈ F0 . Therefore, it is sufficient to show that
F ⊂ {A ⊂ Ω : A ∩ Ω0 ∈ F0 }. We set A = {A ⊂ Ω : A ∩ Ω0 ∈ F0 }. We notice first that
G ⊂ A, since any set G ∈ G is s.t. G ∩ Ω0 ∈ F0 by definition. If we show that A is a σ-field
on Ω, we are done, since then F = σ(G) ⊂ A. We notice that by definition F0 is a σ-field on
Ω0 , i.e., it contains Ω0 . Thus, Ω ∈ A since Ω ∩ Ω0 = Ω0 ∈ F0 . If A ∈ A, then A ∩ Ω0 ∈ F0
and hence Ω0 \ A ∩ Ω0 = Ω0 \ A ∈ F0 . Hence, Ω \ A is s.t. (Ω \ A) ∩ Ω0 = Ω0 \ A ∈ F0 .
Therefore, Ω \ A ∈ A. Suppose that {Ai : i ∈ N} ⊂ A. Then, Ai ∩ Ω0 ∈ F0 for any i ∈ N.
Therefore, ∪i∈N (Ai ∩ Ω0 ) = (∪i∈N Ai ) ∩ Ω0 ∈ F0 . That is, ∪i∈N Ai ∈ A.
Example 4.10. Let Ω = R and R be the family of left-open intervals with the empty set
adjoined (cf. Example 4.6). The σ-field B(R) = σ(R) is referred to as the Borel σ-field on
R.
Exercise 4.7. Let R′ = {(−∞, x] : x ∈ R}. Show that B(R) = σ(R′ ).
Example 4.11. Let Ω = Rk , k ∈ N. Given ai , bi ∈ R, i = 1, . . . , k, a set
k
Y

(ai , bi ],

i=1

is referred to as a rectangle on Rk . Define
k
Y

Rk = A : A =
(ai , bi ], ai , bi ∈ R, i = 1, . . . , k ∪ {∅},
i=1

i.e., the family of rectangles in Rk . Then, the σ-field B(Rk ) = σ(Rk ) is referred to as the
Borel σ-field on Rk .
Exercise 4.8. Let
R′k = {(−∞, x1 ] × · · · (−∞, xk ] : x = (x1 , . . . , xk ) ∈ Rk } ∪ {∅}.
Show that B(Rk ) = σ(R′k ).
Having in mind Example 4.4, we define the Borel σ-field restricted to a subset of Rk as
follows:
Definition 4.2. Let E ⊂ Rk , E ̸= ∅. The Borel σ-field on E is defined by
B(E) = B(Rk ) ∩ E = {A ∩ E : A ∈ B(Rk )}.
Then, using Proposition 4.4, we obtain that
Proposition 4.5. Given any E ⊂ Rk s.t. E ̸= ∅,
B(E) = σ({G ∩ E : G ∈ Rk }).
Definition 4.3. Let Ω ̸= ∅ and F be a σ-field on Ω. The pair (Ω, F) is referred to as a
measurable space. If A ∈ F, then A is said to be measurable. If A ⊂ F and A is a σ-field
on Ω, A is referred to as a sub-σ-field on Ω.

38

4.2

Solution to exercises

Solution 4.1 (Solution to Exercise 4.1). Yes, if Ω is countable, then F = P(Ω). This
follows from the fact that in this case, any set from P(Ω) is countable and hence a member
of F.
Solution 4.2 (Solution to Exercise 4.2). We have seen that (cf. Exercise 1.10) for any
n ∈ N,
[
c
n
n
\
Ai =
Aci .
i=1

i=1

Hence, (a) follows from (ii) and (iii) of Definition 4.1. With regard to (b), using Proposition 1.4, A \ B = A ∩ B c and thus (b) follows from (a) and (ii) of Definition 4.1.
Solution 4.3 (Solution to Exercise 4.3). Let F = {∅, A, Ac , Ω}. We need to verify items
(i), (ii) and (iii) of Definition 4.1. Items (i) and (ii) are clearly satisfied. Since F only
contains 4 sets, we can argue case by case. Let k ∈ {2, 3} and
k
\

Ai k ,

ik =1

be any intersection of subsets Aik ∈ F. Clearly, for any k, if Aik = ∅ for some ik ,
∩kik =1 Aik = ∅ ∈ F. Thus, we have that for any k = 2, 3,
(
k
\
∅,
if ∃ ik s.t. Aik = ∅,
Ai k = T k
1
A
,
otherwise,
ik =1 ik
i =1
k

where A1ik are updated in the sense that
subsets of {A, Ac , Ω},


k
A,
\
A1ik = Ac ,


ik =1
∅,

A1ik ∈ {A, Ac , Ω}. If k = 2, i.e., we intersect two
if A1ik ∈ {A, Ω}, ik = 1, 2
if A1ik ∈ {Ac , Ω}, ik = 1, 2
if A1ik ∈ {Ac , A}, ik = 1, 2.

Otherwise, if k = 3, ∩kik =1 Aik = ∅, since A ∩ Ac = ∅. This shows that any possible
intersection of sets from F is again a member of F. Therefore, since for any k ∈ {2, 3},
k
[
ik =1

Aik =

 \
k

Acik

c
,

ik =1

item (iii) is satisfied.
Solution 4.4 (Solution to Exercise 4.4). Yes, if Ω is finite, then G = P(Ω). This follows
from the fact that in this case, any set from P(Ω) is finite and hence a member of G.
Solution 4.5 (Solution to Exercise 4.5). We need to verify items (i), (ii) and (iii) of
Definition 4.1. Since Ω ∈ Fi for any i ∈ I, Ω ∈ F = ∩i∈I Fi by definition. Also, if A ∈ F,
then A ∈ Fi for any i ∈ I. In particular, Ac ∈ Fi for any i ∈ I. Thus, Ac ∈ F. If
{An : n ∈ N} ⊂ F we have that {An : n ∈ N} ⊂ Fi for any i ∈ I (cf. Exercise 1.8). Thus,
∪i∈I Ai ∈ Fi for any i ∈ I. Hence, ∪i∈I Ai ∈ F.
Solution 4.6 (Solution to Exercise 4.6). Item (a) follows from the fact that σ(A) is a σfield: If A ∈ G, then since either A or Ac is finite, either of the two is a countable union of
elements from A, i.e., A ∈ σ(A). With regard to (b), it remains to show that σ(A) ⊂ G if
Ω is finite. This is certainly true since in this case G = P(Ω).
39

Solution 4.7 (Solution to Exercise 4.7). We show that σ(R) contains R′ (⇒ σ(R′ ) ⊂ σ(R))
and σ(R′ ) contains R (⇒ σ(R) ⊂ σ(R′ )). Let x ∈ R, then, (−∞, x] = ∪n∈I (−n, x] ∈ σ(R),
where I = {n ∈ N : − n < x}. Let (a, b] ∈ R, then (a, b]c = (−∞, a] ∪ (b, ∞) = (−∞, a] ∪
(−∞, b]c ∈ σ(R′ ).
Solution 4.8 (Solution to Exercise 4.8). The inequality σ(R′k ) ⊂ σ(Rk ) follows from the
fact that for any x = (x1 , . . . , xk ) ∈ Rk ,

[
(−∞, x1 ] × . . . × (−∞, xn ] =
(−n, x1 ] × . . . × (−n, xn ] ,
n∈I

where I = {n ∈ N : − n < min{xi : i = 1, . . . , k}}. For the other inequality, let A =
Qk
i=1 (ai , bi ] ∈ Rk . Consider the sets (−∞, bi ], i = 1, . . . , k. Define the sets
Si = (−∞, b1 ] × · · · × (−∞, ai ] × · · · × (−∞, bk ],
| {z }

i = 1, . . . , k.

Position i

Then,
A=

Y
k

 [

k
(−∞, bi ] \
Si .

i=1

i=1

To see it, we notice that by Proposition 1.3,
Y
k



 [
 \
k
k
k  Y
(−∞, bi ] \ Si
Si =
(−∞, bi ] \
i=1

i=1

i=1

i=1

Then, we have that for any i = 1, . . . , k,
Y
k



Y
k
(−∞, bi ] ∩ Sic = (−∞, b1 ] × · · · × (ai , bi ] × · · · × (−∞, bk ].
(−∞, bi ] \ Si =
| {z }
i=1

i=1

Position i

Thus,
k 
\
i=1


(−∞, b1 ] × · · · × (ai , bi ] × · · · × (−∞, bk ] = A,
| {z }
Position i

as desired. Now,
Y
k

 [

k
(−∞, bi ] \
Si ∈ σ(R′k ).
i=1

i=1

σ(R′k )

Hence,
is another σ-field which contains sets of the form A. We know that σ(Rk ) is
the smallest such σ-field. Hence, σ(Rk ) ⊂ σ(R′k ).

4.3

Additional exercises

Exercise 4.9. Let f : X → Y be a function and B be a σ-field on Y . Show that
σ(f ) = {f −1 (B) : B ∈ B},
is a σ-field on X. σ(f ) is referred to as the σ-field generated by f .
Exercise 4.10. Find an example of a set Ω ̸= ∅ and two σ-fields F1 and F2 on Ω s.t. the
union F1 ∪F2 is not a σ-field on Ω. This shows that in contrast to the intersection of σ-fields
(cf. Proposition 4.2), the union of σ-fields is not necessarily a σ-field.
Hint: Example 4.8.
40

Exercise 4.11. Let Ω = [0, 1] and G = {[0, 1/2], [1/2, 1]}. Find σ(G).
Exercise 4.12. Let Ω = R, equipped with the Borel σ-field B(R) (cf. Example 4.10). Show
that
σ(R∗ ) = B(R),
where
R∗ = {A : A = [a, b), a, b ∈ R} ∪ {∅},
i.e., the right-open intervals with the empty set adjoined.
Exercise 4.13. We remain in the setting of Exercise 4.12. Show that
B(R) = σ(R∗∗ ),
where
R∗∗ = {A : A = (q1 , q2 ], q1 , q2 ∈ Q} ∪ {∅},
i.e., the left-open intervals with rational end-points and the empty set adjoined.
Hint: Recall Example 3.4.

41

5

Measurable sets: Part II

5.1

Measure spaces

Definition 5.1. Let (Ω, F) be a measurable space. A function µ : F → R+ is said to be a
measure on F if the following two items are satisfied:
(i) µ(∅) = 0;
(ii) Given any disjoint family {Ai : i ∈ N} of measurable sets (i.e., {Ai : i ∈ N} ⊂ F),
[  X
µ
Ai =
µ(Ai ).
i∈N

i∈N

Example 5.1. Let (Ω, F) be a measurable space and x ∈ Ω be a given point of Ω. Define
the function
(
1, if x ∈ A,
δx (A) =
0, if x ∈
/ A.
Then, A 7→ δx (A) is a measure on F. From the definition of δx , we immediately see that
δx (∅) = 0. Let {Ai : i ∈ N} ⊂ F be disjoint and set A = ∪P
/ A (i.e., x ∈ ∩i∈N Aci ),
i∈N Ai . If x ∈
there does not exists i s.t. x ∈ Ai , hence δx (A) = 0 = i∈N δx (Ai ). Otherwise, if x ∈ A,
since {Ai : i ∈ N} is disjoint, there exists a unique j ∈ N, s.t. x ∈ Aj . Hence also in this
case
X
δx (A) = 1 = δx (Aj ) =
δx (Ai ).
i∈N

Example 5.2. We consider the measurable space (Ω, P(Ω)), where Ω is a finite set and
P(Ω) is the power set of Ω (cf. Example 4.2). Define µ(A) = #A, A ∈ P(Ω). Then, µ is
a measure on F. Clearly, for any A ∈ P(Ω), µ(A) ≥ 0. We need to verify (i) and (ii) of
Definition 5.1. Since #∅ = 0, (i) is satisfied. Let {Ai : i ∈ N} ⊂ P(Ω) be disjoint. Naturally,
since {Ai : i ∈ N} is a disjoint family of sets, the cardinality of its union is the sum of the
individual set cardinalities. Let us show it. Clearly, since Ω is finite, the sets Ai , i ∈ N, and
A = ∪i∈N Ai ⊂ Ω are all finite sets. Let I1 be s.t. Ai = ∅ for any i ∈ I1 and I2 = N \ I1 ,
i.e., Ai ̸= ∅ for any i ∈ I2 . Then, since A is finite, I2 must be finite as well. That is,
Ai ̸= ∅ only for finitely many i. Then, for any i ∈ I2 , let Ai = {xi1 , . . . , xini }, ni ∈ N.
Since {Ai : i ∈ I2 } is disjoint,
[ 
[
X
X
µ
Ai = #
Ai =
#{xik : k = 1, . . . , ni } =
µ(Ai ).
i∈I2

i∈I2

i∈I2

i∈I2

In conclusion, we obtain that
[
[ 
µ(A) = µ
Ai ∪
Ai
i∈I1

i∈I2

[ 
=µ
Ai
i∈I2

=

X

µ(Ai )

i∈I2

=

X

µ(Ai ) +

i∈I1

X
i∈I2

We can generalize the previous example.
42

µ(Ai ) =

X
i∈N

µ(Ai ).

Example 5.3. Consider the measurable space (Ω, P(Ω)), where P(Ω) is the power set of Ω
and Ω is not necessarily finite. Define
(
#A, if A ∈ P(Ω) s.t. A is finite,
µ(A) =
∞
otherwise.
Then, µ is a measure on P(Ω). We have already seen in the previous example that (i) of
Definition 5.1 is satisfied. Thus, let {Ai : i ∈ N} ⊂ P(Ω) be disjoint. Suppose that there
exists j ∈ N s.t. Aj is not finite. Then,
[ 
X
µ
Ai = ∞ =
µ(Ai ).
i∈N

i∈N

Thus, it remains to show (ii) for the case where Ai is finite for any i ∈ N. Given i ∈ N,
let Ai = {xi1 , . . . , xini }, ni ∈ N. Set Un = ∪ni=1 Ai and A = ∪i∈N Ai . As in the previous
example, since the family {Ai : i ∈ N} is disjoint, we have that for any n ∈ N,
µ(Un ) = #{xik : k = 1, . . . , ni , 1 ≤ i ≤ n} =

n
X

#{xik : k = 1, . . . , ni } =

i=1

n
X

µ(Ai ).

i=1

We show that
lim µ(Un ) = µ(A),

n→∞

(8)

then, (ii) of Definition 5.1 is verified. There are two cases, either A is finite or not. If A is
finite, we repeat the arguments from Example 5.1 and obtain
X
µ(A) =
µ(Ai ).
i∈N

Thus, if we show (8) for the case wehen A is not finite, we are done. If A is not finite, then,
for any N ∈ N, there exists an integer n ≥ N , s.t. An is not the empty set. In particular,
for any N ∈ {n ∈ N : n ≥ 2} there exists an integer n ≥ N s.t. #Un − #Un−1 = #An = mn
for some positive integer mn . Hence, we let n1 ∈ N be s.t.
#Un1 = #Un1 −1 + mn1 ,

n1 ≥ 1 + 1.

#Un2 = #Un2 −1 + mn2 ,

n2 ≥ n1 + 1.

Then, we let n2 be s.t.

We continue like that and let nk , k ∈ N, be s.t.
#Unk = #Unk −1 + mnk ,

nk ≥ nk−1 + 1.

Now we note that for any n ∈ N, #Un ≤ #Un+1 , i.e., (#Un )n∈N is increasing. Therefore,
#Unk = #Unk −1 + mnk ≥ #Unk−1 +1−1 + mnk = #Unk−1 + mnk
= #Unk−1 −1 + mnk−1 + mnk .
This shows that for any k ∈ N,
#Unk ≥ #Un1 −1 +

k−1
X
i=0

43

mnk−i .

Pk−1
Hence, given any M ∈ R, if we let k ∈ N be large enough s.t. #Un1 −1 + i=0 mnk−i ≥ M ,
we have that #Un ≥ M for any n ≥ nk . Finding such an integer k is certainly possible,
since #Un1 −1 is a finite number and
k−1
X
i=0

mnk−i ≥ 1 + · · · + 1 = k.
| {z }
k-times

In Particular, for any M ∈ R there exists N = nk ∈ N s.t. #Un ≥ M for any n ≥ N .
Hence, by Definition 3.6, limn→∞ #Un = limn→∞ µ(Un ) = ∞. Clearly, by definition of µ,
since A is not finite, µ(A) = ∞. This shows (8) and completes the argument. The measure
µ is called the counting measure.
Let us also consider a more general version of Example 5.1.
Example 5.4. Let (Ω, F) be a measurable space, I be a countable set and E = {xi : i ∈
I} ⊂ Ω be a collection of points in Ω. Assume that αi , i ∈ I, are s.t. αi ∈ [0, ∞) for any
i ∈ I. Define
X
X
µ(A) =
αi δxi (A) =
αx δx (A), A ∈ F,
i∈I

x∈E

where for any i ∈ I,
(
δxi (A) =

if xi ∈ A,
if xi ∈
/ A.

1,
0,

Then, µ is a measure on F. It is clear that (i) of Definition 5.1 is satisfied. Let {Ak : k ∈
N} ⊂ F be disjoint and set A = ∪k∈N Ak . We need to verify that
X
µ(A) =
µ(Ak ).
k∈N

Certainly, this is true if for any i ∈ I, xi ∈
/ A. Assume that there exists i ∈ I s.t. xi ∈ A.
Let us label these i’s, i.e., i1 is s.t. xi1 ∈ A, i2 is s.t. xi2 ∈ A and so on to obtain a family
{xij : j ∈ J}, where the set J is s.t. J ⊂ I and for any j ∈ J, xij ∈ A. We assume that
any x ∈ {xi : i ∈ I} \ {xij : j ∈ J} is s.t. x ∈
/ A. Otherwise, we can always enlarge the set
J. Then, since {Ak : k ∈ N} is disjoint, for each j ∈ J, there exists a unique kj ∈ N s.t.
xij ∈ Akj . Therefore,
X
µ(A) =
αi δxi (A)
i∈I

X

=
X

αx δx (A)

x∈{x
/ ij : j∈J}

x∈{xij : j∈J}

=

X

αx δx (A) +

αij δxij (A)

j∈J

=

X

αij δxij (Akj ) =

j∈J

αij .

j∈J

Then, we notice that if k ∈ N,
X
αi δxi (Ak ) =
i∈I

X

X

αx δx (Ak ) +

x∈{x
/ ij : j∈J}

x∈{xij : j∈J}

X

=

αx δx (Ak )

x∈{xij : j∈J}

=

X

X

αij δxij (Ak ).

j∈J

44

αx δx (Ak )

Hence, since for any j ∈ J,

P

X

k∈N δxij (Ak )

µ(Ak ) =

k∈N

= δxij (Akj ) = 1,

XX
i∈I

k∈N

=

XX

=
=

X


αij δxij (Ak )

j∈J

k∈N

X


αi δxi (Ak )

αij

X

j∈J


δxij (Ak )

k∈N

αij δxij (Akj ) =

j∈J

X

αij .

j∈J

P
It is important to remark that since αij δxij (Ak ) = ak,j ≥ 0, the double sum (k,j)∈N×J ak,j
is well defined and we are allowed to interchange the order of summation (cf. Proposition 3.11). Clearly, if I is finite, µ(A) < ∞ for any A ∈PF. If I is countably infinite, we
have that #I = #N and hence, for any A ∈ F, µ(A) = n∈N αn δxn (A). Therefore, since
αi P
δxi (A) ≤ αi and αi ≥ 0, if follows from Proposition 3.10 that µ(A) < ∞ for any A ∈ F
if i∈I αi < ∞.
Exercise 5.1. Consider
P the measurable space (R, B(R)), where B(R) is the Borel σ-field
on R. Define µ(B) = n∈B∩N 2−n , B ∈ B(R). Is µ a measure on B(R)?
Exercise 5.2. Let E = {0, 1}, p ∈ (0, 1) and set p0 = 1 − p and p1 = p. Define the function
X
P (B) =
px , B ∈ B(R).
x∈E∩B

That is,

0,



1 − p,
P (B) =

p,



1,

if
if
if
if

0∈
/B
0∈B
0∈
/B
0∈B

and
and
and
and

1∈
/ B,
1∈
/ B,
1 ∈ B,
1 ∈ B.

Is P is a measure on B(R)?
Example 5.5. Consider the measurable space (R, B(R)), where B(R)) is the Borel σ-field
on R (cf. Example 4.6 and 4.10). Then, there exists a unique measure λ on (R, B(R)) s.t. for
any left-open interval (a, b], a, b ∈ R, λ((a, b]) returns the length of (a, b], i.e., λ((a, b]) = b −
a. The measure λ is referred to as the Lebesgue measure on B(R). An explicit construction
of λ is given in the next section.
In the following we list some general properties of measures.
Proposition 5.1. Let (Ω, F) be a measurable space and µ be a measure on F. Then,
(i) given n ∈ N and {Ai : 1 ≤ i ≤ n} ⊂ F disjoint, it follows that
[
 X
n
n
µ
Ai =
µ(Ai );
i=1

i=1

(ii) if A, B ∈ F s.t. A ⊂ B it follows that µ(A) ≤ µ(B);
(iii) if A, B ∈ F s.t. A ⊂ B and µ(A) < ∞ it follows that µ(B \ A) = µ(B) − µ(A);
(iv) given A, B ∈ F, µ(A) + µ(B) = µ(A ∪ B) + µ(A ∩ B);
45

(v) if {Ai : i ∈ N} ⊂ F is s.t. Ai ⊂ Ai+1 ,
[

[ 
n
µ
Ai = µ(An ) ↑ µ
Ai ;
i=1

i∈N

(vi) if {Ai : i ∈ N} ⊂ F is s.t. µ(A1 ) < ∞ and Ai+1 ⊂ Ai ,
\

\ 
n
µ
Ai = µ(An ) ↓ µ
Ai .
i=1

i∈N

(vii) if {Ai : n ∈ N} ⊂ F,
[  X
µ
Ai ≤
µ(Ai );
i∈N

i∈N

Proof of item (v) of Proposition 5.1. Let B1 = A1 , B2 = A2 \ A1 and so on until we set for
any i ∈ N, Bi = Ai \ Ai−1 . It is true that for any i ̸= j, Bi ∩ Bj = ∅. Either, i < j, and then
Bi = Ai \ Ai−1 ⊂ Ai ⊂ Aj−1 ⊂ (Acj ∪ Aj−1 ) = (Aj ∩ Acj−1 )c = (Aj \ Aj−1 )c = Bjc ,
or j > i and then Bj ⊂ Bic . Thus, The family {Bi : i ∈ N} is disjoint. By item (ii) of
Definition 5.1,
[  X
µ
Bi =
µ(Bi ),
i∈N

i∈N

and hence,
n
X

[ 
Bi .
µ(Bi ) ↑ µ

i=1

Further, for any n ∈ N,
definition, B1 = A1 . Then,

∪ni=1 Bi

n+1
[

Bi =

n
[

=

i∈N

∪ni=1 Ai .

Ai ∪ Bn+1 =

=

n−1
[

n
[

Ai ∪ An+1 \ An

i=1

i=1

i=1

To see it, we use an argument by induction. By

Ai ∪ An ∪ An+1 \ An =

n−1
[

Ai ∪ An ∪ An+1 .

i=1

i=1

Therefore, since for any i ∈ N, Ai ⊂ Ai+1 , it follows that ∪ni=1 Bi = An . In conclusion, since
[

Ai =

i∈N

[

An =

n∈N

n
[ [
n∈N


Bi

i=1

=

[

Bi ,

i∈N

we have under application of item (i) of Proposition 5.1,
[
 X
[ 
[ 
n
n
µ(An ) = µ
Bi =
µ(Bi ) ↑ µ
Bi = µ
Ai .
i=1

i=1

i∈N

46

i∈N

Proof of item (vii) of Proposition 5.1. Let B1 = A1 , B2 = A2 \ A1 , B3 = A3 \ A1 ∪ A2 , and
so on s.t. for any i ∈ N,
B i = Ai \

i−1
[

Ak .

k=1

We notice that for i ̸= j, Bi ∩ Bj = ∅ since either i < j and hence
j−1
c
c
Bi = Ai \ ∪i−1
k=1 Ak ⊂ Ai ⊂ ∪k=1 Ak ∪ Aj = Bj ,

or j < i and then Bj ⊂ Bic . Hence, the family {Bi : i ∈ N} is disjoint. Further, we note that
for any n ∈ N,
n
[

Bi =

i=1

n
[

Ai .

i=1

To see it, we can use an argument by induction. We have that A1 = B1 . Then, assume that
∪ni=1 Bi = ∪ni=1 Ai . It follows that
n+1
[

Bi =

[
n


Bi

∪ Bn+1 =

i=1

i=1

[
n


Ai

∪ Bn+1 =

i=1

n
[


 n+1
n
[
[
Ai ∪ An+1 \
Ai =
Ai .

i=1

i=1

i=1

Therefore, by item (i) of Proposition 5.1, we have that for any n ∈ N,
[

[
 X
n
n
n
n
X
Ai = µ
Bi =
µ
µ(Bi ) ≤
µ(Ai ),
i=1

i=1

i=1

(9)

i=1

where we used that for any 1 ≤ i ≤ n, Bi ⊂ Ai and hence µ(Bi ) ≤ µ(Ai ) by (ii) of
Proposition 5.1. To conclude, we define Cn = ∪ni=1 Ai and obtain Cn ⊂ Cn+1 and hence
[

[ 
n
Ai ↑ µ
µ
Ai ,
i=1

i∈N

by (v) of Proposition 5.1. This concludes the argument (cf. Proposition 3.8).
Exercise 5.3. Prove items (i), (ii), (iii) and (iv) of Proposition 5.1.
Remark 5.1. We remark that item (iv) of Proposition 5.1 can be stated more generally for
a finite collection of sets with finite measure (the details are given in Section B.1).
Definition 5.2. Let (Ω, F) be a measurable space and µ be a measure on F. The triple
(Ω, F, µ) is referred to as a measure space.

5.2

Semirings

Definition 5.3. Let Ω be a nonempty set. A family of subsets A of Ω is said to be a
semiring on Ω if
(i) ∅ ∈ A;
(ii) A, B ∈ A ⇒ A ∩ B ∈ A;
(iii) if A, B ∈ A and A ⊂ B, then there exists a disjoint collection of sets {C1 , . . . , Cn } ⊂ A
s.t. B \ A = ∪nk=1 Ck .

47

Example 5.6. We have seen in Example 4.6 that the family of left-open intervals
R = {A : A = (a, b], a, b ∈ R} ∪ {∅},
is not a σ-field on R. Still, it is a semiring on R. By definition, ∅ ∈ R. Let A, B ∈ R, i.e.,
A = (a1 , a2 ] and B = (b1 , b2 ]. If A ∩ B = ∅, then A ∩ B ∈ R. Otherwise,
A ∩ B = (max{a1 , b1 }, min{a2 , b2 }].
Thus, item (ii) of Definition 5.3 is satisfied. With regard to (iii), let A, B ∈ R s.t. A ⊂ B.
If A = B = ∅, then A \ B = ∅ and with C = ∅, the result follows. Similarly, if A = B, the
result follows with C = ∅. If B ̸= ∅ but A = ∅, then B \ A = B and with C = B, the result
follows. Thus, suppose that A, B ̸= ∅, A ⊂ B and A ̸= B, i.e., b1 < a1 and a2 < b2 . We
have that B \ A = (b1 , a1 ] ∪ (a2 , b2 ]. Hence, with C1 = (b1 , a1 ] and C2 = (a2 , b2 ], the result
follows.
Example 5.7. Let Ω be an infinite set and consider the family
G = {A : A ⊂ Ω s.t. A is finite or Ac is finite}.
Then, G is not a σ-field on Ω (cf. Example 4.5). However, G is a semiring on Ω.

5.3

Solution to exercises

Solution 5.1 (Solution to Exercise 5.1). Notice that we can write for any B ∈ B(R),
X
X
X
X
µ(B) =
2−n δn (B) =
2−n δn (B) +
2−n δn (B) =
2−n δn (B).
n∈B∩N

n∈B c ∩N

n∈B∩N

n∈N

Thus, µ isPa measure on B(R) (cf. Example 5.4). We remark that upon Exercise 3.14, we
have that n∈N 2−n = 1. That is, µ(A) < ∞ for any A ⊂ B(R).
Solution 5.2 (Solution to Exercise 5.2). We set α0 = 1 − p and α1 = p and obtain that for
any B ∈ B(R),
X
X
αx δx (B) =
px .
x∈E

x∈E∩B

Thus, P is a measure on B(R) (cf. Example 5.4). We remark that

P

x∈E

px = 1.

Solution 5.3 (Solution to Exercise 5.3).
(i) We define Ai = ∅ for any i > n and the statement is verified as a consequence of (i)
and (ii) in Definition 5.1.
(ii) In general, A ∪ B = A ∪ (B \ A). Sine A ⊂ B, it follows that B = A ∪ (B \ A). Hence
by (i), µ(B) = µ(A) + µ(B \ A). Since µ(B \ A) ≥ 0, the result follows. Notice that
µ(A) = ∞ is possible.
(iii) As with the previous solution, µ(B) = µ(A) + µ(B \ A). Now, since µ(A) < ∞, we
obtain µ(B) − µ(A) = µ(B \ A).
(iv) We write A ∪ B = (A \ B) ∪ (B \ A) ∪ (A ∩ B). Then, since {A \ B, B \ A, A ∩ B} is
disjoint, it follows that
µ(A ∪ B) = µ(A \ B) + µ(B \ A) + µ(A ∩ B)
Similarly, since A ∩ B is a subset of both, A and B, we write
A = (A \ (A ∩ B)) ∪ (A ∩ B) = (A \ B) ∪ (A ∩ B).
48

and
B = (B \ (A ∩ B)) ∪ (A ∩ B) = (B \ A) ∪ (A ∩ B).
Hence,
µ(A) + µ(B) = µ(A \ B) + µ(B \ A) + 2µ(A ∩ B) = µ(A ∪ B) + µ(A ∩ B).

5.4

Additional exercises

Exercise 5.4. Suppose that E ⊂ R is a countable set. Let f : E → [0, ∞) be a function and
define
X
µ(B) =
f (x), B ∈ B(R).
x∈E∩B

Verify that µ is a measure on B(R).
Exercise 5.5. Let E = {0, 1, . . . , n}, n ∈ N, and p ∈ (0, 1). For any k ∈ E, let
 
n k
pk =
p (1 − p)n−k .
k
Define the function
P (B) =

X

pk ,

B ∈ B(R).

k∈E∩B

Is P a measure on B(R)?
Exercise 5.6. Let (Ω, F) be a measurable space and µ : F → R+ be a function s.t. µ(∅) = 0.
Suppose that
Pn
• For any finite disjoint collection {Ai : i = 1, . . . , n} ⊂ F, µ(∪ni=1 Ai ) = i=1 µ(Ai ) (µ
is finitely additive on F);
P∞
• for any collection {Ai : i ∈ N} ⊂ F, µ(∪∞
i=1 Ai ) ≤
i=1 µ(Ai ) (µ is countable subadditive on F).
Show that µ is a measure on F.
Exercise 5.7. Show that the family
G = {A : A ⊂ Ω s.t. A is finite or Ac is finite},
of Example 5.7 is a semiring on Ω.
Exercise 5.8. Prove item (vi) of Proposition 5.1.

49

6

Measurable sets: Part III

A selection of omitted proofs of this chapter are found in Section B.2 of the appendix.

6.1

The Lebesgue measure

The main result of this chapter is the following proposition:
Proposition 6.1. There exists a measure λ on B(R) (referred to as the Lebesgue measure
on B(R)) which is s.t.
for any left-open interval (a, b], λ returns its length, i.e., λ((a, b]) = b − a.

(10)

Further, λ is the unique measure on B(R) which satisfies (10).
The intention of this chapter is to explore the tools that provide arguments for the latter
proposition.

6.2

Measure extensions

Proposition 6.2. Let (a, b], a < b ∈ R, be any left-open interval. Let I be countable and
(ai , bi ], i ∈ I, be s.t., (a, b] ⊂ ∪i∈I (ai , bi ], then
X
b−a≤
(bi − ai ).
(11)
i∈I

If the collection {(ai , bi ] : i ∈ I} is disjoint we also have the following result (Exercise 6.10).
Proposition 6.3. Let (a, b], a < b ∈ R, be any left-open interval. Let I be countable and
{(ai , bi ] : i ∈ I} be a disjoint collection of left-open intervals s.t. ∪i∈I (ai , bi ] ⊂ (a, b]. Then
X
(bi − ai ) ≤ b − a.
i∈I

Definition 6.1. Let Ω ̸= ∅ be a set and A be a collection of subsets from Ω. Let A ∈ P(Ω)
be any subset of Ω. A collection {Ui : i ∈ I} is said to be a covering of A by sets from A if
{Ui : i ∈ I} ⊂ A and A ⊂ ∪i∈I Ui . A covering {Ui : i ∈ I} of A by sets from A is referred to
as countable (resp. finite) if I is countable (resp. finite). We write CA (A) for the set which
contains all the countable coverings of A by sets from A, i.e.,
CA (A) = {ξ : ξ is a countable covering of A by sets from A}.
Example 6.1. Consider the setting of Example 4.6 and let Ω = R and R be the family of
left-open intervals with the empty set adjoined:
R = {A : A = (a, b], a, b ∈ R} ∪ {∅}.
Let Br (x) be any open ball with center x ∈ R and radius r > 0. That is, Br (x) = (x −
r, x + r) is an open interval with endpoints a = x − r and b = x + r. Consider the set
ξ1 = {(a, x], (x, b]}. Then, ξ1 ∈ CR ((a, b)). As another example, let for n ∈ N,


2r(i + 1)
2ri
, i = 0, . . . 2n − 1.
Uin = a + n , a +
2
2n
Then, ξ2 = {Uin : i = 0, . . . 2n − 1} ∈ CR ((a, b)) for any n ∈ N. As a final example, define


a b
Uk =
,
, k ∈ N ∪ {0}.
2k 2k
50

Then, ξ3 = {Uk : k ∈ N ∪ {0}} ∈ CR ((a, b)). Each of the coverings ξ1 , ξ2 and ξ3 of (a, b) by
sets from R offers an approach to quantify the length of (a, b) by summing up the
Prespective
lengths of the sets from R. Given A ∈ P(R), we define the function vℓ (ξ) = U ∈ξ ℓ(U ),
ξ ∈ CR (A) where ℓ : R → [0, ∞) is s.t.
(
b − a, if U = (a, b],
ℓ(U ) =
0,
if U = ∅.
As an example, we have that vℓ (ξ1 ) = x − a + b − x = b − a. Notice also, that
vℓ (ξ2 ) =

n
2X
−1

i=0

2r(i + 1) − i
2n

2r
4r
2r
6r
4r
2r(2n − 1)
2r(2n − 1)
= n + n − n + n − n + ··· +
+
2r
−
2
2
2
2
2
2n
2n
= 2r = b − a.
Exercise 6.1. Verify that vℓ (ξ3 ) = 2(b − a).
In the following we show that
inf{vℓ (ξ) : ξ ∈ CR ((a, b])} =

inf
ξ∈CR ((a,b])

vℓ (ξ) = b − a,

(12)

i.e., b − a is a lower bound for the values of vℓ (ξ), ξ ∈ CR ((a, b]).
Exercise 6.2. Verify that inf ξ∈CR ((a,b]) vℓ (ξ) ≤ b − a.
Upon the later exercise, it remains to show that b − a ≤ inf ξ∈CR ((a,b]) vℓ (ξ). Let ξ be any
countable covering of (a, b] by sets from R. That is, ξ = {Ui : i ∈ I}, with Ui = (ai , bi ] or
Ui = ∅, i ∈ I, where I is countable. Since ℓ(∅) = 0, we assume without loss of generality
that
P Ui = (ai , bi ] for any i ∈ I. Therefore, we have that (a, b] ⊂ ∪i∈I (ai , bi ] and vℓ (ξ) =
i∈I (bi − ai ). Since I is countable, either I is finite or #I = #N. Using Proposition 6.2
we obtain,
X
b−a≤
(bi − ai ) = vℓ (ξ).
i∈I

It follows that b − a ≤ inf ξ∈CR ((a,b]) vℓ (ξ). We also saw that there exists ξ ∈ CR ((a, b]) s.t.
b − a = vℓ (ξ). Hence, the latter infimum is actually a minimum. In conclusion we have
proven the following result.
Proposition 6.4. Given any left-open interval (a, b], minξ∈CR ((a,b]) vℓ (ξ) = b − a.
We build on the latter result and define the function
ℓ∗ (A) =

inf
ξ∈CR (A)

vℓ (ξ),

A ∈ P(R).

Exercise 6.3. Verify that ℓ∗ ({a}) = 0 for any point a ∈ R.
The given examples show that the function P(R) ∋ A 7→ ℓ∗ (A) is in alignment with our
intuitive understanding of the length of an interval. However, we will see in the following
that ℓ∗ is not a measure on P(R). Nevertheless, we will show that it is always possible to
restrict ℓ∗ to σ(R) ⊂ P(R) to obtain a measure λ on σ(R) = B(R) which agrees with ℓ on R.
This measure λ will be referred to as the Lebesgue measure on B(R) (cf. Example 5.5). The
function ℓ∗ will be termed an outer measure, in accordance with the property that restricted
to a smaller σ-field it becomes a measure.
51

Leaving the framework of the latter example, we introduce the following general definition.
Definition 6.2. Let Ω be a nonempty set. An outer measure µ∗ is a function µ∗ : P(Ω) →
R+ that satisfies the following properties:
(i) µ∗ (∅) = 0;
(ii) A, B ∈ P(Ω), s.t. A ⊂ B ⇒ µ∗ (A) ≤ µ∗ (B);
(iii) µ∗ is countableP
subadditive on P(Ω), i.e., for any collection {An : n ∈ N} ⊂ P(Ω),
∞
∗
µ∗ (∪∞
n=1 An ) ≤
n=1 µ (An ).
Then, the following result offers a general classification of the function ℓ∗ covered in
Example 6.1:
Proposition 6.5. Let A ⊂ P(Ω) where Ω is some nonempty
set. Suppose that ∅ ∈ A and
P
ρ : A → R+ is a function s.t. ρ(∅) = 0. Let vρ (ξ) = U ∈ξ ρ(U ), ξ ∈ CA (A). Then, the
function,
P(Ω) ∋ A 7→ ρ∗ (A) =

inf
ξ∈CA (A)

vρ (ξ),

is an outer measure.
Exercise 6.4. Let ℓ be as in Example 6.1. Verify that ℓ∗ (R) = ∞.
Definition 6.3. Let µ∗ : P(Ω) → R+ be a function. Define the set
M(µ∗ ) = {A ∈ P(Ω) : µ∗ (A ∩ E) + µ∗ (Ac ∩ E) = µ∗ (E) ∀ E ∈ P(Ω)}.
We say that A is µ∗ -measurable if A ∈ M(µ∗ ).
We obtain the following result.
Proposition 6.6. Let µ∗ be an outer measure on P(Ω). Then,
(I) M(µ∗ ) is a σ-field;
(II) The restriction µ∗ |M(µ∗ ) is a measure.
The main result of this section is the following:
Proposition 6.7. Let A ⊂ P(Ω) be a semiring and ρ : A → R+ be a function which is s.t.,
• ρ(∅) = 0;
• ρ is finitely additive on A, i.e., for any finite
Pn disjoint collection {Ai : i = 1, . . . , n} ⊂ A,
n ∈ N, with ∪ni=1 Ai ∈ A, ρ(∪ni=1 Ai ) = i=1 ρ(Ai );
• ρ is countable subadditive
on A, i.e., for any collection {Ai : i ∈ N} ⊂ A with ∪∞
i=1 Ai ∈
P∞
∞
A, ρ(∪i=1 Ai ) ≤ i=1 ρ(Ai ).
Then, ρ extends to a measure on σ(A). That is, there exists a measure ρ↑ : σ(A) → R+
which is s.t. ρ↑ (A) = ρ(A) for any A ∈ A.
Exercise 6.5. Let ρ be as in Proposition 6.7. Show that ρ is monotone on A, i.e., A, B ∈ A
s.t. A ⊂ B ⇒ ρ(A) ≤ ρ(B).
We remark that in the statement of Proposition 6.7, since A is not necessarily a σ-field,
to make sense of the condition that ρ is finitely additive (resp. countable subadditive) on A,
it is required to demand that ∪ni=1 Ai ∈ A (resp. ∪∞
i=1 Ai ∈ A).
52

Example 6.2. We remain in the setting of Example 6.1, where ℓ : R → [0, ∞) is s.t.
(
b − a, if U = (a, b],
ℓ(U ) =
0,
if U = ∅,
and for A ∈ P(R),
ℓ∗ (A) =

inf
ξ∈CR (A)

vℓ (ξ),

vℓ (ξ) =

X

ℓ(U ),

ξ ∈ CR (A),

U ∈ξ

with
CR (A) = {ξ : ξ is a countable covering of A by sets from R}.
Proposition 6.5 shows that ℓ∗ is an outer measure on P(R). By Proposition 6.6, M(ℓ∗ )
is in fact a σ-field on R and the restriction of the outer measure ℓ∗ to M(ℓ∗ ) written as
ℓ∗ |M(ℓ∗ ) is a measure on M(ℓ∗ ). In addition, a set A ⊂ R is called Lebesgue measurable, if
A ∈ M(ℓ∗ ), i.e., if A is ℓ∗ -measurable. We also know that the family of left-open intervals R
is a semiring (cf. Example 5.6). Then, let {Ai , i ∈ N} ⊂ R, Ai = (ai , bi ], be disjoint
P and s.t.,
∪i∈N (ai , bi ] = A ∈ R. Using Propositions 6.2 and 6.3, we conclude that ℓ(A) = i∈N ℓ(Ai ).
Hence, ℓ is additive on R and hence clearly finitely additive
P on R. If {Ai , i ∈ N} ⊂ R is
not disjoint, then still, Propositions 6.2 shows that ℓ(A) ≤ i∈N ℓ(Ai ). Hence, ℓ satisfies all
the conditions of Proposition 6.7. Therefore, there exists a measure ℓ↑ on σ(R) which is s.t.
for any A ∈ R, ℓ↑ (A) = ℓ(A). The measure ℓ↑ is called the Lebesgue measure on σ(R) and
we use the notation ℓ↑ = λ (cf. Example 5.5). In fact, we have that λ = ℓ∗ |σ(R) , i.e., the
Lebesgue measure on B(R) equals the restriction of the outer measure ℓ∗ to B(R) (cf. the
proof of Proposition 6.7). We also have that B(R) ⊂ M(ℓ∗ ) (cf. the proof of Proposition 6.7).
Thus, every Borel set is also Lebesgue measurable. One can show that M(ℓ∗ ) \ B(R) ̸= ∅,
i.e., there are sets that are Lebesgue measurable but not Borel measurable. Even further, the
following result shows that P(R) \ M(ℓ∗ ) ̸= ∅.
Proposition 6.8. There are sets V ⊂ R which are not Lebesgue measurable.
We omit a proof and refer to [1] or [2].
Definition 6.4. Let (Ω, F) be a measurable space and µ be a measure on F. Let A ⊂ F.
The measure µ is called σ-finite on A if Ω = ∪i∈I Ai for some countable collection of sets
{Ai : i ∈ I} ⊂ A which are s.t. µ(Ai ) < ∞ for any i ∈ I.
A proof of the following result is given in Section B.3 of the appendix.
Proposition 6.9. Let Ω ̸= ∅ be a set and assume that A ⊂ P(Ω) is s.t. A, B ∈ A ⇒
A ∩ B ∈ A. Let µ1 and µ2 be two measures on σ(A) where at least one of the measures µ1
and µ2 is a σ-finite measure on A. If µ1 (A) = µ2 (A) for any A ∈ A, then µ1 (A) = µ2 (A)
for any A ∈ σ(A), i.e., the two measures agree on σ(A).
Proposition 6.10. The Lebesgue measure λ on B(R) is the unique measure on B(R) which
is s.t. for any left-open interval (a, b], λ((a, b]) = b − a.
Remark 6.1. We remark that upon Example 6.2 and the latter proposition, we have proven
Proposition 6.1.

6.3

The Lebesgue measure on real coordinate spaces

Let Ω = Rk , k ∈ N, and consider the function
(Q
Qk
k
i=1 (bi − ai ) if A =
i=1 (ai , bi ]
ℓk (A) =
0,
otherwise,
53

defined on the set
k
Y

Rk = A : A =
(ai , bi ], ai , bi ∈ R, i = 1, . . . , k ∪ {∅},
i=1

i.e., the family of rectangles in Rk (cf. Example 4.11). That is, ℓk k ∈ N, returns length
(k = 1), area (k = 2), volume (k = 3) and hypervolume (k ≥ 4). Then, Proposition 6.1 is
generalized as follows:
Proposition 6.11. There exists a measure λk on B(Rk ) = σ(Rk ) (referred to as the (kdimensional) Lebesgue measure on B(Rk )) which is s.t.
k
Y

for any rectangle A =

(ai , bi ], λk satisfies λk (A) = ℓk (A).

(13)

i=1

Further, λk is the unique measure on B(Rk ) which satisfies (13).

6.4

Solution to exercises

Solution 6.1 (Solution to Exercise 6.1). We have that
vℓ (ξ3 ) =

∞
X
(b − a)
k=0

2k

= (b − a)

∞  k
X
1
k=0

2

= 2(b − a).

Solution 6.2 (Solution to Exercise 6.2). This is clearly the case, as an example, take
ξ∗ = {(a, b]}, then ξ∗ ∈ CR ((a, b]) and vℓ (ξ∗ ) = b − a. Hence,
inf
ξ∈CR ((a,b])

vℓ (ξ) ≤ b − a.

Solution 6.3 (Solution to Exercise 6.3). Let a ∈ R. We know that ℓ∗ (A) ≥ 0 for any
A ∈ P(R). In particular, ℓ∗ ({a}) ≥ 0. Define for any ε > 0,



ε
ε
ξa =
a − n , a : n ∈ N ∈ CR ({a}).
2
We have that vℓ (ξaε ) = ε. Hence, since ε was arbitrary, vℓ (ξaε ) = 0. This shows that
ℓ∗ ({a}) ≤ 0 and hence ℓ∗ ({a}) = 0.
Solution 6.4 (Solution to Exercise 6.4). By Proposition 6.5, ℓ∗ is an outer measure on
P(R). In particular, it is monotone. That is, A ⊂ B ⇒ ℓ∗ (A) ≤ ℓ∗ (B). Also, because
of Proposition 6.4, for any n ∈ N, ℓ∗ ((−n/2, n/2]) = n. This shows that for any n ∈ N,
n = ℓ∗ ((−n/2, n/2]) ≤ ℓ∗ (R) and hence ℓ∗ (R) can not be finite.
Solution 6.5 (Solution to Exercise 6.5). Let A, B ∈ A s.t. A ⊂ B. Then, since A is a
semiring, there exists a disjoint collection {Ci : i = 1, . . . , n} ⊂ A, n ∈ N, s.t. B \ A =
∪ni=1 Ci . In particular, B = A ∪ (B \ A) and hence, since ρ is assumed to be finitely additive
on A,

ρ(B) = ρ A ∪

[
n


Ck

= ρ(A) + ρ

i=1

[
n
i=1

54


Ck

≥ ρ(A).

6.5

Additional exercises

Exercise 6.6. Argue that each of the following sets is a Borel set, i.e., a member of B(R)
and deduce its Lebesgue measure:
• R;
• {a}, a ∈ R (singleton sets);
• (a, b), [a, b) and [a, b], where a, b ∈ R.
Exercise 6.7. Prove Proposition 6.10.
Exercise 6.8. Show that ℓ∗ is not finitely additive on P
P(R), i.e., there exists a disjoint
n
collection {Ai : i = 1, . . . , n} ⊂ P(R) s.t. ℓ∗ (∪ni=1 Ai ) ̸= i=1 ℓ∗ (Ai ). Conclude that ℓ∗ is
not a measure on P(R).
Hint: Proposition 6.8.
Exercise 6.9. Prove Proposition 6.3.
Hint: Induction.
Exercise 6.10. Let U = {U : U ⊂ Rk open}, i.e., U contains all the open sets of Rk (cf.
Definition 2.16). Show that B(Rk ) = σ(U).
B(Rk ) contains U:
Step1: Define
k
Y

Rk (Q) = A : A =
(ai , bi ], ai , bi ∈ Q, i = 1, . . . , k .
i=1

Verify that Rk (Q) is countable.
Step2: Let U ∈ U be nonempty. Argue that for any x ∈ U , there exists Rx ∈ Rk (Q)
s.t. x ∈ Rx and Rx ⊂ U .
Hint: Recall that since U is open, it follows that for any x ∈ U , there exists an
open ball Bεx (x) s.t. Bεx (x) ⊂ U . Hence, it is sufficient to find
Rx = (a1 , b1 ] × · · · × (ak , bk ] ∈ Rk (Q)
s.t. x ∈ Rx and for i = 1, . . . , k, bi − ai < r(εx , k), where r(εx , k) is chosen s.t.
∥x − y∥ < εx for any y ∈ Rx .
Step3: Write U as a countable union of rectangles from Rk (Q).
σ(U) contains Rk : Show that any element of Rk can be written as a countable intersection
of open rectangles (cf. Exercise 2.4).

55

7

Measurable functions

The omitted proofs of this chapter are found in Section B.4 of the appendix.

7.1

The concept of measurable functions

Definition 7.1. Let (Ω, F) and (Ω∗ , F ∗ ) be two measurable spaces (cf. Definition 4.3). A
function f : Ω → Ω∗ is said to be measurable F/F ∗ if for any A∗ ∈ F ∗ , f −1 (A∗ ) ∈ F.
Proposition 7.1. Let (Ω, F) and (Ω∗ , F ∗ ) be two measurable spaces and f : Ω → Ω∗ be a
function. Suppose that F ∗ = σ(G) and for any G ∈ G, f −1 (G) ∈ F. Then, f is F/F ∗
measurable.
Proof. It is enough to show that Σ∗ = {A∗ : f −1 (A∗ ) ∈ F} is a σ-field on Ω∗ . We have that
Ω∗ ∈ Σ∗ , since f −1 (Ω∗ ) = Ω and F is a σ-field, i.e., it contains Ω. Let A∗ ∈ Σ∗ . Then,
f −1 ((A∗ )c ) = f −1 (A∗ )c (cf. Proposition 2.4) and hence (A∗ )c ∈ Σ∗ . Let {A∗i : i ∈ N} ⊂ Σ∗ .
∗
∞
−1
∗
∗
Then, since f −1 (∪∞
(A∗i ) (cf. Proposition 2.4), ∪∞
i=1 Ai ) = ∪i=1 f
i=1 Ai ∈ Σ .
Example 7.1. Consider the measurable space (Rm , B(Rm )) and (Rk , B(Rk )). Let f : Rm →
Rk be continuous (cf. Definition 2.17). Then, f is measurable B(Rm )/B(Rk ). To see it,
let U = {U : U open in Rk }. Then, since f is continuous, for any U ∈ U, f −1 (U ) is
an open set of Rm . Since B(Rm ) contains the open sets of Rm , it follows that for any
U ∈ U, f −1 (U ) ∈ B(Rm ). We know that B(Rk ) = σ(U) (cf. Exercise 6.10). Hence, by
Proposition 7.1, f is measurable.
Definition 7.2. A function f : Rm → Rk is called Borel function if it is measurable
B(Rm )/B(Rk ).
Upon Example 7.2 we have proven the following result.
Proposition 7.2. Any continuous function f : Rm → Rk is a Borel function.
Remark 7.1. Suppose that f : E → Rk , where E ⊂ Rm , E ̸= ∅. Using Proposition 4.4 and
Exercise 6.10, we know that
B(E) = σ({G ∩ E : G open in Rm }).
Further, by Proposition 2.11, if f : E → Rk is continuous, then, for any U ⊂ Rk open,
f −1 (U ) ∈ {G ∩ E : G open in Rm }. Hence, by Proposition 7.1, f is B(E)/B(Rk ) measurable.
Using the structure of the Borel σ-field, the next result is helpful to verify that a function
f : Ω → R is F/B(R) measurable.
Proposition 7.3. Let (Ω, F) be a measurable space and f : Ω → R be a real-valued function.
Suppose that {ω ∈ Ω : f (ω) ≤ x} ∈ F for any x ∈ R, then f is F/B(R) measurable.
Proof. Notice that for any x ∈ R, {ω ∈ Ω : f (ω) ≤ x} = f −1 ((−∞, x]). Since B(R) =
σ({(−∞, x] : x ∈ R}) (cf. Exercise 4.7), f is F/B(R) measurable (cf. Proposition 7.1).
Exercise 7.1. Let (Ω, F) be a measurable space and f (ω) = α for any ω ∈ Ω, where α ∈ R.
Show that f is F/B(R) measurable.
Example 7.2. In Example 5.1, we have considered the measure A 7→ δω (A) for fixed ω ∈ Ω.
If now A ⊂ Ω is fixed and ω is variable, then, the function
(
1, if ω ∈ A,
ω 7→ 1A (ω) = δω (A) =
,
0, otherwise.
56

is referred to as the indicator function of the set A. Then, if A ∈ F, ω 7→ 1A (ω) is F/B(R)
measurable. To see it, we notice that for any x ∈ R,


∅, if x ≥ 1,
{ω ∈ Ω : 1A (ω) > x} = A, if 0 ≤ x < 1,


Ω if x < 0.
Since A ∈ F, {ω ∈ Ω : 1A (ω) > x} ∈ F for any x ∈ R. Thus, {ω ∈ Ω :
any x ∈ R. By Proposition 7.3, ω 7→ 1A (ω) is F/B(R) measurable.

1A (ω) ≤ x} ∈ F for

Example 7.3. Let Ω = {h, t} and F = P({h, t}) = {∅, {h}, {t}, {h, t}}. Then, {h} ∈
P({h, t}). Thus,
(
1, if ω = h,
f (ω) =
0, if ω = t,
is P({h, t})/B(R) measurable.
Example 7.4. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F/B(R)
measurable. Then, f = min{fi : i = 1, . . . , k} is F/B(R) measurable. To see it, we notice
that for any x ∈ R and i = 1, . . . , k, since fi is F/B(R) measurable, fi−1 ((x, ∞)) ∈ F.
Therefore, for any x ∈ R,
f −1 ((x, ∞)) = {ω ∈ Ω : f (ω) > x} = ∩ki=1 {ω ∈ Ω : fi (ω) > x} = ∩ki=1 fi−1 ((x, ∞)) ∈ F.
Therefore, for any x ∈ R, (f −1 ((x, ∞)))c = f −1 ((−∞, x]) ∈ F. Using Proposition 7.3, f is
F/B(R) measurable.
The following result shows that the measurability of a vector valued function is characterized in terms of the measurability of the respective coordinate functions.
Proposition 7.4. Let (Ω, F) be a measurable space and f : Ω → Rk , i.e.,
f (ω) = (f1 (ω), . . . , fk (ω)).
Then, f is F/B(Rk ) measurable if and only if for any i = 1, . . . , k, fi : Ω → R is F/B(R)
measurable.
The latter result offers a helpful tool to show that if f1 , . . . , fk : Ω → R are F/B(R)
Pk
Qk
measurable functions, then, the functions i=1 fi and i=1 fi are F/B(R) measurable as
well. In order to arrive there, the conclusion of the following exercise is valuable.
Exercise 7.2. Let (Ω, F) and (Ω∗ , F ∗ ) be two measurable spaces and f : Ω → Ω∗ be a
function. Let (Ω∗∗ , F ∗∗ ) be a third measurable space and f ∗ : Ω∗ → Ω∗∗ be another function.
Show that if f is F/F ∗ measurable and f ∗ is F ∗ /F ∗∗ measurable, then the composition
f ∗ (f ) : Ω → Ω∗∗ is F/F ∗∗ measurable.
Proposition 7.5. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F/B(R)
measurable. Suppose that g : Rk → R is B(Rk )/B(R) measurable. Then,
ω 7→ g((f1 (ω), . . . , fk (ω))),
is F/B(R) measurable.
Notice that we usually avoid the double bracket and simply write
ω 7→ g((f1 (ω), . . . , fk (ω))) = g(f1 (ω), . . . , fk (ω)).
57

Proof of Proposition 7.5. Since fi : Ω → R, i = 1, . . . , k, are F/B(R) measurable, we use
Proposition 7.4 and deduce that the map
ω 7→ (f1 (ω), . . . , fk (ω)),
is F/B(Rk ) measurable. Then, since g is B(Rk )/B(R) measurable, we rely on Exercise 7.2
and verify that
ω 7→ g(f1 (ω), . . . , fk (ω)),
is F/B(R) measurable.
A direct consequence of the latter result is the following (cf. Example 7.1).
Proposition 7.6. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F/B(R)
measurable. Then, if g : Rk → R is continuous,
ω 7→ g(f1 (ω), . . . , fk (ω)),
is F/B(R) measurable.
Example 7.5. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F/B(R)
Pk
measurable. Then, i=1 fi is F/B(R) measurable (cf. Proposition 2.12).
Example 7.6. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F/B(R)
Qk
measurable. Then, i=1 fi is F/B(R) measurable (cf. Proposition 2.12).
Exercise 7.3. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F/B(R)
measurable. Let c1 , . . . , ck ∈ R. Then, the function
ω 7→ f (ω) =

k
X

ci fi (ω),

i=1

is F/B(R) measurable.
Remark 7.2. Let (Ω, F) be a measurable space and f : Ω → R be F/B(R) measurable s.t.
f (Ω) ⊂ E, where E ∈ B(R). Suppose that g : E → R is continuous. Then, the composition
g(f ) : Ω → R is F/B(R) measurable. To see it, we notice that for any B ∈ B(R),
g(f )−1 (B) = {ω : g(f (ω)) ∈ B} = {ω : f (ω) ∈ g −1 (B)} = f −1 (g −1 (B)).
Therefore, since by assumption f is F/B(R) measurable, it remains to check that g −1 (B) ∈
B(R). Upon Remark 7.1 we know that since g is continuous, it is B(E)/B(R) measurable.
In particular, g −1 (B) ∈ B(E). Further, since E ∈ B(R), it follows that B(E) ⊂ B(R) since
for any A ∈ B(R), A ∩ E ∈ B(R) (recall Definition 4.2). In conclusion, g −1 (B) ∈ B(R).
Definition 7.3. A function f : Ω → R is called simple if there exists n ∈ N, α1 , . . . , αn ∈ R
and sets A1 , . . . , An ⊂ Ω s.t.
f (ω) =

n
X

αi 1Ai (ω),

ω ∈ Ω.

i=1

That is, a simple function is a finite linear combination of indicator functions.
Example
Pn7.7. Let (Ω, F) be a measurable space and f be a simple function on Ω, i.e.,
f (ω) = i=1 αi 1Ai (ω). Then, if Ai ∈ F for any i = 1, . . . , n, f is F/B(R) measurable.

58

Example 7.8. Let n ∈ N and Ω = {ω : ω = (ω1 , . . . , ωn ) : ωi ∈ {0, 1}, i = 1, . . . , n}. We
write Ω = A0 ∪ A1 ∪ · · · An , where
Ak = {ω ∈ Ω :

n
X

ωi = k},

k = 0, . . . , n.

i=1

Define
f (ω) =

n
X

k 1Ak (ω).

k=0

Then, since Ak ∈ P(Ω) for any k = 0, . . . , n, f is P(Ω)/B(R) measurable.
Definition
Pn7.4. Let (Ω, F) be a measurable space and f : Ω → R be a simple function on Ω,
i.e., f = i=1 αi 1Ai . f is called standard if ∪ni=1 Ai = Ω and {A1 , . . . , An } ⊂ F is disjoint.
If f is standard, we say that f is a simple function in standard form.
The following result shows that simple functions can be written in standard form.
Pn
Proposition 7.7. Let (Ω, F) be a measurable space and f (ω) = i=1 αi 1Ai (ω), ω ∈ Ω,
be a simple function on Ω s.t. Ai ∈ F for any i = 1, . . . , n. Then, there exists a standard
simple function g : Ω → R s.t. f (ω) = g(ω) for any ω ∈ Ω.

7.2

Functions taking values in the extended real numbers

In the context of measurable functions, it is helpful to work with the extended real numbers
R. Thus, we extend the definition of a measurable function to allow for function f : Ω → R.
This will be useful in the context of limits of measurable functions.
Definition 7.5. Let (Ω, F) be a measurable space and f : Ω → R. We say that f is F
measurable if for any A ∈ B(R), {ω ∈ Ω : f (ω) ∈ A} ∈ F and {ω ∈ Ω : f (ω) = −∞} ∈ F
and {ω ∈ Ω : f (ω) = ∞} ∈ F.
Remark 7.3. To combine terminology, if f : Ω → R, then f is said to be F measurable
if it is F/B(R) measurable, i.e., in this case there is no need to bother about the sets
{ω ∈ Ω : f (ω) = −∞} and {ω ∈ Ω : f (ω) = −∞}. Notice that if f (ω) ∈ R for any ω ∈ Ω,
we anyway have that {ω ∈ Ω : f (ω) = −∞} = {ω ∈ Ω : f (ω) = −∞} = ∅ ∈ F. Hence, any
results on F measurable functions f : Ω → R apply directly to F/B(R) measurable functions
f : Ω → R.
Remark 7.4. If (Ω, F) be a measurable space and f : Ω → Rk , k ≥ 1, then the statement
f is F measurable always means that f is F/B(Rk ) measurable. As an example, if the
measurable space (Ω, F) is given by (Rm , B(Rm )), i.e., F = B(Rm ) and f : Rm → Rk , then
f is B(Rm ) measurable if it is B(Rm )/B(Rk ) measurable.
Proposition 7.8. Let (Ω, F) be a measurable space and f, g : Ω → R be two F measurable
functions. Then, {ω ∈ Ω : f (ω) = g(ω)} ∈ F.
Exercise 7.4. Let (Ω, F) be a measurable space and f : Ω → R be F measurable. Show that
the function ω 7→ cf (ω), c ∈ R, is F measurable.

7.3

Sequences of measurable functions

Proposition 7.9. Let (Ω, F) be a measurable space and fn : Ω → R, n ∈ N, be a sequence
of functions s.t. fn is F measurable for any n ∈ N. Then,
(i) given E ⊂ N, the functions supn∈E fn and inf n∈E fn are F measurable;
59

(ii) The functions lim inf n→
− ∞ fn and lim supn→
− ∞ fn are F measurable;
(iii) If for any ω ∈ Ω, limn→∞ fn (ω) exists, then ω 7→ (limn→∞ fn )(ω) is F measurable;
(iv) We have that {ω ∈ Ω : (fn (ω))n∈N converges} ∈ F;
n→∞

(v) Let f : Ω → R be F measurable, then, {ω ∈ Ω : fn (ω) −−−−→ f (ω)} ∈ F.
The following result shows that any non-negative F measurable function can be understood as a monotone limit of non-negative standard simple functions.
Proposition 7.10. Let (Ω, F) be a measurable space f : Ω → R be a F measurable function
s.t. f (ω) ≥ 0 for any ω ∈ Ω. Then, there exists a sequence of standard simple functions
fn : Ω → [0, ∞), n ∈ N, s.t. for any ω ∈ Ω, fn (ω) ↑ f (ω).
Definition 7.6. Let f : Ω → R be a function. We define the positive part of f as the function
f + = max{f, 0},
and the negative part of f as
f − = max{−f, 0},
Exercise 7.5. Show that
(a) for any ω ∈ Ω, f + (ω) ≥ 0 and f − (ω) ≥ 0;
(b) f (ω) = f + (ω) − f − (ω);
(c) |f (ω)| = f + (ω) + f − (ω).
Verify further that if (Ω, F) is a measurable space and f : Ω → R is a F measurable function,
then its positive and negative parts are F measurable.
Upon the latter exercise, we have the following result.
Proposition 7.11. Let (Ω, F) be a measurable space and f : Ω → R be a F measurable
function. Then, there exists a sequence of standard simple functions (fn )n∈N s.t. for any
ω ∈ Ω, limn→∞ fn (ω) = f (ω).
Proof. We write f = f + −f − . Since both, f + and f − are non-negative and F measurable, we
use Proposition 7.10 to find simple functions (fn+ )n∈N and (fn− )n∈N s.t. fn+ (ω) ↑ f + (ω) and
n→∞
fn− (ω) ↑ f − (ω). Therefore, for any ω ∈ Ω, fn+ (ω)−fn− (ω) −−−−→ f + (ω)−f − (ω) = f (ω).
We note that the statement of Exercise 7.3 can be generalized.
Proposition 7.12. Let (Ω, F) be a measurable space and fi : Ω → R, i = 1, . . . , k, be F
measurable. Then, the functions
Qk
• ω 7→ i=1 fi (ω);
Pk
• ω 7→ i=1 ci fi (ω), c1 , . . . , ck ∈ R;
are F measurable.
Proof. We may see this result as a consequence of Propositions 7.11 and 7.9. Since for any
i = 1, . . . , k, fi is F measurable, we write fi (ω) = limn→∞ fin (ω), ω ∈ Ω, where (fin )n∈N
is a sequence of F measurable functions (cf. Propositions 7.11). Therefore, by item (iii) of
Propositions 7.9,
ω 7→ lim

n→∞

Y
k

fin



i=1

(ω) =

k
Y
i=1

60

fi (ω),

and
ω 7→ lim

X
k

n→∞


k
X
ci fin (ω) =
ci fi (ω),

i=

i=1

are F measurable.

7.4

Minimal measurability

Let f (ω) = (f1 (ω), . . . , fk (ω)), ω ∈ Ω, be a function defined on some set Ω, taking values in
Rk . We recall (cf. Exercise 4.9) that the σ-field generated by f is given by
σ(f ) = {f −1 (B) : B ∈ B(Rk )}.
Let
I = {F : F is a σ-field on Ω s.t. σ(f ) ⊂ F}.
If F ∈ I, then f is F measurable, since for any B ∈ B(Rk ), f −1 (B) ∈ σ(f ) ⊂ F. Let
\
Σ=
F.
F ∈I

We know that Σ is a σ-field (cf. Proposition 4.2) and by definition, we know that
Σ = σ(σ(f )) = σ(f ),
since σ(f ) is a σ-field. Further, since σ(f ) is a σ-field that contains σ(f ), σ(f ) ∈ I. Consider
the set
J = {F : F is a σ-field on Ω and f is F measurable}.
We have that I ⊂ J. Take F ∈ J, hence f is F measurable. Then, σ(f ) ⊂ F. Hence,
I = J. In conclusion, σ(f ) is the smallest σ-field on Ω s.t. f is σ(f ) measurable since any
other A ∈ J = I, is s.t. σ(f ) = Σ = ∩F ∈I F ⊂ A. We notice that any function h : Ω → R
that is σ(f ) measurable is s.t. for any A ∈ B(R) there exists B ∈ B(Rk ) s.t.
{ω ∈ Ω : g(ω) ∈ A} = {ω ∈ Ω : f (ω) ∈ B}.
The next result shows that the condition that h : Ω → R is σ(f ) measurable is equivalent to
the condition that h = g(f ), for some function g : Rk → R.
Proposition 7.13. Let f (ω) = (f1 (ω), . . . , fk (ω)), ω ∈ Ω, be a function defined on some set
Ω, taking values in Rk . Let σ(f ) be the σ-field generated by f and h : Ω → R be a function.
Then, h is σ(f ) measurable if and only if there exists a function g : Rk → R which is B(Rk )
measurable and s.t. h(ω) = g(f (ω)).
Example 7.9. Let Ω = {h, t}, F = P({h, t}) and f1 be the P({h, t})/B(R) measurable
map
(
1, if ω = h,
f1 (ω) =
0, if ω = t,
given in Example 7.3. Further, let
(
1,
f2 (ω) =
0,

if ω = t,
if ω = h.

That is, f1 = 1H and f2 = 1T , where H = {ω ∈ Ω : ω = h} and T = {ω ∈ Ω : ω = t}.
Define the map h = 1H + 1T . Then, h is σ(f ) measurable, where f = (f1 , f2 ). This follows
from Proposition 7.13, with g(x) = x1 + x2 , x = (x1 , x2 ) ∈ R2 , which is B(Rk ) measurable
since it is continuous (cf. Propositions 2.12 and 7.2).
61

7.5

Solution to exercises

Solution 7.1 (Solution to Exercise 7.1). This follows from the fact that for any x ∈ R,
{ω ∈ Ω : f (ω) > x} ∈ {∅, Ω} ⊂ F.
Solution 7.2 (Solution to Exercise 7.2). We need to show that for any A∗∗ ∈ F ∗∗ ,
f ∗ (f )−1 (A∗∗ ) ∈ F.
Therefore, let A∗∗ ∈ F ∗∗ . We have that
f ∗ (f )−1 (A∗∗ ) = {ω ∈ Ω : f ∗ (f )(ω) ∈ A∗∗ }
= {ω ∈ Ω : f ∗ (f (ω)) ∈ A∗∗ }
= {ω ∈ Ω : f (ω) ∈ (f ∗ )−1 (A∗∗ )}

= f −1 (f ∗ )−1 (A∗∗ )
Then, since by assumption, f ∗ is F ∗ /F ∗∗ measurable, it follows that (f ∗ )−1 (A∗∗ ) ∈ F ∗ .
Further, since f is F/F ∗ measurable, we conclude that f −1 ((f ∗ )−1 (A∗∗ )) ∈ F.
Solution 7.3 (Solution to Exercise 7.3). Since for any i = 1, . . . , k, ω 7→ ci and ω 7→ fi (ω)
are F/B(R) measurable, ω 7→ ci fi (ω) is F/B(R) measurable (cf. Example 7.6). Therefore,
f is F/B(R) measurable (cf. Example 7.5).
Solution 7.4 (Solution to Exercise 7.4). If c = 0, then {ω ∈ Ω : cf (ω) = 0} = Ω. Thus,
for any set A ⊂ R, the set {ω ∈ Ω : cf (ω) ∈ A} is either the empty set or Ω. Suppose that
c ̸= 0. Then,
{ω ∈ Ω : cf (ω) = −∞} = {ω ∈ Ω : f (ω) = −∞} ∈ F,
and
{ω ∈ Ω : cf (ω) = ∞} = {ω ∈ Ω : f (ω) = ∞} ∈ F,
since f is F measurable. Consider the function
f ∗ (ω) = cf (ω)1F (ω),

ω ∈ Ω,

where F = {ω ∈ Ω : cf (ω) ∈ R}. We notice that F ∈ F, since
F c = {ω ∈ Ω : cf (ω) = −∞} ∪ {ω ∈ Ω : cf (ω) = ∞}.
Let x ∈ R and define z(ω) = 0 for any ω ∈ Ω, i.e., the function that is constant and equal
to zero on Ω. We have that

{ω ∈ Ω : f ∗ (ω) ≤ x} = {ω ∈ Ω : f ∗ (ω) ≤ x} ∩ F ∪ ({ω ∈ Ω : f ∗ (ω) ≤ x} ∩ F c )

= {ω ∈ Ω : cf (ω) ≤ x} ∩ F ∪ ({ω ∈ Ω : z(ω) ≤ x} ∩ F c )

= {ω ∈ Ω : f (ω) ≤ x/c} ∩ F ∪ ({ω ∈ Ω : z(ω) ≤ x} ∩ F c ) ∈ F,
since f is F measurable, F ∈ F and z is F measurable. This shows that f ∗ is F/B(R)
measurable (cf. Proposition 7.3). Therefore, given A ∈ B(R),

{ω ∈ Ω : cf (ω) ∈ A} = {ω ∈ Ω : f ∗ (ω) ∈ A} ∩ F ∪ ({ω ∈ Ω : cf (ω) ∈ A} ∩ F c )
= {ω ∈ Ω : f ∗ (ω) ∈ A} ∩ F ∈ F.
This shows that ω 7→ cf (ω) is F measurable.
62

Solution 7.5 (Solution to Exercise 7.5). By definition, f + (ω) = max{f (ω), 0} ≥ 0 and
f − (ω) = max{−f (ω), 0} ≥ 0. Regarding (b), let ω ∈ Ω, then, if f (ω) < 0, −f (ω) > 0,
and hence f + (ω) − f − (ω) = f (ω). Similarly, if f (ω) > 0, then f + (ω) − f − (ω) = f (ω). If
f (ω) = 0, then f + (ω) = f − (ω) = 0. To see (c), notice that for any ω ∈ Ω,
(
f (ω),
if f (ω) ≥ 0,
+
−
f (ω) + f (ω) = max{f (ω), 0} + max{−f (ω), 0} =
−f (ω), if f (ω) < 0.
Finally, by item (i) of Proposition 7.9, if f is F measurable, f + and f − are F measurable
as well (cf. Exercise 7.4).

7.6

Additional exercises

Exercise 7.6. Let (Ω, F) be a measurable space and f : Ω → R be F measurable. Verify
that the following functions are F measurable:
• ω 7→ ef (ω) ;
• ω 7→ 1/f (ω) (provided that for any ω ∈ Ω, f (ω) ̸= 0);
• ω 7→ log(f (ω)) (provided that for any ω ∈ Ω, f (ω) > 0).
Exercise 7.7. Let (Ω, F) be a measurable space and f1 : Ω → R and f2 : Ω → R be two
F/B(R) measurable functions s.t. f1 (Ω) ⊂ E1 and f2 (Ω) ⊂ E2 , where E1 , E2 ∈ B(R). Let
g1 : E1 → R and g2 : E2 → R be continuous. Verify that the function
f (ω) = (g1 (f1 )(ω), g2 (f2 )(ω)),

ω ∈ Ω,

is F/B(R2 ) measurable.
Exercise 7.8. Let (Ω, F) and (Ω∗ , F ∗ ) be two measurable spaces and g : Ω → Ω∗ be F/F ∗
measurable. Let µ be a measure on F. Define the function
µg −1 (A∗ ) = µ(g −1 (A∗ )) = µ({ω ∈ Ω : g(ω) ∈ A∗ }),

A∗ ∈ F ∗ .

Show that µg −1 is a measure on F ∗ .
Exercise 7.9. Let f and h be as in Proposition 7.13. Suppose that there exists g : Rk → R
which is B(Rk ) measurable and s.t. h(ω) = g(f (ω)). Then, h is σ(f ) measurable.
Hint: f is σ(f ) measurable.
Exercise 7.10. Let f and h be as in Proposition 7.13. Suppose that h is a simple function
in standard form (cf. Definition 7.4 with F = σ(f )). Show that there exists g : Rk → R
which is B(Rk ) measurable and s.t. h(ω) = g(f (ω)).
Hint: Consider the sets Bi = {ω ∈ Ω : h(ω) = αi }, i = 1 . . . , n, where αi ∈ R, i = 1 . . . , n,
are the n values that h can take.

63

8

Integration: Part I

We rely on the following conventions regarding infinity:
x + ∞ = ∞ + x = ∞,

x − ∞ = −∞ + x = −∞,

x · ∞ = ∞ · x = ∞,

x · (−∞) = (−∞) · x = −∞,

x ∈ R,
x > 0,

0 · ∞ = ∞ · 0 = 0,
∞ · ∞ = ∞.
The omitted proofs of this chapter are found in Section B.5 of the appendix.

8.1

The integral for nonnegative functions

If f : Ω → R is s.t. f (ω) ≥ 0 for any ω ∈ Ω, f is said to be nonnegative.
Definition 8.1. Let Ω be a set. A partition of Ω is a disjoint collection {A : A ∈ P },
P ⊂ P(Ω), s.t. ∪A∈P A = Ω. That is, a partition of Ω is a disjoint collection of subsets of
Ω whose union is Ω. If ξ is a partition of Ω, a set A ∈ ξ is referred to as an atom of ξ. A
partition ξ of Ω is said to be finite, if it contains a finite number of atoms.
Example 8.1. Let Ω = {0, 1, . . . , N }, N ∈ N. Then, ξ = {{ω} : ω ∈ Ω} is a partition of Ω.
Definition 8.2. Let (Ω, F) be a measurable space. We use the notation Z0F (Ω) = Z0F for
the set which contains all the finite partitions of Ω with atoms form F. That is,
Z0F = {ξ : ξ is a finite partition of Ω s.t. for any A ∈ ξ, A ∈ F}.
Definition 8.3. Let (Ω, F, µ) be a measure space and f : Ω → R be nonnegative and F
measurable. Then, we define

X
Sµf (ξ) =
inf f (ω) µ(A), ξ ∈ Z0F ,
A∈ξ

ω∈A

and
Z

f (ω)µ(dω) = sup Sµf (ξ).
ξ∈Z0F

Ω

Upon the latter definition, we deduce the integral for a (nonnegative) standard simple
function (cf. Definition 7.4).
PN
Proposition 8.1. Let (Ω, F, µ) be a measure space and f (ω) = i=1 αi 1Ai , where N ∈ N,
αi ∈ [0, ∞), i = 1, . . . , N , and {Ai : i = 1, . . . , N } ∈ Z0F . That is, f is a simple function in
standard form, with nonnegative coefficients αi . We have that
Z
f (ω)µ(dω) =
Ω

N
X

αi µ(Ai ).

i=1

Example 8.2. Consider the measure space (R, B(R), λ), i.e., the real numbers equipped
with the Borel σ-field and the Lebesgue measure (cf. Example 6.2). Let −∞ < a = a0 <
a1 < · · · < aN = b < ∞ and consider the partition



ξ = (−∞, a0 ] ∪ (ai−1 , ai ] : i = 1, . . . , N ∪ (aN , ∞) .
Define
(P
f (x) =

N
i=1

αi 1(ai−1 ,ai ] (x),

0,
64

if x ∈ (a, b],
otherwise.

Using the convention that 0 · ∞ = 0 (see also Exercise 6.5), we obtain that
Z
N
X
f (x)λ(dx) =
αi (ai − ai−1 ),
R

i.e.,

R
R

i=1

f (x)λ(dx) gives the “area under the curve” of f .

Exercise 8.1. Let (Ω, F, µ) be a measure space and f, g : Ω → R be two Rnonnegative and
F
R measurable functions s.t. for any ω ∈ Ω, f (ω) ≤ g(ω). Show that Ω f (ω)µ(dω) ≤
g(ω)µ(dω).
Ω
The following two results are important tools in integration theory. The first is known as
the monotone convergence theorem and the second shows that the integral of nonnegative
functions is linear.
Proposition 8.2. Let (Ω, F, µ) be a measure space and fn : Ω → R, n ∈ N, be a sequence
of nonnegative F measurable functions s.t. for any ω ∈ Ω fn (ω) ↑ f (ω) for some f : Ω → R.
Then,
Z
Z
fn (ω)µ(dω) ↑
f (ω)µ(dω).
Ω

Ω

Proposition 8.3. Let (Ω, F, µ) be a measure space, f, g : Ω → R be two nonnegative and F
measurable functions. Given α, β ∈ [0, ∞) we have that
Z
Z
Z
(αf + βg)(ω)µ(dω) = α
f (ω)µ(dω) + β
g(ω)µ(dω).
Ω

Ω

Ω

As a consequence of the latter two propositions we have the following result:
Proposition 8.4. Let (Ω, F, µ) be a measure space and fi : Ω → R, i ∈ N, be a sequence of
nonnegative F measurable functions, then

Z X 
XZ
fi (ω)µ(dω) =
fi (ω)µ(dω) .
Ω

i∈N

Ω

i∈N

Pn

P
Proof.
Pn Since for any i ∈ N, fi (ω) ≥ 0, we have that i=1 fi (ω) ↑ i∈N fi (ω). Notice that
( i=1 fi (ω))n∈N is a sequence of nonnegative F measurable functions. By Proposition 8.2,

Z X
Z X 
n
fi (ω)µ(dω) ↑
fi (ω)µ(dω).
Ω

Ω

i=1

i∈N

Further, by Proposition 8.3,

 XZ

Z X
n
n Z
X
fi (ω)µ(dω) =
fi (ω)µ(dω) ↑
fi (ω)µ(dω) .
Ω

i=1

i=1

Ω

i∈N

Ω

Since a limit of a real valued sequence is unique, the result follows.
Remark 8.1. We remark that the monotone convergence theorem (cf. Proposition 8.2),
allows for another interpretation of the integral for nonnegative functions. If (Ω, F, µ) is
a measure space and f : Ω → R is a nonnegative and F measurable function, then, we
have seen in Proposition 7.10 that it is always possible to approximate f by a sequence of
(nonnegative) standard simple functions, i.e., for any ω ∈ Ω, fn (ω) ↑ f (ω) where for any
n ∈ N, fn is a simple function in standard form. Hence, upon the monotone convergence
theorem, we obtain,
Z
Z
f (ω)µ(dω) = lim
fn (ω)µ(dω),
Ω

n→∞

Ω

where the latter convergence is monotone. Hence, the integral for a nonnegative and F measurable function can be understood as the monotone limit of the integral of simple functions.
65

Definition 8.4. Let (Ω, F, µ) be a measure space. Suppose that for any ω ∈ Ω, S(ω) is a
statement on Ω. We say S is true µ almost everywhere (a.e.) if µ({ω : S(ω) is false}) = 0.
Example 8.3. Let (Ω, F, µ)
R be a measure space and f : Ω → R be F measurable and nonnegative. If f = 0 µ a.e., then Ω f (ω)µ(dω) = 0. To see it take any ξ ∈ Z0F . Let A ∈ ξ. Suppose
that A ∩ {ω : f (ω) = 0} =
̸ ∅, then inf ω∈A f (ω) = 0. Otherwise, if A ∩ {ω : f (ω) = 0} = ∅,
µ(A) = µ(A ∩ {ω : f (ω) ̸= 0}) ≤ µ({ω : f (ω) ̸= 0}) = 0.
Hence, Sµf (ξ) = 0.
We can derive further properties of the integral for nonnegative functions.
Proposition 8.5. Let (Ω, F, µ) be a measure space. Assume that f, g : Ω → R be two
nonnegative and F measurable functions.
R
(i) If µ({ω : f (ω) > 0}) > 0, then Ω f (ω)µ(dω) > 0;
R
(ii) If Ω f (ω)µ(dω) < ∞, then f < ∞ µ a.e.;
R
R
(iii) If f ≤ g µ a.e., then Ω f (ω)µ(dω) ≤ Ω g(ω)µ(dω);
R
R
(iv) If f = g µ a.e., then Ω f (ω)µ(dω) = Ω g(ω)µ(dω).
Exercise 8.2. Let (Ω, F, µ) be a measure space and fn : Ω → R, n ∈ N, be a sequence of
nonnegative
F measurable
functions s.t. fn ↑ f µ a.e. for some f : Ω → R. Show that
R
R
f
(ω)µ(dω)
↑
f
(ω)µ(dω).
n
Ω
Ω

8.2

Integrable functions

We recall the definition of the positive (f + ) and negative (f − ) parts of a function (cf.
Definition 7.6, recall also Exercise 7.5).
Definition 8.5. Let (Ω, F, µ) be a measure space and f : Ω → R be a F measurable function.
The integral of f is defined by
Z
Z
Z
+
f (ω)µ(dω) =
f (ω)µ(dω) −
f − (ω)µ(dω),
Ω

R

+

Ω

R

Ω

−

R
unlessR Ω f (ω)µ(dω) = Ω f (ω)µ(dω)
= ∞, in which case Ω f (ω)µ(dω) is not defined. If
R
both, Ω f + (ω)µ(dω) < ∞ and Ω f − (ω)µ(dω) < ∞, f is said to be integrable.
Remark 8.2. If (Ω, F, µ) is a measure space and f is as in the latter definition, then the
assumption that f is integrable is defined upon the measure µ, i.e., if one wants to further
refer to the measure of integration one specifies that f is integrable with respect to µ.
SupExercise 8.3. Let (Ω, F, µ) be a measure space and f, g : Ω → R be F measurable.
R
pose
that
f
is
integrable
and
f
=
g
µ
a.e.
Show
that
g
is
integrable
and
f
(ω)µ(dω)
=
Ω
R
g(ω)µ(dω).
Ω
Another characterization of integrability is the following:
Proposition 8.6. Let (Ω, F,Rµ) be a measure space and f : Ω → R be F measurable. Then,
f is integrable if and only if Ω |f (ω)|µ(dω) < ∞.
R
R
Proof. By definition, f is integrable if Ω f + (ω)µ(dω) < ∞ and Ω f − (ω)µ(dω) < ∞. This
is equivalent to
Z
Z
Z
Z
+
−
+
−
f (ω)µ(dω) +
f (ω)µ(dω) =
f (ω) + f (ω)µ(dω) = |f (ω)(ω)|µ(dω) < ∞.
Ω

Ω

Ω

Ω

R
Recall also Exercise 7.5. Notice also that f integrable and R Ω |f (ω)(ω)|µ(dω) = ∞ gives a
contradiction. Hence, if f is integrable, it must follow that Ω |f (ω)(ω)|µ(dω) < ∞.
66

Exercise 8.4. Let (Ω, F, µ) be a measure space and f, g : Ω → R be F measurable. Show
that
(a) if |f | ≤ |g| a.e., and g is integrable, then f is integrable as well;
(b) if µ(Ω) < ∞ and f is bounded on Ω, then f is integrable.
The following is a general version of (iii) in Proposition 8.5.
Proposition 8.7. Let (Ω, F, µ) be a measure
R space and f, Rg : Ω → R be F measurable. If f
and g are integrable and f ≤ g a.e., then, Ω f (ω)µ(dω) ≤ Ω g(ω)µ(dω).
The extension of Proposition 8.3 reads as follows:
Proposition 8.8. Let (Ω, F, µ) be a measure space and f, g : Ω → R be F measurable. If f
and g are integrable, then for any α, β ∈ R, αf + βg is integrable and
Z
Z
Z
(αf + βg)(ω)µ(dω) = α
f (ω)µ(dω) + β
g(ω)µ(dω).
Ω

Ω

Ω

Exercise 8.5. Let (Ω, F, µ) be a measure space and A ∈ F be s.t. µ(A) < ∞. Let f =
PN
i=1 αi 1Ai , N ∈ N, αi ∈ R, i = 1, . . . , N , be a simple function where {Ai : i = 1, . . . , N } ⊂
F is disjoint and ∪N
i=1 Ai = A. Show that
Z
f (ω)µ(dω) =
A

N
X

αi µ(Ai ).

i=1

Exercise 8.6. Let (Ω, F, µ) be a measure space and f, g : Ω → R be F measurable and
integrable. Show that
Z
Z
Z
f (ω)µ(dω) −
g(ω)µ(dω) ≤ |f (ω) − g(ω)|µ(dω).
Ω

8.3

Ω

Ω

Fatou’s lemma and Lebesgue’s dominated convergence theorem

The following is known as Fatou’s lemma.
Proposition 8.9. Let (Ω, F, µ) be a measure space and fn : Ω → R, n ∈ N, be a sequence
of nonnegative and F measurable functions. Then,
Z
Z
lim inf fn (ω)µ(dω) ≤ lim inf
f (ω)µ(dω).
−∞
n→
−∞ Ω n
Ω n→
Fatou’s lemma is used to prove Lebesgue’s dominated convergence (cf. Section B.5 of the
appendix):
Proposition 8.10. Let (Ω, F, µ) be a measure space and fn : Ω → R, n ∈ N, be a sequence
− f a.e. and for
of F measurable functions. Suppose that there exist f, g : Ω → R s.t. fn →
any n ∈ N, |fn | ≤ g a.e. where g is integrable. Then f is integrable and
Z
Z
n→∞
fn (ω)µ(dω) −−−−→
f (ω)µ(dω).
Ω

Ω

In the following we discuss some applications of the latter proposition. As a first consequence, we can further extend Proposition 8.4.
Proposition 8.11. Let (Ω, F, µ) be a measure
space and fi : Ω → R, i ∈ N, be a sequence
Pn
f
exists
a.e. and there exists integrable g s.t.
of
F
measurable
functions.
If
lim
n→∞
i=1 i
Pn
P
| i=1 fi | ≤ g a.e., then i∈N fi and fi , i ∈ N, are integrable and
 Z X 
XZ
fi (ω)µ(dω).
fi (ω)µ(dω) =
i∈N

Ω

Ω

67

i∈N

Pn
Pn
n→∞ P
Proof. Since limn→∞ i=1 fi exists a.e., we have that i=1 fi (ω) −−−−→ i∈N fi (ω) a.e.
By Proposition 8.10, we can interchange limit and integration, i.e.,

Z X
Z X 
n
n→∞
fi (ω)µ(dω) −−−−→
fi (ω)µ(dω).
Ω

In particular, limn→∞

R

Ω

i=1

i∈N

Pn
( i=1 fi )(ω)µ(dω) exists. Hence, since
Ω


 XZ

Z X
n
n Z
X
lim
fi (ω)µ(dω) = lim
fi (ω)µ(dω) =
fi (ω)µ(dω) ,

n→∞

Ω

i=1

n→∞

i=1

Ω

i∈N

Ω

the result follows.
Another consequence is the following result:
Proposition 8.12. Let (Ω, F, µ) be a measure space and f : U × Ω → R be a function where
U ⊂ Rk . Assume that
(i) for any u ∈ U ω 7→ f (u, ω) is F measurable;
(ii) for any u0 ∈ U , u 7→ f (u, ω) is continuous in u0 µ a.e.;
(iii) there exists a nonnegative and µ integrable g : Ω → R s.t. for any u ∈ U , |f (u, ω)| ≤
g(ω), µ a.e.
R
Then, F (u) = Ω f (u, ω)µ(dω), u ∈ U , is s.t. F : U → R and F is continuous on U .
Proof. Using Exercise 8.4, (iii) implies that for any u ∈ U , ω 7→ f (u, ω) is µ integrable.
n→∞
Hence, F : U → R. Let un , n ∈ N, be s.t. un −−−−→ u0 , u0 ∈ U . Then, (ii) implies
n→∞
that f (un , ω) −−−−→ f (u0 , ω), µ a.e. on Ω (cf. Proposition 3.26). Therefore, we apply
n→∞
Proposition 8.10, and conclude that F (un ) −−−−→ F (u0 ), as well. Since u0 ∈ U was arbitrary,
F is continuous on U .
Example 8.4. Consider the measure space (R, B(R), λ), where λRis the Lebesgue measure
on B(R). Let φ : R → R be B(R) measurable and integrable, i.e., R |φ(x)|λ(dx) < ∞. The
Fourier transform φ̂ of φ is defined as
Z
φ̂(u) =
eiux φ(x)λ(dx),
R

where i 2 = −1, the imaginary number. Let f (u, x) = eiux φ(x), u, x ∈ R. Then, given any
u ∈ R, x 7→ eiux is B(R) measurable since it is continuous on R. Therefore, x 7→ eiux φ(x)
is B(R) measurable (cf. Example 7.6). Then, by the continuity of u 7→ eiux , for any x ∈ R,
the function u 7→ f (u, x) is continuous on R. Further,Rit follows with |eiux | = 1, that for
any u, x ∈ R, |f (u, x)| ≤ |φ(x)|, where by assumption R |φ(x)|λ(dx) < ∞. Therefore, we
apply Proposition 8.12, and conclude that the Fourier transform of φ is s.t. φ̂ : R → R and
is continuous on R.
Example 8.5. Consider (R, B(R), λ) as in the previous example. Let φ : R → R be B(R)
measurable and integrable. Suppose that h : R → R is bounded and continuous. Let
Z
h ∗ φ(u) =
h(u − x)φ(x)λ(dx), u ∈ R.
R

Similar to the previous example, we apply Proposition 8.12 and readily see that h ∗ φ is
continuous and bounded on R.

68

8.4

Integration over measurable sets

Definition 8.6. Let (Ω, F, µ) be a measure space and f : Ω → R be a F measurable function.
The integral of f over a set A ∈ F is defined as
Z
Z
f (ω)µ(dω) = (1A f )(ω)µ(dω).
A

Ω

Exercise 8.7. Let (Ω, F, µ) be a measure space and f : Ω → R Rbe F measurable and either
nonnegative or integrable. Show that if µ(A) = 0, A ∈ F, then A f (ω)µ(dω) = 0.
Exercise 8.8. Let (Ω, F, µ) be a measure space and F ∈ F. Show that
F ∋ A 7→ µF (F ∩ A),
is a measure on F and for any nonnegative and F measurable function f : Ω → R,
Z
Z
f (ω)µF (dω) =
f (ω)µ(dω).
Ω

F

Exercise 8.9. Let (Ω, F, µ) be a measure space and f : Ω → R be a F measurable function.
Suppose that either f is nonnegative or integrable and let {Ai : i ∈ I} ⊂ F be disjoint, where
I ⊂ N. Show that

Z
XZ
f (ω)µ(dω) =
f (ω)µ(dω) .
∪i∈I Ai

Ai

i∈I

Example 8.6. Consider the measure space (N, P(N), µ), where µ is the counting measure
and P(N) is the power set of N (cf. Example 5.3). We have that for any nonnegative P(N)
measurable function f : N → R,
Z
X
f (k)µ(dk) =
f (k).
N

k∈N

To see it, we define the sequence of functions
(
f (k),
fn (k) = (f 1{0,...,n} )(k) =
0,

if 0 ≤ k ≤ n,
otherwise.

Then, (fn )n∈N is a sequence of nonnegative P(N) measurable functions. Further, given any
k ∈ N, fn (k) ↑ f (k). By Proposition 8.2,
Z
Z
fn (k)µ(dk) ↑
f (k)µ(dk).
N

N

We write
N = {1} ∪ . . . ∪ {n} ∪ (N \ {1, . . . , n}).
Therefore, using Exercise 8.9, we obtain,
Z
Z
Z
Z
fn (k)µ(dk) =
fn (k)µ(dk) + · · · +
fn (k)µ(dk) +
fn (k)µ(dk)
N
{1}
{n}
N\{1,...,n}
Z
Z
=
fn (k)1{1} (k)µ(dk) + · · · + fn (k)1{n} (k)µ(dk)
N
N
Z
Z
= fn (1) 1{1} µ(dk) + · · · + fn (n) 1{1} µ(dk)
N

N

= fn (1)µ({1}) + · · · fn (n)µ({n})
n
n
X
X
=
fn (k) =
f (k).
k=1

Hence,

P

k∈N

f (k) =

R
N

k=1

f (k)µ(dk).
69

Example 8.7. Let f : N × N → R, f (i, j) = aij with aij ≥ 0 for any (i, j) ∈ N × N. We
consider the measure space (N, P(N), µ), where µ is the counting measure and P(N) is the
power set of N (cf. Example 5.3). Fix any j ∈ N, and define the function fj (i) = f (i, j), i ∈
N, i.e., fj : N → R is a sequence of real numbers. Clearly, given any j ∈ N, fj−1 (B) ∈ P(N),
B ∈ B(R).PThat is, fj , j ∈ N, is a sequence of nonnegative P(N) measurable functions.
Let S(i) = j∈N fj (i), i ∈ N. Notice that as the limit of a sequence of measurable functions
Pn
( j=1 fj (i)), S is P(N) measurable (cf. Proposition 7.9). Using Example 8.6, we know that
 XX 
Z
X
XX
S(i)µ(di) =
S(i) =
fj (i) =
aij .
N

i∈N

i∈N

j∈N

i∈N

j∈N

Also, by Proposition 8.4, using Example 8.6 again,
 XX 
 XX
Z
XZ
aij .
fj (i) =
S(i)µ(di) =
fj (i)µ(di) =
N

N

j∈N

j∈N

j∈N

i∈N

i∈N

Which shows that
XX
i∈N


aij

XX

=

j∈N

j∈N


aij .

i∈N

Example 8.8. Let (Ω, F, µ) be a measure space and P
f : Ω → R be F measurable and integrable. Suppose that I is a countable set and µ = i∈I µi , where µi is a collection of
measures on F. Then,

Z
XZ
f (ω)µ(dω) =
f (ω)µi (dω) .
Ω

Ω

i∈I

To see it, suppose first that f is nonnegative. If f (ω) = 1A (ω), A ∈ F, then

Z
X
XZ
f (ω)µ(dω) = µ(A) =
µi (A) =
f (ω)µi (dω) .
Ω

i∈I

Ω

i∈I

PN
Now suppose that f = k=1 αk 1Ak is a nonnegative simple function (f is assumed to be in
standard from, cf. Proposition 7.7). By Proposition 8.3, we obtain:
Z
f (ω)µ(dω) =
Ω

Z X
N
Ω

=

N
X
k=1


Z
N
X
αk 1Ak (ω) µ(dω) =
αk

k=1

αk

k=1

X



1Ak µ(dω)

Ω

 XX
 XZ

N
µi (Ak ) =
αk µi (Ak ) =
f (ω)µi (dω) .

i∈I

i∈I

i∈I

k=1

Ω

Notice that we are allowed to interchange the order of summation by Proposition 3.11. If f
is F measurable and nonnegative function, we rely on Proposition 7.10 and find a sequence
of nonnegative standard simple functions (fn )n∈N s.t. for any ω ∈ Ω, fn (ω) ↑ f (ω). Using
the previous case, we deduce that
Z

XZ

Z
f (ω)µ(dω) = lim
fn (ω)µ(dω) = lim
fn (ω)µi (dω) .
Ω

n→∞

n→∞

Ω

Given any n ∈ N, write fn =
display it reads

PNn

lim

k=1

n→∞

i∈I

Ω

αkn 1Akn . Then, on the right-hand side of the latter

XX
Nn
i∈I


αkn µi (Akn )

k=1

70

PNn
αkn µi (Akn ), i ∈ I, n ∈ N. By Proposition 8.2, we
Set gRni = k=1
R know that for any i ∈ I,
gni ↑ Ω f (ω)µi (dω). Suppose that I is finite and for any i ∈ I, Ω f (ω)µi (dω) < ∞. Then,
it follows from Proposition 3.4, that
X  XZ

i
lim
gn =
f (ω)µi (dω) ,
(14)
n→∞

i∈I

Ω

i∈I

R
and the result follows. If there exists i ∈ I, s.t. gni ↑ Ω f (ω)µi (dω) = ∞, then, both sides
of (14) are equal to ∞ and the result remains true. Thus, if I is finite, the statement
is
P∞
m
verified.
If
I
is
countably
infinite,
#I
=
#N,
and
upon
Example
8.7,
we
write
g
=
n
m=1
R m
g c(dm), where c is the counting measure on P(N). Therefore, as a consequence of
N n
Proposition 8.2, we obtain
lim

n→∞

X
∞

gnm



Z



gnm c(dm)

= lim

n→∞

m=1

=

∞
X

Z Z
=

N

m=1

Ω

N

Z


f (ω)µm (dω)

Ω

=


f (ω)µm (dω) c(dm)

XZ
i∈I


f (ω)µi (dω) .

Ω

For the remaining case, we write f = f + − f − and apply the result to f + and f − .

8.5

Solution to exercises

Solution 8.1 (Solution to Exercise 8.1). This follows from the fact that Sµf (ξ) ≤ Sµg (ξ) for
any ξ ∈ Z0F (cf. Definition 1.11).
Solution 8.2 (Solution to Exercise 8.2). Let A = {ω : fn (ω) ↑ f (ω)}. By assumption,
µ(Ac ) = 0. Define fn∗ (ω) = fn (ω)1A (ω), f ∗ (ω) = f (ω)1A (ω),
R ω ∈ Ω. Then, Rfor any ω ∈ Ω,
fn∗ (ω) ↑ f ∗ (ω). Hence, using Proposition 8.2, it follows that Ω fn∗ (ω)µ(dω) ↑ Ω f ∗ (ω)µ(dω).
Further, for any n ∈ N, fn = fn∗ µ a.e. since {ω : fn ̸= fn∗ } ⊂ Ac . Similarly, f = f ∗ µ a.e.
Therefore, using item (iv) of Proposition 8.5,
Z
Z
Z
Z
fn (ω)µ(dω) =
fn∗ (ω)µ(dω) ↑
f ∗ (ω)µ(dω) =
f (ω)µ(dω).
Ω

Ω

Ω

Ω

Solution
8.3 (Solution to Exercise 8.3). Since f is integrable, Ω f + (ω)µ(dω) < ∞ and
R −
f
(ω)µ(dω)
< ∞. Notice that by definition of f + and f − , {ω : f + (ω) = g + (ω)} ∩
Ω
{ω : f − (ω) = g − (ω)} = {ω : f (ω) = g(ω)}. So that {ω : f (ω) ̸= g(ω)} = {ω : f + (ω) ̸=
g + (ω)} ∪ {ω : f − (ω) ̸= g − (ω)}. Hence, f + = g + and f − = g − µ a.e. Thus, the result
follows from item (iv) of Proposition 8.5.
R

Solution 8.4 (Solution to Exercise 8.4).
(a) First of all, ω 7→ |f (ω)| and ω 7→ |g(ω)| are nonnegative and F measurable. Using
item (iii) of Proposition 8.5, it follows that
Z
Z
|f (ω)(ω)|µ(dω) ≤ |g(ω)(ω)|µ(dω),
Ω

Ω

where the latter integral is finite by Proposition 8.6. Therefore, using Proposition 8.6
again, f is integrable.
(b) We recall that f bounded on Ω means that there exists 0 ≤ M < ∞ s.t. |f (ω)| ≤ M
for any ω ∈ Ω (cf. Definition 2.20). Then, using the result of Exercise 8.1, we obtain
Z
Z
|f (ω)(ω)|µ(dω) ≤ M
µ(dω) = M µ(Ω) < ∞.
Ω

Ω

71

Solution 8.5 (Solution to Exercise 8.5). Given any ω ∈ Ω,
|f (ω)| ≤ |max{αi : i = 1, . . . , N }|.
Hence, the function
obtain

1A f is integrable since µ(A) < ∞. Then, we use Proposition 8.8, and
Z
f (ω)µ(dω) =
A

=

n
X
i=1
n
X

Z

=



Ω

Z



1Ai (ω)µ(dω)

αi
Ω

i=1
n
X

1A 1Ai (ω)µ(dω)

αi

αi µ(Ai ),

i=1

where we used that Ai ⊂ A and

1Ai is nonnegative for any i = 1, . . . , N .

Solution 8.6 (Solution to Exercise 8.6). Let h : Ω → R be any F measurable and integrable
function.
Given Rany ω ∈ Ω, −|h(ω)|R≤ h(ω) ≤ |h(ω)|. Hence,
by Proposition 8.7, we obtain
R
R
h(ω)µ(dω)
≤
|h(ω)|µ(dω)
and
−h(ω)µ(dω)
≤
|h(ω)|µ(dω).
There are two cases,
Ω
Ω
Ω
Ω
R
either Ω h(ω)µ(dω) ≥ 0, then,
Z
Z
Z
h(ω)µ(dω) ≤ |h(ω)|µ(dω),
h(ω)µ(dω) =
Ω

Ω

or

R
Ω

Ω

h(ω)µ(dω) < 0, then (cf. Proposition 8.3),
Z
Z
Z
Z
h(ω)µ(dω) =
−h(ω)µ(dω) ≤ |h(ω)|µ(dω).
h(ω)µ(dω) = −
Ω

Ω

Ω

Ω

To conclude, we set h = f − g.
Solution 8.7 (Solution to Exercise 8.7). Since {ω : f 1A ̸= 0} ⊂ A, it follows that f 1A is
zero a.e. Thus, if f is nonnegative we rely on item (iv) of Proposition 8.5 and conclude. If
f is integrable, we use Exercise 8.3 and arrive at the same conclusion.
Solution 8.8 (Solution to Exercise 8.8). It is clear that µF is a measure on F. Let f = 1A ,
A ∈ F. We have that
Z
Z
f (x)µF (dω) =
µF (dω)
Ω
A
Z
Z
= µF (A) = µ(F ∩ A) =
µ(dω) =
1F ∩A (x)µ(dω)
F ∩A
Ω
Z
Z
=
1F (ω)1A (ω)µ(dω) = f (x)µ(dω).
Ω

F

If f = i=1 αi 1Ai is a nonnegative simple function (f is assumed to be in standard from,
cf. Proposition 7.7), then by Proposition 8.3,
PN

Z
f (x)µF (dω) =
Ω

N
X

Z
αi

 X
Z
N
1Ai (ω)µF (dω) =
αi

Ω

i=1

i=1



1Ai (ω)µ(dω) =

F

Z
f (x)µ(dω).
F

Let f be any F measurable and nonnegative function. We rely on Proposition 7.10 and find a
sequence of nonnegative standard simple functions (fn )n∈N s.t. for any ω ∈ Ω, fn (ω) ↑ f (ω).
By Proposition 8.2, it follows from the previous case that
Z

Z
Z
Z
f (x)µF (dω) = lim
fn (x)µF (dω) = lim
fn (x)µ(dω) =
f (x)µ(dω).
Ω

n→∞

n→∞

Ω

72

F

F

Solution 8.9 (Solution to Exercise 8.9). We notice first that if I is finite, then the result
follows from Proposition 8.8. Hence we assume that I = N. Suppose that f is nonnegative.
Using Definition 8.6, we have that

Z
Z
Z X
f (ω)µ(dω) =
1∪i∈N Ai (ω)f (ω)µ(dω) =
1Ai (ω)f (ω) µ(dω),
∪i∈N Ai

Ω

Ω

i∈N

since {Ai : i ∈ N} is disjoint. Then, we use Proposition 8.4 and obtain
 XZ

Z
XZ
f (ω)µ(dω) =
1Ai (ω)f (ω)µ(dω) =
f (ω)µ(dω) .
∪i∈N Ai

Ω

i∈N

i∈N

Ai

Suppose P
now that f is integrable. Define fi = f 1Ai , i ∈ N. We have that for any ω ∈ Ω,
n
limn→∞ i=1 fi (ω) = f 1∪i∈N Ai (ω). In particular,
n
X

fi (ω) ≤ |f |1∪i∈N Ai (ω) ≤ f (ω) .

i=1

Therefore, by Proposition 8.11,
Z
f (ω)µ(dω) =
∪i∈N Ai

8.6

XZ
i∈N


f (ω)µ(dω) .

Ai

Additional exercises

Exercise 8.10. Let (Ω, F) be a measurable space and x ∈ Ω be given. Define the measure
(
1, if x ∈ A,
A 7→ δx (A) =
0, if x ∈
/ A.
on F (cf. Example 5.1). Let f : Ω → R be nonnegative and F measurable. Show that
Z
f (ω)δx (dω) = f (x).
Ω

R

Hint: Calculate Ω f (ω)δx (dω) if f is a nonnegative simple function in standard form and
rely on Propositions 7.10 and 8.2.
Extension: Using positive and negative parts of Rf , it can be shown that it is enough to
demand that f : Ω → R is F measurable to obtain Ω f (ω)δx (dω) = f (x).
Exercise 8.11. Calculate the integral in each of the following cases:

R P
(a) R
n∈N 1(0,1/2n ] (x) λ(dx), where λ is the Lebesgue measure on B(R);
R
(b) N x2 λ(dx), where λ is the Lebesgue measure on B(R);
R
(c) N 1/n µ(dn), where µ is the counting measure on the power set of N;
R
(d) R y 2 µ(dy), where µ is the measure on B(R) given by (cf. Example 5.4),
µ(B) =

N
X

px δx (B),

x=0

(
1,
δx (B) =
0,

with N ∈ N, and 0 ≤ px ≤ 1 for any x ∈ {1, . . . , N }.

73

if x ∈ B,
if x ∈
/ B,

Exercise 8.12. Let (Ω, F, µ) be a measure space Rand fn : Ω → R, n ∈ N, be a sequence of
F measurable and integrable functions s.t. supn∈N Ω fn (ω)µ(dω) < ∞. Show that if for any
ω ∈ Ω, fn (ω) ↑ f (ω), then f is integrable and
Z
Z
fn (ω)µ(dω) ↑
f (ω)µ(dω).
Ω

Ω

Hint: Consider the sequence of nonnegative and F measurable functions fn − f1 .
Exercise 8.13. Let (Ω, F, µ) be a measure space. Assume that M is another σ-field on Ω
s.t. M ⊂ F and µ|M is the restriction of µ to M. Suppose that f : Ω → R is M measurable.
Show that if either f is nonnegative or integrable with respect to µ, then,
Z
Z
f (ω)µ(dω) =
f (ω)µ|M (dω).
Ω

Ω

Exercise 8.14. Consider (R, B(R), λ), where λ is the Lebesgue measure on B(R). Let
n→∞
f (x) = 0 for any x ∈ R. Find a sequence of B(R) measurable functions s.t. fn (x) −−−−→ f (x)
R
n→∞
for any x ∈ R and R fn (x)λ(dx) −−−−→ ∞.

74

9

Integration: Part II

9.1

Pushforward measure

Definition 9.1. Let (Ω, F) and (Ω∗ , F ∗ ) be two measurable spaces and g : Ω → Ω∗ be F/F ∗
measurable. Suppose that µ is a measure on F. The measure µg −1 as given in Exercise 7.8
is referred to as the pushforward measure of µ.
Proposition 9.1. Let (Ω, F) and (Ω∗ , F ∗ ) be two measurable spaces, g : Ω → Ω∗ be F/F ∗
measurable, µ be a measure on F and µg −1 be the pushforward measure of µ. Let f : Ω∗ → R
be F ∗ measurable.
(i) If f is nonnegative, then for any A∗ ∈ F ∗ ,
Z
Z
f (g(ω))µ(dω) =
g −1 (A∗ )

f (ω ∗ )µg −1 (dω ∗ );

A∗

(15)

(ii) f is integrable with respect to µg −1 if and only if f (g) is integrable with respect to µ;
(iii) if f (g) is integrable with respect to µ, then (15) holds.
Proof. Notice first that since f is F ∗ measurable and g is F/F ∗ , the composition f (g) is
F measurable (cf. Exercise 7.2). In order to show (i), let f be nonnegative. If f = 1B ∗ ,
B ∗ ∈ F ∗ , then given any A∗ ∈ F ∗ ,
Z
Z
f (g(ω))µ(dω) =
1g−1 (A∗ ) (ω)1B∗ (g(ω))µ(dω)
g −1 (A∗ )
Ω
Z
=
1g−1 (A∗ ) (ω)1g−1 (B∗ ) (ω)µ(dω)
ZΩ
=
1g−1 (A∗ ∩B∗ ) (ω)µ(dω)
Ω
Z
= µ(g −1 (A∗ ∩ B ∗ )) = µg −1 (A∗ ∩ B ∗ ) =
1A∗ ∩B∗ (ω∗ )µg−1 (dω∗ ),
Ω∗

and thus (15) is satisfied. If f = i=1 αi 1Bi∗ is a nonnegative simple function (f is assumed
to be in standard from, cf. Proposition 7.7), then by Proposition 8.3,
X

Z
Z
N
αi 1Bi∗ (g(ω))µ(dω)
f (g(ω))µ(dω) =
PN

g −1 (A∗ )

g −1 (A∗ )

=

N
X

α1
g −1 (A∗ )

i=1

Z
=

i=1

Z

1

Bi∗


(g(ω))µ(dω)

f (ω ∗ )µg −1 (dω ∗ ).

A∗

where the last equality follows by the previous case. Let now f be any F ∗ measurable
and nonnegative function. We rely on Proposition 7.10 and find a sequence of nonnegative
standard simple functions (fn )n∈N s.t. for any ω ∗ ∈ Ω∗ , fn (ω ∗ ) ↑ f (ω ∗ ). By Proposition 8.2,
it follows from the previous case that
Z
 Z
Z
f (ω ∗ )µg −1 (dω ∗ ) = lim
fn (g(ω))µ(dω) =
f (g(ω))µ(dω).
A∗

n→∞

g −1 (A∗ )

g −1 (A∗ )

This completes the proof of (i). By Proposition 8.6, f is integrable with respect to µg −1 if
and only if
Z
|f (ω ∗ )|µg −1 (dω ∗ ) < ∞.
Ω∗

75

By (i), the latter integral is equla to
Z
Z
|f (g(ω))|µ(dω) = |f (g(ω))|µ(dω),
g −1 (Ω∗ )

Ω

thus, (ii) follows. It remains to show (iii). Suppose that f (g) is integrable with respect to
µ, i.e., f is integrable with respect to µg −1 . We write f = f + − f − and obtain
Z
Z
Z
f (ω ∗ )µg −1 (dω ∗ ) =
f + (ω ∗ )µg −1 (dω ∗ ) −
f − (ω ∗ )µg −1 (dω ∗ ).
A∗

A∗

A∗

Then, by (i),
Z

f + (ω ∗ )µg −1 (dω ∗ ) −

Z

f − (ω ∗ )µg −1 (dω ∗ )
Z
+
f (g(ω))µ(dω) −
f − (g(ω))µ(dω)

A∗

A∗

Z
=
g −1 (A∗ )

g −1 (A∗ )

Z
=

f (g(ω))µ(dω).
g −1 (A∗ )

9.2

Densities

Proposition 9.2. Let (Ω, F, µ) be a measure space and ϕ : Ω → R be a nonnegative and F
measurable function. Then, ν defined by
Z
ν(A) =
ϕ(ω)µ(dω), A ∈ F,
A

is a measure on F.
Definition 9.2. Let (Ω, F, µ) be a measure space and ν be a measure on F. A nonnegative
and F measurable
R function ϕ : Ω → R is said to be a density of ν with respect to µ if for any
A ∈ F, ν(A) = A ϕ(ω)µ(dω).
Proposition 9.3. Let (Ω, F, µ) be a measure space. Suppose that ν is a measure on F with
density ϕ with respect to µ. Then,
(i) for any nonnegative and F measurable function f ,
Z
Z
f (ω)ν(dω) =
f (ω)ϕ(ω)µ(dω),
A

A ∈ F;

(16)

A

(ii) f is integrable with respect to ν if and only if f ϕ is integrable with respect to µ;
(iii) if f ϕ is integrable with respect to µ, then (16) holds.
Proof. The proof is similar to the proof of Proposition 9.1, we leave it as an exercise (Exercise 9.6).
Example 9.1. If λ is the Lebesgue measure on B(R) and f is the identity, i.e., f (x) = x
for any x ∈ R and s.t. x 7→ xϕ(x) is integrable with respect to λ, then if ν has density ϕ with
respect to λ, we obtain
Z
Z
xν(dx) =
xϕ(x)λ(dx), A ∈ B(R).
A

A

76

9.3

Integration with respect to the Lebesgue measure on the real
line

In the following we cover integration methods that relate to the Lebesgue measure. In
particular, we compare the Lebesgue integral with the Riemann integral. A selection of
omitted proofs are given in Section B.6 of the appendix.
Definition 9.3. Consider the measure space (R, B(R), λ), where λ is the Lebesgue measure
on the Borel σ-field B(R). In accordance
with Definition 8.5, a B(R) measurable function
R
integrable
if
|f
(x)|λ(dx)
f : R → R is Lebesgue
R
RR
R < ∞. The integral of f with respect to
λ is denoted with R f (x)dx, i.e., R f (x)dx = R f (x)λ(dx). If E ⊂ R and λ|E is the
restriction of λ to B(E) (cf. Definition R4.2), then a B(E) measurable function f : E → R
is
integrable if E |f (x)|λ|E (dx) < ∞. Also in this case we write
R referred to as Lebesgue
R
f
(x)λ|
(dx)
=
f
(x)dx.
E
E
E
In accordance with the fact that the Lebesgue measure of a single point is zero, we adapt
the following definition.
Definition 9.4. If f : E → R is B(E) measurable and Lebesgue integrable we adapt the
following notation:
Z
Z b
f (x)dx =
f (x)dx, if A ∈ P(E) s.t. A ∈ {[a, b], (a, b], [a, b), (a, b)};
ZA
Za∞
f (x)dx =
f (x)dx if A ∈ P(E) s.t. A ∈ {(a, ∞), [a, ∞)}, a ∈ R;
A

a

Z

Z

b

f (x)dx =
A

f (x)dx

if A ∈ P(E) s.t. A ∈ {(−∞, b), (−∞, b]},

b ∈ R.

−∞

We review the definition of a Riemann integrable function:
Definition 9.5. Let [a, b] ⊂ R be a closed interval. A function f : [a, b] → R is called
Riemann integrable with integral If (a, b) if for any ε > 0 there exists δ > 0 s.t. for any
partition
a = a1 < a2 < · · · < aN +1 = b,
of [a, b] with λ([ai , ai+1 ]) < δ and xi ∈ [ai , ai+1 ], i = 1, . . . , N , it follows that
If (a, b) −

N
X

f (xi )λ([ai , ai+1 ]) < ε.

i=1

We relate the Riemann integral with the Lebesgue integral:
Proposition 9.4. Consider the measure space ([a, b], B([a, b]), λ|[a,b] ), where [a, b] ⊂ R is
a closed interval and λ|[a,b] is the Lebesgue measure restricted to B([a, b]). Assume that
f : [a, b] → R is B([a, b]) measurable and Riemann integrable. Then, f is Lebesgue integrable
Rb
and If (a, b) = a f (x)dx, i.e., the Riemann integral equals the Lebesgue integral of f on [a, b].
Remark 9.1. It can be shown that if f : [a, b] → R is continuous, then it is Riemann
integrable. Notice that f : [a, b] → R continuous, implies that f is B([a, b]) measurable (cf.
Remark 7.1). Hence, upon the latter proposition, if f : [a, b] → R is continuous, then it is
Rb
Lebesgue integrable and I(a, b) = a f (x)dx.
With respect to improper integrals, we have the following result:
Proposition 9.5. Let u ∈ (a, ∞) ∪ {∞}. Suppose that for any a < b < u, f restricted to
[a, b] is B([a, b]) measurable, nonnegative and Riemann
R u integrable. Then, if the improper
integral limb↑u If (a, b) = If (a, u) is s.t. If (a, u) ∈ R, a f (x)dx = If (a, u).
77

Actually, a more general version of Proposition 9.5, with f not necessarily nonnegative,
can be proven. It follows from the fact that if f : [a, b] → R is Riemann integrable, its
positive and negative parts are Riemann integrable as well.
Proposition 9.6. Let a, b ∈ R. We consider two cases,
(I) Let u ∈ (a, ∞) ∪ {∞}. Assume that for any a < b < u, f restricted to [a, b]
is B([a, b]) measurable and Riemann integrable. Suppose that the improper integral
limb↑u If (a, b) = If (a, u) is s.t. If (a, u) ∈ R.
(II) let u ∈ (−∞, b) ∪ {−∞}. Assume that for any u < a < b, f restricted to [a, b]
is B([a, b]) measurable and Riemann integrable. Suppose that the improper integral
lima↓u If (a, b) = If (u, b) is s.t. If (u, b) ∈ R.
Ru
Rb
We have that a f (x)dx = If (a, u) and u f (x)dx = If (u, b) in case (I) and (II), respectively.
The following result is often helpful in practice.
Proposition 9.7. Suppose that f : [a, b] → R is continuous with antiderivative F : [a, b] →
R, i.e., F ′ (x) = f (x) for any x ∈ [a, b], then
Z b
f (x)dx = [F (x)]ba = F (b) − F (a).
a

Example 9.2. Let E ⊂ R s.t. [a, b] ⊂ E. Define f = 1[a,b] . We can consider the measure
R
Rb
space (E, B(E), λ|E ) and by Proposition 8.1, E f (x)dx = a f (x)dx = λ([a, b]) = b − a.
Clearly, f |[a,b] is continuous with antiderivative F (x) = x, x ∈ [a, b]. Thus,
Z b
f |[a,b] (x)dx = [x]ba = b − a.
a

Exercise 9.1. Let f (x) = e

−x

R∞

, x ∈ [0, ∞). Show that

0

e−x dx = 1.

Definition 9.6. Let f : [a, b] → R be B([a, b]) measurable and Lebesgue integrable. The
integral of f when the limits of integration are reverted is defined as follows
Z b
Z a
f (x)dx = −
f (x)dx.
a

b

Definition 9.7. Let E ⊂ R and f : R → R be a function. f is even if f (−x) = f (x) and f
is odd if f (−x) = −f (x).
Example 9.3. The functions x 7→ cos(x) and x 7→ sin(x) are even and odd, respectively (cf.
Example 3.7).
Proposition 9.8. Let a ∈ (0, ∞) and f : [−a, a] → R be a B([−a, a]) measurable and
Lebesgue integrable function. Then, if f is odd,
Z a
f (x)dx = 0.
−a

Proof. We have that
Z

a

Z

a

f (x)dx =
−a

Z

0

f (x)dx +
Z

f (x)dx
−a
Z −a

0
a

f (x)dx −

=
0

Z
=

f (x)dx
0

a

Z
f (x)dx +

0

f (−x)dx
0

= 0.
78

a

R0
R −a
R −a
Ra
Notice that −a f (x)dx = − 0 f (x)dx by Definition 9.6 and − 0 f (u)du = 0 f (−x)dx
upon the substitution u = −x.
Ra
Example 9.4. For any a ∈ (0, ∞), −a sin(x)dx = 0. In particular,
Z

a

e−

x2
2

sin(x)dx = 0,

−a

since x 7→ e−x

2

/2

sin(x) is odd.

Exercise 9.2. Let a ∈ (0, ∞) and f : [−a, a] → R be a B([−a, a]) measurable and Lebesgue
integrable function. Show that if f is even,
Z a
Z a
f (x)dx.
f (x)dx = 2
−a

0

Exercise 9.3. Show that for any a ∈ (0, ∞),

9.4

Ra
−a

|x|dx = a2 .

Change of variable

Definition 9.8. Let U ⊂ Rm be an open set and T : U → Rk be a function. T is said
to be continuously differentiable on U if for any x0 ∈ U the partial derivatives ∂xj Ti (x0 ),
j = 1, . . . , m, i = 1, . . . , k, exist and are continuous on U .
Remark 9.2. For further details on the notion of differentiability of a function T : U → Rk ,
we refer to Section A.7. In particular, we note that the differential of a differentiable map
T : U → Rk in x0 ∈ U is represented in terms of the Jacobian matrix JT (x0 ) of f in x0 (cf.
Definition A.15 and Proposition A.24).
The following result is known as the change of variable theorem. For now, we omit a
proof and rely on common references such as [1] or [2].
Proposition 9.9. Let U and V be two open sets of Rk . Suppose that T : U → V is bijective,
continuously differentiable on U and s.t. det JT (x0 ) ̸= 0 for any x0 ∈ U . Then, if f : V → R
is nonnegative and B(V )/B(R) measurable we have that
Z
Z
f (T (x))|det JT (x)|dx =
f (y)dy.
(17)
U

V

Remark 9.3. If f inR Proposition 9.9 is B(V )/B(R)
R measurable but not necessarily nonnegative but s.t. both U |f (T (x)) det JT (x)|dx and V |f (y)|dy are finite, (17) still holds.
As a main application, Proposition 9.9 allows to integrate in polar coordinates.
Example 9.5. Let T : U → V be as in Example 2.7, i.e.,
T (ρ, θ) = (ρ cos(θ), ρ sin(θ)),

(ρ, θ) ∈ U,

where U = (0, ∞) × (0, 2π) and V = R2 \ ([0, ∞) × {0}). Clearly, U is an open subset of
R2 (cf. Example 2.4). If we write V = R2 ∩ ([0, ∞) × {0})c we readily see that also V is an
open subset of R2 (cf. Examples 2.14 and 2.19). Given (ρ, θ) ∈ U , we have that
∂x1 T1 (ρ, θ) = cos(θ), ∂x2 T1 (ρ, θ) = −ρ sin(θ), ∂x1 T2 (ρ, θ) = sin(θ), ∂x2 T2 (ρ, θ) = ρ cos(θ).
Thus, the partial derivatives exist and are all continuous on U (cf. Proposition 3.26). Hence,
T is continuously differentiable on U . Also, given any (ρ, θ) ∈ U , det JT (ρ, θ) = ρ > 0.
We have already seen in Example 2.7 that T : U → V is bijective. Hence, T satisfies the

79

assumptions of Proposition 9.9 and we deduce that for any nonnegative and B(V )/B(R)
measurable function f : V → R,
Z
Z
f (y)dy =
f (ρ cos(θ), ρ sin(θ))ρd(ρ, θ).
V

(0,∞)×(0,2π)

If we recall Definition 4.2, we notice that if f : R2 → R is nonnegative and B(R2 )/B(R)
measurable (i.e., a Borel function), then, the restriction f |V is B(V )/B(R) measurable.
This is because for any A ∈ B(R),
{y ∈ V : f |V (y) ∈ A} = {y ∈ V : f (y) ∈ A}
= {y ∈ R2 : f (y) ∈ A} ∩ V ∈ {B ∩ V : B ∈ B(R2 )},
since f is B(R2 )/B(R) measurable. We conclude that for any nonnegative Borel function,
Z
Z
f (y)dy =
f (ρ cos(θ), ρ sin(θ))ρd(ρ, θ).
(18)
V

(0,∞)×(0,2π)

In order to discover the full potential of (18), the next section allows for a further refinement
of (18), i.e., we introduce tools to integrate on product spaces.

9.5

Integration on product spaces

The following covers useful results concerning the integral on product spaces. The proofs
are given in the appendix (cf. Section B.7)
Definition 9.9. Let (X, X ) and (Y, Y ) be two measurable spaces. The product σ-field on
the cartesian product X × Y is defined by

X ⊗ Y = σ {A × B : A ∈ X , B ∈ Y } .
Remark 9.4. The latter definition extends to products of higher order. Consider a collection
of measure spaces (X1 , X1 ), . . . , (Xn , Xn ). We define

⊗ni=1 Xi = X1 ⊗ · · · ⊗ Xn = σ {A1 × · · · × An : Ai ∈ Xi , i = 1, . . . , n} .
One can then show that the latter product is associative. If n = 3, that means
(X1 ⊗ X2 ) ⊗ X3 = X1 ⊗ (X2 ⊗ X3 ) = X1 ⊗ X2 ⊗ X3 .
Example 9.6. Assume that X and Y are countable and consider the measurable spaces
(X, P(X)) and (Y, P(Y )), where P(X) and P(Y ) are the power sets on X and Y , respectively. Then,
P(X × Y ) = P(X) ⊗ P(Y ).
It is clear that P(X) ⊗ P(Y ) ⊂ P(X × Y ) (recall that P(X × Y ) is the largest possible σ-field
on X × Y ). With regard to the other inequality. Let S ⊂ X × Y . Then, since X and Y are
countable, X ×Y is countable (cf. Proposition 2.8) and in particular S is countable. We write
S = ∪(x,y)∈S {(x, y)} ∈ P(X) ⊗ P(Y ), since for any (x, y) ∈ S, {(x, y)} ∈ P(X) ⊗ P(Y ).
Therefore, P(X × Y ) ⊂ P(X) ⊗ P(Y ).
One of the most central results of measure theory is the following:
Proposition 9.10. Let (X, X , µ) and (Y, Y , ν) be two measure spaces where µ and ν are
σ-finite on X and Y , respectively. Then there exists a unique σ-finite measure µ ⊗ ν on
X ⊗ Y which is s.t. for any A ∈ X and B ∈ Y ,
µ ⊗ ν(A × B) = µ(A)ν(B).
80

The measure µ ⊗ ν of the latter proposition is called the product measure on X ⊗ Y .
Remark 9.5. Suppose that (X1 , X1 ), (X2 , X2 ) and (X3 , X3 ) are three measure spaces with
σ-finite measures µ1 , µ2 and µ3 . Then, upon the previous proposition, we obtain a unique
and σ-finite measure µ1 ⊗ µ2 on X1 ⊗ X2 s.t. for any Ai ∈ Xi , i = 1, 2,
µ1 ⊗ µ2 (A1 × A2 ) = µ1 (A1 )µ2 (A2 ).
Then, we consider the measurable spaces (X1 × X2 , X1 ⊗ X2 ) and (X3 , X3 ) and upon Proposition 9.10 again, we obtain a unique measure (µ1 ⊗ µ2 ) ⊗ µ3 on (X1 ⊗ X2 ) ⊗ X3 which is
s.t. for any Ai ∈ Xi , i = 1, 2, 3,
(µ1 ⊗ µ2 ) ⊗ µ3 (A1 × A2 × A3 ) = µ1 ⊗ µ2 (A1 × A2 )µ3 (A3 ) = µ1 (A1 )µ2 (A2 )µ3 (A3 ).
Then, since (X1 ⊗X2 )⊗X3 = X1 ⊗X2 ⊗X3 , (µ1 ⊗µ2 )⊗µ3 is a measure on X1 ⊗X2 ⊗X3 .
We define µ1 ⊗µ2 ⊗µ3 = (µ1 ⊗µ2 )⊗µ3 as the product measure on X1 ⊗X2 ⊗X3 . We remark
that the latter strategy can be iterated for products of higher order. If (X1 , X1 ), . . . , (Xn , Xn )
is a collection of measurable spaces where for any i = 1, . . . , n, µi is a σ-finite measure on
Xi , then we obtain a unique and σ-finite measure ⊗ni=1 µi on ⊗ni=1 Xi which is s.t. for any
Ai ∈ Xi , i = 1, . . . , n.
⊗ni=1 µi

Y
n


Ai

i=1

=

n
Y

µi (Ai ).

i=1

Example 9.7. Assume that X and Y are countable and consider the measurable spaces
(X, P(X)) and (Y, P(Y )), where P(X) and P(Y ) are the power sets on X and Y , respectively. If µ is the counting measure on P(X) and ν is the counting measure on P(Y ), then
µ⊗ν is the counting measure on P(X ×Y ). To see it, let S ∈ P(X)⊗P(Y ), i.e., S ⊂ X ×Y .
Write m for the counting measure on P(X × Y ). Since S is countable, S = ∪(x,y)∈S {(x, y)}.
Then, we obtain
[
[
[
µ ⊗ ν(S) =
µ ⊗ ν({(x, y)}) =
µ({x})ν({y}) =
m({(x, y)}) = m(S).
(x,y)∈S

(x,y)∈S

(x,y)∈S

Example 9.8. Let E × F ⊂ R × R. One can show that B(E) ⊗ B(F ) = B(E × F ), i.e., the
product σ field of B(E) and B(F ) on the cartesian product E ×F is equal to the Borel σ-field
on E × F . This can be generalized to products of higher orders: If Ei ⊂ R, i = 1, . . . , n, we
have that
B(E1 × · · · × En ) = B(E1 ) ⊗ · · · ⊗ B(En ).
(19)
In particular, we have that
B(R) ⊗ · · · ⊗ B(R) = B(Rn ).
{z
}
|
n-times

Further, if λ is the Lebesgue measures on B(R), then one can prove that λ2 = λ ⊗ λ,
i.e., the Lebesgue measure on B(R2 ) is equal to the product measure on B(R) ⊗ B(R) (cf.
Exercise 9.9). We recall that λ is σ-finite on B(R) (cf. Definition 6.4). In general, we
have that λ ⊗ · · · ⊗ λ = λn , i.e., the n-fold product of the Lebesgue measure on B(R) is the
Lebesgue measure on B(Rn ).
The next result is known as the Fubini-Tonnelli theorem.
Proposition 9.11. Let µ and ν be two σ-finite measures on the measurable spaces (X, X )
and (Y, Y ), respectively. Let f : X × Y → R be nonnegative and X ⊗ Y measurable. Then,

81

(i) the functions
Z

Z

X ∋ x 7→

f (x, y)ν(dy) and Y ∋ y 7→
Y

f (x, y)µ(dx),
X

are X and Y measurable, respectively;
(ii) we have that
Z
f (x, y)µ ⊗ ν(d(x, y))


Z Z
Z Z
=
f (x, y)ν(dy) µ(dx) =
f (x, y)µ(dx) ν(dy).
X×Y

X

X

Y

X

Regarding non necessarily nonnegative functions, we have the Fubini-Lebesgue theorem.
Proposition 9.12. Let µ and ν be two σ-finite measures on the measurable spaces (X, X )
and (Y, Y ), respectively.
Let f : X × Y → R be X ⊗ Y measurable and integrable with
R
respect to µ ⊗ ν, i.e., X×X |f (x, y)|µ ⊗ ν(d(x, y)) < ∞. Then,
R
R
(i) Y |f (x, y)|ν(dy) < ∞ µ a.e. on (X, X ) and X |f (x, y)|µ(dx) < ∞ ν a.e. on (Y, Y );
c
) = 0 and ν(FYc ) = 0, respectively,
(ii) there exist sets FX ∈ X and RFY ∈ Y s.t. µ(FX
whereR for any x ∈ FX , x 7→ Y f (x, y)ν(dy) is X measurable and for any y ∈ FY ,
y 7→ X f (x, y)µ(dx) is Y measurable;

(iii) we have that
Z Z

Z

Z

f (x, y)µ(dx) ν(dy) < ∞,

f (x, y)ν(dy) µ(dx) < ∞ and
Y

Y

X

X

and
Z
f (x, y)µ ⊗ ν(d(x, y))


Z Z
Z Z
=
f (x, y)ν(dy) µ(dx) =
f (x, y)µ(dx) ν(dy).
X×Y

X

Y

Y

X

Example 9.9. We consider the measure space ([0, ∞), B([0, ∞)), λ|[0,∞) ). Define the function
f (x, y) = e−(x+y) ,

(x, y) ∈ [0, ∞)2 .

Clearly, f is continuous on [0, ∞)2 and hence B([0, ∞)2 ) measurable. Since B([0, ∞)2 ) =
B([0, ∞))⊗B([0, ∞)), f is measurable with respect to the product σ-field on [0, ∞)2 . Further,
for Ai ∈ B([0, ∞)), i = 1, 2,
λ|[0,∞) ⊗ λ|[0,∞) (A1 × A2 ) = λ|[0,∞) (A1 )λ|[0,∞) (A2 ) = λ(A1 )λ(A2 ).
Also, since λ ⊗ λ = λ2 , it follows in particular that (λ ⊗ λ)|[0,∞)2 = λ2 |[0,∞)2 and we obtain
(λ ⊗ λ)|[0,∞)2 (A1 × A2 ) = λ2 |[0,∞)2 (A1 × A2 ) = λ(A1 )λ(A2 ).
Since a product measure is uniquely defined upon sets Ai ∈ B([0, ∞)), we deduce that
λ2 |[0,∞)2 = λ|[0,∞) ⊗ λ|[0,∞) .

82

Clearly, for any (x, y) ∈ [0, ∞)2 , f (x, y) > 0. Hence, we are in place to apply Proposition 9.11, and conclude that
Z
Z
e−(x+y) d(x, y) =
e−(x+y) λ2 |[0,∞)2 (d(x, y))
[0,∞)2
[0,∞)2
Z
=
e−(x+y) λ|[0,∞) ⊗ λ|[0,∞) (d(x, y))
[0,∞)×[0,∞)
∞Z ∞

Z

e

=

−(x+y)


Z
dy dx =

0

0

0

∞

e

−x

 Z
dx

∞

e

−y


dy

= 1.

0

Remark 9.6. Let E × F ⊂ Rk × Rm . We equip the product space E × F with the product
σ-field B(E) ⊗ B(F ) and the product measure λk |E ⊗ λm |F , where λk |E and λm |F represent
the Lebesgue measures on Rk and Rm restricted to E and F , respectively. To further simplify
the notation, if f : E × F → R is B(E) ⊗ B(F ) measurable (either nonnegative or integrable
w.r.t. λk |E ⊗ λm |F ), we adapt the notation
Z
Z
f (x, y)λk |E ⊗ λm |F (d(x, y)) =
f (x, y)d(x, y).
(20)
E×F

E×F

Notice that upon latter example (cf. Example 9.9 where k = m = 1), we always have
λ|E ⊗ λ|F = λ2 |E×F .
Hence, in this case, the integral (20) is the usual integral of f w.r.t. the Lebesgue measure
on B(E × F ) (recall also Example 9.8). Of course, this can be generalized to products of
higher orders: If Ei ⊂ R, i = 1, . . . , n, we always have that
⊗ni=1 λ|Ei = λn |Qni=1 Ei ,
Qn
and (20) is the usual integral ofQf w.r.t. the Lebesgue measure on B( i=1 Ei ). Finally,
n
n
n
we keep in mind (19),
Qn i.e., B( i=1 Ei ) = ⊗i=1 B(Ei ). In particular, f is ⊗i=1 B(Ei )
measurable
if it is B( i=1 Ei ) measurable (which is in particular the case if it is continuous
Qn
on i=1 Ei , cf. Remark 7.1).
Upon the introduced notation given in (20), the Fubini-Tonnelli theorem (cf. Proposition 9.11) leads to the following result:
Proposition 9.13. Let E × F ⊂ Rk × Rm . Given a nonnegative and B(E) ⊗ B(F ) measurable f : E × F → R, we always have
Z
f (x, y)d(x, y)
E×F


Z Z
Z Z
=
f (x, y)dy dx =
f (x, y)dx dy.
E

F

F

E

Similarly, upon Proposition 9.12, we obtain:
k
m
Proposition 9.14. Let E
R ×F ⊂ R ×R . Given a B(E)⊗B(F ) measurable f : E ×F → R
which is integrable, i.e., E×F |f (x, y)|d(x, y) < ∞, we always have
Z
f (x, y)d(x, y)
E×F


Z Z
Z Z
=
f (x, y)dy dx =
f (x, y)dx dy.
E

F

F

E

With respect to practical applications, the latter two proposition are primary tools for
the integration (w.r.t. the Lebesgue measure) of functions defined on real coordinate spaces.
83

Example 9.10. Let f : [0, 1] × [0, 1] → R be defined by f (x, y) = x2 y 2 . By Proposition 9.13,
we readily calculate:
2  2

Z 1
Z
Z 1 Z 1
1
1
2
2
2
x dx =
y dy dx =
x
f (x, y)d(x, y) =
= .
3
9
0
0
0
[0,1]2
Keep in mind that f is continuous on [0, 1]2 and hence B([0, 1]2 ) = B([0, 1]) ⊗ B([0, 1])
measurable.
Example 9.11. The convolution of two B(Rk ) measurable functions ϕ1 , ϕ2 : Rk → R can
be defined as
Z
ϕ1 ∗ ϕ2 (z) = 1A (z)
ϕ1 (z − x)ϕ2 (x)dx, z ∈ Rk ,
Rk

k
where A = {z ∈
< ∞} (cf. Example 8.5, where A = R). We
R R : Rk |ϕ1 (z − x)ϕ2 (x)|dx
R
remark that if Rk |ϕ1 (x)|dx < ∞ and Rk |ϕ2 (x)|dx < ∞ (i.e., ϕ1 and ϕ2 are integrable),
then λk (Ac ) = 0. To see it, we apply Fubini-Tonnelli (cf. Proposition 9.13) and write

 Z

Z
Z Z
|ϕ2 (x)|dx < ∞.
(21)
|ϕ1 (x)|dx
|ϕ1 (z − x)ϕ2 (x)|dx dz =

R

Rk

Rk

Rk

Rk

We remark that it can be shown that the map (x, z) 7→ |ϕ1 (z − x)ϕ2 (x)| is B(RkR) ⊗ B(Rk )
measurable (cf. Proposition B.7). In conclusion, by item (ii) of Proposition 8.5, Rk |ϕ1 (z −
c
x)ϕ2 (x)|dx < ∞ λk a.e.,
R i.e., λk (A ) = 0. This shows that for integrable ϕ1 and ϕ2 , we
have that ϕ1 ∗ ϕ2 (z) = Rk ϕ1 (z − x)ϕ2 (x)dx almost Reverywhere with respect to λk . Notice
further that (21) and Exercise 8.6 imply that that Rk |ϕ1 ∗ ϕ2 (z)|dz < ∞, i.e., ϕ1 ∗ ϕ2
is integrable. Hence, the convolution of two integrable functions is again integrable. For
integrable functions
R ϕ1 , ϕ2 and ϕ3 , we define ϕ1 ∗ ϕ2 ∗ ϕ3 (z) = (ϕ1 ∗ ϕ2 ) ∗ ϕ3 (z). Again,
ϕ1 ∗ ϕ2 ∗ ϕ3 (z) = Rk ϕ1 ∗ ϕ2 (z − x)ϕ3 (x)dx λk a.e. In general, for n integrable functions
ϕ1 , . . . , ϕn : Rk → R, we define
ϕ1 ∗ · · · ∗ ϕn (z) = (· · · ((ϕ1 ∗ ϕ2 ) ∗ ϕ3 ) ∗ · · · ∗ ϕn−2 ) ∗ ϕn−1 ) ∗ ϕn (z),
|
{z
}

z ∈ Rk ,

(22)

=ϕ1 ∗···∗ϕn−1

R
where ϕ1 ∗ · · · ∗ ϕn (z) = Rk ϕ1 ∗ · · · ∗ ϕn−1 (z − x)ϕn (x)dx λk a.e. The map ϕ1 ∗ · · · ∗ ϕn is
referred to as the n-fold convolution of ϕ1 , . . . , ϕn .

9.6

Integration in polar coordinates

We reconsider Example 9.5. In particular, we further develop equation (18). The general
result reads as follows:
Proposition 9.15. Let f : R2 → R be a nonnegative Borel function (i.e., B(R2 ) measurable). Then,

Z
Z 2π  Z ∞
f (y)dy =
f (ρ cos(θ), ρ sin(θ))ρdρ dθ
R2

0

Z

∞

Z

0
2π

=
0


f (ρ cos(θ), ρ sin(θ))dθ ρdρ.

0

Proof. Let T : U → R2 be defined as in Example 9.5, i.e.,
T (ρ, θ) = (ρ cos(θ), ρ sin(θ)),

(ρ, θ) ∈ U.

Since T is continuous on U , it is B(U )/B(R2 ) measurable (cf. Remark 7.1). Therefore,
by Exercise 7.2, since f is B(R2 )/B(R) measurable, f ◦ T : U → R is nonnegative and
84

B(U )/B(R) measurable, i.e., B((0, ∞) × (0, 2π)) measurable. We apply Proposition 9.13 to
the right hand side of (18) and obtain

Z
Z 2π  Z ∞
f (ρ cos(θ), ρ sin(θ))ρdρ dθ
f (y)dy =
V

0

Z

∞

Z

0
2π

=


f (ρ cos(θ), ρ sin(θ))dθ ρdρ,

0

0

where V = R2 \ ([0, ∞) × {0}). Since V c = [0, ∞) × {0} = ∪n∈N ([0, n) × {0}), we obtain (cf.
Example 9.8),
λ2 (V c ) = lim λ2 ([0, n) × {0}) = lim λ([0, n))λ({0}) = 0.
n→∞

Then, by Exercise 8.7,

n→∞

f (y)dy = R2 f (y)dy and the proposition is proven.
R ∞ −x2
Example 9.12. Let A = −∞ e
dx. By Proposition 9.13 and Proposition 9.15,
Z

2

A =

e

R

R

V

−(x2 +y 2 )

∞

Z

e

d(x, y) =

R2

−ρ2

Z

∞



Z

dθ ρdρ = 2π

∞

2

e−ρ ρdρ.

0

0

0

Then, upon the substitution u = ρ2 ,
Z

2π

2

e−ρ ρdρ = 1/2.

0

Hence, A =

√

π.

Exercise 9.4. Let Dr (0) = Br [0] ⊂ R2 be the closed ball (i.e. disk) with radius r and center
at the origin. Show that λ2 (Dr (0)) = πr2 .

9.7

Solution to exercises

Solution 9.1 (Solution to Exercise 9.1). We have that f is continuous with antiderivative
F (x) = − e−x . Therefore, we obtain,
Z ∞
Z b
−x
e dx = lim
e−x dx = lim [− e−x ]b0 = 0 − (−1) = 1,
b↑∞

0

b↑∞

0

since limb↑∞ (− e−b ) = 0.
Solution 9.2 (Solution to Exercise 9.2). We have that
Z a
Z 0
Z
f (x)dx =
f (x)dx +
−a

−a

a

f (x)dx.

0

Ra
R0
Hence, it is sufficient to show that −a f (x)dx = 0 f (x)dx. Using the substitution u(x) =
−x, we obtain that
Z 0
Z u(0)
Z 0
Z a
Z a
f (x)dx = −
f (−u)du = −
f (−u)du =
f (−u)du =
f (u)du.
−a

u(−a)

a

0

0

Solution
R a 9.3 (Solution
R a to Exercise 9.3). Since x 7→ |x| is even, we rely on Exercise 9.2 and
obtain −a |x|dx = 2 0 xdx = a2 .
Solution 9.4 (Solution to Exercise 9.4). By Proposition 9.15, we have that
Z
Z r  Z 2π 
λ2 (Dr (0)) =
1Dr (0) (y)dy =
ρ
dθ dρ = πr2 .
R2

0

85

0

9.8

Additional exercises

Exercise 9.5. Prove Proposition 9.2.
Exercise 9.6. Prove Proposition 9.3.
Exercise 9.7. Calculate the following integrals:
R∞
(a) 0 x e−x dx;
(b)

1
2π

(c)

R

R
R2

[0,1]2

e−(

x2
2

2

+ y2 )

d(x, y);

xy 1g−1 ((−∞,0]) (x, y)d(x, y), with g(a, b) = b − a, a, b ∈ R.

Exercise 9.8. Let (X1 , X1 ), (X2 , X2 ), and (X3 , X3 ) be measurable spaces. Show that
(X1 ⊗ X2 ) ⊗ X3 = X1 ⊗ X2 ⊗ X3 .
Exercise 9.9. Show that λ2 = λ ⊗ λ, i.e., the product of the Lebesgue measure on B(R)
equals the Lebesgue measure on B(R2 ).

86

10

General notions in Probability

A selection of omitted proofs of this chapter is found in Appendix C.

10.1

Probability spaces

Definition 10.1. Let (Ω, F) be a measurable space. A probability P on F is a measure on
F s.t. P(Ω) = 1. The triple (Ω, F, P) is a referred to as a probability space.
Example 10.1. Let Ω be a finite and nonempty set. Define
P(A) =

#A
,
#Ω

A ∈ P(Ω),

(23)

where P(Ω) is the power set on Ω. Then, P is a probability on P(Ω) (cf. Example 5.2).
Example 10.2. Let C be a set s.t. #C = 52. Suppose that
C = S1 ∪ S2 ∪ S3 ∪ S4 ,
with {S1 , S2 , S3 , S4 } disjoint and s.t. #Si = 13 for any i = 1, 2, 3, 4. We remain in the
setting of the previous example with
Ω = {A ⊂ C : #A = 5},
and P on P(Ω) defined as in (23). Upon Exercise 1.11, we already know that #Ω =
Let
Ai = {A ⊂ Si : #A = 5},

52
5



.

i = 1, 2, 3, 4,

and define A = A1 ∪ A2 ∪ A3 ∪ A4 . Since {A1 , A2 , A3 , A4 } ⊂ P(Ω) is disjoint, it follows that

4 13
P(A) = 525 .
5

If we interpret C as the collection of 52 poker cards with suits defined upon S1 , S2 , S3 and
S4 , P(A) is the probability of a flush, i.e., obtaining a poker hand which consists only of
cards of the same suit.
Exercise 10.1. Let Ω = {(ω1 , ω2 ) : ω1 , ω2 ∈ {1, 2, 3, 4, 5, 6}} and define P on P(Ω) as in
(23). Let A = {(ω1 , ω2 ) ∈ Ω : ω2 > ω1 }. Calculate P(A).
Example 10.3. Consider the measurable space ([0, 1], B([0, 1])), where B([0, 1]) is the Borel
σ-field on [0, 1]. Then, λ|[0,1] , the restriction of the Lebesgue measure to B([0, 1]) is a
probability on B([0, 1]). Similarly, the measure
P(A) =

λ|[a,b] (A)
,
λ|[a,b] ([a, b])

A ∈ B([a, b]),

is a probability on B([a, b]), a < b, a, b ∈ R.

10.2

Random variables and random vectors

Definition 10.2. Let (Ω, F) be a measurable space. A map X : Ω → R is referred to as a
random variable on (Ω, F) if it is F/B(R) measurable.
Example 10.4. Any continuous map f : [a, b] → R is a random variable on ([a, b], B([a, b]))
(cf. Remark 7.1). In particular, the identity map g(x) = x, x ∈ [a, b], is a random variable
on ([a, b], B([a, b])).
87

Example 10.5. Let Ω = {(i, j) : i, j ∈ {1, 2, 3, 4, 5, 6}}, then the map X((i, j)) = min{i, j},
(i, j) ∈ Ω, is a random variable on (Ω, P(Ω)).
Example 10.6. If
i , i = 1, . . . , n, are s.t. Xi is a random variable on (Ω, F) for any
PX
n
i = 1, . . . , n, then i=1 Xi is a random variable on (Ω, F) (cf. Proposition 7.12).
Definition 10.3. Let (Ω, F) be a measurable space. A map X : Ω → Rk is referred to as a
random vector on (Ω, F) if it is F/B(Rk ) measurable.
Remark 10.1. By Proposition 7.4, X = (X1 , . . . , Xk ) is a random vector on (Ω, F) if and
only if Xi is a random variables on (Ω, F) for any i = 1, . . . , k. In particular, for k = 1,
X is a random variable. In what follows, if no distinction is needed, our results are primed
for random vectors and the respective result for random variables follows by considering the
case where k = 1.
Example 10.7. Let Ω = {(i, j) : i, j ∈ {1, 2, 3, 4, 5, 6}}. Given (i, j) ∈ Ω, define X1 ((i, j)) =
min{i, j} and X2 ((i, j)) = max{i, j}. Then, X = (X1 , X2 ) is a random vector on (Ω, P(Ω)).
Example 10.8. Let X = (X1 , . . . , Xk ) be a random vector on (Ω, F) and g : Rk → R be
B(Rk )/B(R) measurable. Then, g(X) is a random variable on (Ω, F). In particular, if g is
continuous, g(X) is a random variable on (Ω, F).
We note that a direct consequence of Proposition 7.13 is the following result.
Proposition 10.1. Let (Ω, F, P) be a probability space and X be a random vector on (Ω, F).
A random variable Y on (Ω, F) is σ(X) measurable if and only if there exists a function
f : Rk → R which is B(Rk ) measurable and s.t. Y = f (X).
Definition 10.4. Let (Ω, F, P) be a probability space. The distribution or law of a random
vector X on (Ω, F) is the pushforward measure PX = PX −1 on B(Rk ) (cf. Definition 9.1).
In particular, for any B ∈ B(Rk ) we use the simplified notation
{ω ∈ Ω : X(ω) ∈ B} = {X ∈ B},
and hence
PX (B) = P(X ∈ B).
For now, unless mentioned otherwise, if (Ω, F, P) is a probability space any random
vector X is a random vector on (Ω, F), i.e., a F measurable functions with values in Rk .

10.3

Discrete laws

Definition 10.5. Let (Ω, F, P) be a probability space. A random vector is referred to as
discrete if there exists a countable set E = E1 × · · · × Ek ⊂ Rk s.t. PX (E) = 1. That is to
say that the law of X has a countable support.
Proposition 10.2. Let (Ω, F, P) be a probability space. A random vector X is discrete if
and only if
X
PX =
px δx , px = P(X = x),
(24)
x∈E

for some P
countable set E = E1 × · · · × Ek ⊂ Rk . In particular, for any B ∈ B(Rk ),
PX (B) = x∈B∩E px .
Remark 10.2. The latter proposition shows that the law of a discrete random vector X
with support E is determined by P(X = x), x ∈ E. Notice that the measure PX given in
(24) was already introduced in the more general setting of Example 5.4.
88

Proof of Proposition 10.2. Suppose that X is discrete. Let B ∈ B(Rk ). We have that
 [

X
X
PX (B) = PX (B ∩ E) = P(X ∈ B ∩ E) = P
{X = x} =
px =
px δx (B).
x∈B∩E

x∈B∩E

x∈E

With respect to the other direction, if PX is given by (24), then
X
X
1 = PX (Rk ) =
px δx (Rk ) =
px = P(X ∈ E) = PX (E),
x∈E

x∈E

i.e., X is a discrete random vector according to Definition 10.5.
Example 10.9. Let Ω = {t, h} and
(
0,
X(ω) =
1,

if ω = t,
if ω = h.

Then, X is a random variable on (Ω, P(Ω)). Suppose that P is a probability on P(Ω) s.t.
P(X = 0) = 1 − p and P(X = 1) = p. Clearly, PX ({0, 1}) = 1. By Proposition 10.2, we
deduce that the law of X is given by
PX = (1 − p)δ0 + pδ1 .
That is, for any B ∈ B(R),

0,



1 − p,
PX (B) =
p,



1,

if
if
if
if

0∈
/B
0∈B
0∈
/B
0∈B

and
and
and
and

1∈
/ B,
1∈
/ B,
1 ∈ B,
1 ∈ B.

Notice that PX was already introduced in Exercise 5.2.
Example 10.10. Let ∅ =
̸ E ⊂ Rk be a countable set. Generally, a measure
X
P =
px δx , px ≥ 0,
x∈E

defined on B(Rk ) which satisfies x∈E px = 1, is referred to as a discrete probability distribution. In the following we list some classical examples.
P

Discrete uniform: E ⊂ R is a finite set s.t. #E = n and px = 1/n for any x ∈ E;
Bernoulli: E = {0, 1} and p0 = 1 − p and p1 = p, p ∈ [0, 1];

Binomial: E = {0, 1, . . . , n}, n ∈ N and px = nx px (1 − p)n−x , p ∈ [0, 1];
Geometric: E = N and px = (1 − p)x−1 p, p ∈ (0, 1);
Poisson: E = N ∪ {0} and px = (λx /x!) e−λ , λ > 0;
Pk
Multinomial E = {(x1 , . . . , xk ) ∈ {0, . . . , N }k :
i=1 xi = N }, N ∈ N, and

p(x1 ,...,xk ) =

N!
Qk

i=1 (xi !)


px1 1 · . . . · pxkk ,

with pi ∈ [0, 1] for any i = 1, . . . , k
Pn
Exercise 10.2. Verify that x=0 px = 1, px =
89

k
X

pk = 1,

i=1

n
x



px (1 − p)n−x , p ∈ [0, 1].

Exercise 10.3. Verify that

P∞

x=0

px = 1, px = (λx /x!) e−λ , λ > 0.

Remark 10.3. If X = (X1 , . . . , Xk ) : Ω → Rk is discrete with support E = E1 × · · · × Ek ,
we apply Proposition 10.2 and deduce that for any i = 1, . . . , k,
P(Xi = x) = P(X1 ∈ R, . . . , Xi−1 ∈ R, Xi = x, Xi+1 ∈ R, . . . , Xk ∈ R)
= PX (R × · · · × R × {x} × R × · · · × R)
X
=
px1 ,...,xk .
(x1 ,...,xk )∈E
xi =x

Given i = 1, . . . , k, we apply the notation,
x−i = (x1 , . . . , xi−1 , xi+1 , . . . , xk ),
and
E−i = E1 × · · · × Ei−1 × Ei+1 · · · × Ek .
Then, we obtain
P(Xi = x) =

X

px1 ,...,xi−1 ,x,xi+1 ,...,xk .

(25)

x−i ∈Ei−1

Notice that the sum in (25) is zero if x ∈
/ Ei . Thus, for any i = 1, . . . , k, Xi has support
Ei . Further, since the law of Xi is determined by Ei , i = 1, . . . , k (cf. Remark 10.2), it is
sufficient to compute (25) for x ∈ Ei . If n = 2, (25) gives,
X
P(X1 = x) =
P({X1 = x} ∩ {X2 = x2 }), x ∈ E1 ;
x2 ∈E2

P(X2 = y) =

X

P({X1 = x1 } ∩ {X2 = y}),

y ∈ E2 .

x1 ∈E1

A formal treatment on how to compute the sum (25) for general n is given in Section B.8
of the appendix (cf. Proposition B.11).

10.4

Continuous laws

Definition 10.6. Let (Ω, F, P) be a probability space. A random vector is referred to as
continuous if the law of X has density ϕ : Rk → [0, ∞) with respect to the Lebesgue measure
on B(Rk ) (cf. Definition 9.2). That is, for any B ∈ B(Rk ),
Z
PX (B) =
ϕ(x)dx.
B

The density ϕ of PX is referred to as a probability density function.
Remark 10.4. Recall that by definition of a density, a probability density function is B(Rk )
measurable. Notice that if X is a continuous random variable with probability density funcRb
tion ϕ, then, for any a < b, P(a ≤ X ≤ b) = a ϕ(x)dx.
Example 10.11. Suppose that X = (X1 , X2 ) is a random vector with probability density
function
(
e−(x1 +x2 ) , if (x1 , x2 ) ∈ [0, ∞)2 ,
ϕ(x1 , x2 ) =
0,
otherwise.

90

By Proposition 9.13 (take E = F = R, recall also Example 9.9 and that B(R2 ) = B(R) ⊗
B(R)), we obtain that for any A × B, A ∈ B(R) and B ∈ B(R),
 Z

Z
−x1
−x2
dx1
e
dx2 .
(26)
PX (A × B) = P(X1 , X2 ) ∈ A × B) =
e
B

A

R

Therefore, if we set PX1 (C) = PX2 (C) =

C

e−x dx, C ∈ B(R), we deduce that

PX (A × B) = PX1 (A)PX2 (B) = PX1 (A)PX1 (B).
R
Example 10.12. Generally, the map B 7→ P (B) = RB ϕ(x)dx, ϕ : Rk → [0, ∞) is a measure
on B(Rk ) (cf. Proposition 9.2) and if in addition R ϕ(x)dx = 1, P is referred to as a
probability distribution with probability density function
R ϕ. We use the notation P (dx) =
ϕ(x)dx to indicate that for any B ∈ B(Rk ), P (B) = B ϕ(x)dx. In the following we give
some classical examples of probability distributions with probability density function ϕ.
Continuous uniform: Given a, b ∈ R, a < b,
ϕ(x) =

1
1[a,b] (x),
b−a

x ∈ R;

Exponential: Given λ > 0,
ϕ(x) = λ e−λx 1[0,∞) (x),

x ∈ R;

Normal: Given µ ∈ R and σ ∈ (0, ∞),
ϕ(x) = √

1
2πσ 2

e−

(x−µ)2
2σ 2

,

x ∈ R;

Multivariate Normal: Given Σ ∈ Rk×k , positive definite and symmetric, and µ ∈ Rk ,
ϕ(x) = p

1
(2π)k

1

det Σ

e− 2 (x−µ)

t

Σ−1 (x−µ)

,

x ∈ Rk .

(27)

Definition 10.7. Let (Ω, F, P) be a probability space. Suppose that for any ω ∈ Ω, S(ω) is
a statement on Ω. We say S is true P almost surely (a.s.) if P({ω : S(ω) is true}) = 1 (cf.
Definition 8.4).
Definition 10.8. Let (Ω, F, P) be a probability space and X be a random variable. Suppose
that µ ∈ R and σ ≥ 0. Then, X ∼ N (µ, σ 2 ) is to say that X is Gaussian (or normal) with
mean µ and variance σ 2 . If σ > 0, X ∼ N (µ, σ 2 ) indicates that the law of X has probability
density function
(x−µ)2
1
ϕ(x) = √
e− 2σ2 , x ∈ R.
(28)
2πσ 2
If σ = 0, X ∼ N (µ, 0) indicates that P(X = µ) = 1, i.e., X is constant and equal to µ P
a.s. If X ∼ N (0, 1), X is said to be standard Gaussian (or normal).
√
Remark 10.5. Let µ ∈ R and σ > 0. If we substitute u = (x − µ)/( 2σ), we obtain with
Example 9.12,
Z ∞
√
√ Z ∞ −u2
√ √
(x−µ)2
− 2σ2
dx = 2σ
e
du = 2σ π = 2πσ 2 .
e
−∞

−∞

91

10.5

Expectation

Definition 10.9. Let (Ω, F, P) be a probability space and X be a random variable. In either
case
• X is nonnegative;
• X is integrable with respect to P;
the expectation of X is defined by
Z
E[X] =

X(ω)P(dω).
Ω

If X = (X1 , . . . , Xk ) is a random vector, E[X] = (E[X1 ], . . . , E[Xk ]) is defined if E[Xi ] is
defined for any i = 1, . . . , k.
Proposition 10.3. Let (Ω, F, P) be a probability space and X be a random vector. Then,
for any nonnegative and B(Rk ) measurable map f : Rk → R,
Z
E[f (X)] =
f (x)PX (dx).
(29)
Rk

In addition, if f is not necessarily nonnegative, (29) is also satisfied if E[|f (X)|] < ∞.
Proof. Since f (X) : Ω → R is nonnegative and F measurable, it follows that E[f (X)] is well
defined. Using Proposition 9.1 with g = X, we obtain that
Z
Z
E[f (X)] =
f (X(ω))P(dω) =
f (x)PX (dx).
Rk

Ω

For the case where E[|f (X)|] < ∞, the result also follows from Proposition 9.1.
Example 10.13. Let (Ω, F, P) be a probability space. Suppose that X is a discrete random
variable with support E and s.t. either
(i) for any x ∈ E, x ≥ 0, i.e., P(X ≥ 0) = 1, that is X ≥ 0 P a.s.;
or
(ii) E[|X|] < ∞.
Then, in case (i) E[X] is well defined and we have that X = X 1[0,∞) P a.s. We apply
Proposition 10.3 with f (x) = x1[0,∞) (x) and deduce that
 X
Z ∞
X Z ∞
X
E[X] = E[f (X)] =
xPX (dx) =
xpy δy (dx) =
ypy =
xP(X = x).
0

y∈E

0

y∈E

x∈E

Keep in mind Example 8.8, Exercise 8.10 and Proposition 10.2. In case (ii), E[X] is well
defined as well and we apply Proposition 10.3 with f : R → R be the identity map, i.e.,
f (x) = x, x ∈ R and obtain
 X
Z
X Z
X
E[X] =
xPX (dx) =
xpy δy (dx) =
ypy =
xP(X = x).
R

y∈E

R

y∈E

x∈E

Example 10.14. Let (Ω, F, P) be a probability space. Suppose that X is a continuous
random variable with probability density function ϕ. Suppose that either
(i) X ≥ 0 P a.s.;
92

or
(ii) E[|X|] < ∞.
In case (i), E[X] is well defined, X = X 1[0,∞) P a.s. and we apply Proposition 10.3 with
f (x) = x1[0,∞) (x) to deduce that
Z ∞
Z ∞
E[X] = E[f (X)] =
xPX (dx) =
xϕ(x)dx.
0

0

Keep in mind Proposition 9.3. In case (ii), E[X] is well defined and we let f : R → R be the
identity map and again apply Propositions 10.3 and 9.3 to deduce that
Z
Z
E[X] =
xPX (dx) =
xϕ(x)dx.
R

R

Example 10.15. Let X be a discrete random variable with Poisson distribution, i.e., P(X =
x) = (λx /x!) e−λ , x ∈ N ∪ {0}, λ > 0. We notice that 1 = PX (N ∪ {0}) = P(X ∈ N ∪ {0}).
That is, X ≥ 0 P a.s. Hence, upon Example 10.13, E[X] is well defined and we calculate
E[X] = e

−λ

∞
∞
∞
X
X
X
λk
λk−1
λk
−λ
−λ
=e
= λe
= λ e−λ eλ = λ < ∞.
k
k!
(k − 1)!
(k − 1)!
k=1

k=0

k=1

Example 10.16. Let X be a continuous random variable with uniform distribution, i.e.,
PX has probability density function ϕ(x) = 1/(b − a)1[a,b] (x), x ∈ R. We apply Proposition 10.3 with f (x) = |x|, x ∈ R and readily notice that E[|X|] < ∞. Recall that x 7→ |x|
is continuous on [a, b] and hence Riemann integrable, i.e., E[|X|] < ∞ follows directly from
Proposition 9.4. Thus, by Example 10.15, we have that E[X] is well defined and
Z b
(b − a)(b + a)
(a + b)
b2 − a 2
1
=
=
.
xdx =
E[X] =
b−a a
2(b − a)
2(b − a)
2
Example 10.17. Let Ω = {(i, j) : i, j ∈ {1, 2, 3, 4, 5, 6}} as given in Example 10.7. Define
the random variable X((i, j)) = i + j, (i, j) ∈ {1, 2, 3, 4, 5, 6}2 . X is nonnegative and hence
E[X] is well defined and we calculate
6

E[X] =

X

(i + j)P(X = (i, j)) =

(i,j)∈Ω

X

1
1 X
(i + j)
=
36
36 i=1

(i,j)∈Ω

X
6


(i + j)

j=1

 6 

 6 

6
X
1 X
1 X
6(6 + 1)
=
6i +
j
=
6i +
36 i=1
36 i=1
2
j=1


1 36(6 + 1) 36(6 + 1)
=
+
= 7.
36
2
2
Keep in mind Example 1.7.
Example 10.18. Suppose that X ∼ N (µ, σ 2 ). We verify that E[X] = µ. If σ = 0, then, by
Definition 10.8, P(µ = X) = 1, i.e., by Exercise 8.3,
Z
Z
µ = µP(Ω) =
µP(dω) =
X(ω)P(dω) = E[X].
Ω

Ω

Hence, suppose that σ > 0. Consider the case where µ = 0 and σ = 1 (i.e., X is standard
normal). Upon a substitution u = x2 /2 we obtain
Z
0

b

2
1
√ x e−x /2 dx =
2π

Z
0

b2

2

b2
1
1 
1 − e−b
√ e−u du = √
− e−u 0 = √
.
2π
2π
2π
93

Hence, limb↑∞

Rb
0

√
√
2
(1/ 2π)x e−x /2 dx = 1/( 2π). Similarly, we verify that
0

Z

2
1
−1
√ x e−x /2 dx = √ .
2π
2π

lim

a↓−∞

a

Therefore E[X] = 0. Now, if µ ∈ R and σ > 0, we obtain
Z ∞
Z ∞
2
2
2
1
1
√
√ (xσ + µ) e−x /2 dx
x e−(x−µ) /(2σ ) dx =
2π
2πσ 2
−∞
−∞
Z ∞
2
1
√ e−x /2 dx = µ,
=µ
2π
−∞
√
R∞
2
2
since −∞ (1/ 2π) e−x /2 dx = 1. Notice that x 7→ |x| e−x /2 is continuous on [a, b] for
any a ̸= b, a, b ∈ R. Therefore, the latter map is Riemann integrable on [a, b] and in
particular, Lebesgue integrable and both integrals agree (cf. Proposition 9.4). Further, since
2
x 7→ |x| e−x /2 is even we recall Exercise 9.2 and obtain
Z

∞

|x| e

−x2 /2

b

Z

|x| e

dx = lim 2
b↑∞

−∞

−x2 /2

Z
b↑∞

0

Hence, by Proposition 9.6, x 7→ x e−x

2

/2

b

dx = lim 2

x e−x

2

/2

dx = 2.

0

is Lebesgue integrable.

Remark 10.6. Let (Ω, F, P) be a probability space and X be a random vector where the law
of X is unknown. We notice that by Proposition 10.3, for any A ∈ B(Rk ),
Z
Z
E[1A (X)] =
1A (X(ω))P(dω) =
1A (x)PX (dx) = PX (A).
Rk

Ω

Hence, Proposition 10.3 allows us to identify the law of X.
Example 10.19. Let (Ω, F, P) be a probability space and X = (X1 , . . . , Xk ) be a random vector where the distribution of X has probability density function ϕ(x1 , . . . , xk ), (x1 , . . . , xk ) ∈
Rk . Then, for any i = 1, . . . , k, the law of Xi has probability density function
Z
pi (x) =
ϕ(x1 , . . . , xi−1 , x, xi+1 , . . . , xk )d(x1 , . . . , xi−1 , xi+1 , . . . , xk ), x ∈ R. (30)
Rk−1

To see it, let i ∈ {1, . . . , k}. Given (x1 , . . . , xk ) ∈ Rk , define the map πi (x1 , . . . , xk ) = xi .
Then, for any nonnegative B(R) measurable function f : R → R, we apply Proposition 10.3
with f (πi ) and obtain
E[f (Xi )] = E[f (πi (X)]
Z
=
f (xi )ϕ(x1 , . . . , xk )d(x1 , . . . , xk )
Rk
Z

Z
=
f (xi )
ϕ(x1 , . . . , xk )d(x1 , . . . , xi−1 , xi+1 , . . . , xk ) dxi ,
R

Rk−1

where we made use of Proposition 9.13 (recall also Example 9.8).
Example 10.20. Let (Ω, F, P) be a probability space and U be a random variable with
uniform law on [0, 1], i.e., PU (dx) = 1[0,1] (x)dx. Define the random variable X = −2 log(U ).
By Proposition 10.3, for any f : R → R, nonnegative and B(R) measurable,
Z
E[f (X)] = E[f (−2 log(U ))] =

f (−2 log(u))1[0,1] (u)du =

Z

f (−2 log(u))du.
0

R

94

1

We substitute x(u) = −2 log(u) (dx/du = −2/u ⇔ du = −u/2) and obtain for any ε > 0
Z

1

Z

x(1)

f (−2 log(u))du =
ε

x(ε)



Z x(ε)
e−x/2
e−x/2
f (x) −
dx =
f (x)
dx,
2
2
0

where we recall Definition 9.6. Hence,
Z
ε→0

x(ε)

f (x)

lim

0

e−x/2
dx =
2

Z

∞

f (x)
0

e−x/2
dx = lim
ε→0
2

Z

1

f (−2 log(u))du = E[f (X)].
ε

By Remark 10.6, PX (dx) = 2−1 e−x/2 dx, i.e., the law of X is exponential with λ = 1/2.
Exercise 10.4. Let X ∼ N (µ, σ 2 ), σ > 0. Show that X − µ ∼ N (0, σ 2 ).
The following is known as Markov’s inequality:
Proposition 10.4. Let (Ω, F, P) be a probability space and X be a random variable s.t.
E[|X|p ] < ∞ where p ∈ N. Then, for any a > 0, P(|X| ≥ a) ≤ a−p E[|X|p ].
Proof. Let a > 0. We have that
Z
Z
|X|p (ω)
E[|X|p ]
P(|X| ≥ a) =
1{|X|≥a} (ω)P(dω) ≤
1
(ω)P(dω)
≤
.
{|X|≥a}
ap
ap
Ω
Ω

10.6

Distribution function

Definition 10.10. Let (Ω, F, P) be a probability space and X be a random variable. The
distribution function F of X is defined by
FX (t) = P(X ≤ t) = PX ((−∞, t]),

t ∈ R.

Exercise 10.5. Let (Ω, F, P) be a probability space and X and Y be two random variables
with equal distribution function F . Verify that PX = PY , i.e., X and Y have the same law.
Remark 10.7. Using Proposition 10.2, if X is discrete, we have that for any t ∈ R,
X
FX (t) =
px .
x∈E
x≤t

If X is continuous with law that has probability density function ϕ, we have upon Definition 10.6 that for any t ∈ R,
Z t
FX (t) =
ϕ(x)dx.
−∞

Proposition 10.5. Let (Ω, F, P) be a probability space and X be a random variable. Then,
the distribution function FX : R → [0, 1] of X is continuous if and only if for any t ∈ R,
P(X = t) = 0.
Example 10.21. Suppose that the law of X is Binomial with parameters n and p, i.e.,
n  
X
n x
PX =
p (1 − p)n−x δx .
x
x=0
Then, FX (t) is equal to zero for any t < 0 and 1 for any t ≥ n. The jumps are at the points
x = 0, . . . , n.
95

Proposition 10.6. Let (Ω, F, P) be a probability space and X be a continuous random
variable with distribution function FX . Let
E = {t ∈ R : 0 < FX (t) < 1}.
Then, if FX is strictly increasing on E, the restriction FX |E : E → (0, 1) is invertible with
inverse FX |−1
E that is strictly in increasing on (0, 1).
Exercise 10.6. Let X be a random variable with uniform law on [a, b], i.e., PX (dx) =
1/(b − a)1[a,b] (x)dx. Calculate FX (t), t ∈ R. Show that FX restricted to (a, b) is invertible
and calculate its inverse.
Exercise 10.7. Let X ∼ N (0, 1). Show that for any t ∈ R, 1 − FX (−t) = FX (t).

10.7

Variance and covariance

Definition 10.11. Let (Ω, F, P) be a probability space and X be a random variable s.t.
E[|X|] < ∞. The variance of X is defined by


Var(X) = E (X − E[X])2 ∈ R+ .
Proposition 10.7. Let (Ω, F, P) be a probability space and X be a random variable s.t.
E[|X|] < ∞. Then,
(i) Var(X) = E[X 2 ] − E[X]2 ;
(ii) X = E[X] P a.s. if and only if Var(X) = 0;
(iii) Given a > 0, P(|X − E[X]| ≥ a) ≤ a−2 Var(X).
We remark that the last item is known as Chebyshev’s inequality.
Proof. We readily deduce items (i) and (ii) from Definition 10.11. Item (iii) is just Markov’s
inequality (cf. Proposition 10.4) applied to X − E[X] with p = 2.
Exercise 10.8. Let X be a random variable s.t. Var(X) < ∞. Show that Var(a + X) =
Var(X).
Remark 10.8. Notice that if X is a random variable s.t. E[|X|2 ] < ∞, then E[|X|] < ∞.
To see it, take the set A = {ω : |X| ≤ 1}. We have that
Z
Z
Z
E[|X|] = |X|(ω)P(dω) +
|X|(ω)P(dω) ≤ P(A) +
|X|2 (ω)P(dω) < ∞.
A

Ac

Ac

In particular, if E[|X|2 ] < ∞, then Var(X) < ∞. Clearly, if Var(X) < ∞, then E[|X|2 ] <
∞. Thus, Var(X) < ∞ if and only if E[|X|2 ] < ∞.
Example 10.22. Let X be a random variable with law PX that is continuous uniform with
probability density ϕ(x) = 1/(b − a)1[a,b] (x), x ∈ R. By Example 10.16, we know that
E[X]2 = (a + b)2 /4. Further, by Proposition 10.3,
Z b
1
2
E[X ] =
x2 dx
b−a a

b
1 3
b3 − a3
(b − a)(b2 + ab + a2 )
(b2 + ab + a2 )
1
x
=
=
=
.
=
b−a 3
3(b − a)
3(b − a)
3
a
Hence,
Var(X) =

4b2 + 4ab + 4a2 − 3a2 − 3b2 − 6ab
b2 + a2 − 2ab
(a − b)2
=
=
.
12
12
12
96

Remark 10.9. One can show that if X ∼ N (µ, σ 2 ) then Var(X) = σ 2 . Notice that if
X ∼ N (µ, 0), then X = µ = E[X] P a.s., i.e., by item (ii) of Proposition 10.7, Var(X) = 0.
The following is known as a version of the Cauchy–Schwarz inequality.
Proposition 10.8. Let (Ω, F, P) be a probability space and X and Y be two random variables
s.t. E[|X|2 ] < ∞ and E[|Y |2 ] < ∞. Then,
p
p
(31)
E[|XY |] ≤ E[X 2 ] E[Y 2 ].
We define the covariance between two random variables.
Definition 10.12. Let (Ω, F, P) be a probability space.
(i) If X and Y are two random variables s.t. Var(X) < ∞ and Var(Y ) < ∞, then the
covaraince of X and Y is defined as
Cov(X, Y ) = E[XY ] − E[X]E[Y ] = E[(X − E[X])(Y − E[Y ])];
(ii) if Cov(X, Y ) = 0 for two random variables, then X and Y are referred to as uncorrelated;
(iii) If X = (X1 , . . . , Xk ) is a random vector, where for any i = 1, . . . , k, Var(Xi ) < ∞,
then the covariance matrix Σ(X) is defined by Σ(X)i,j = Cov(Xi , Xj ), 1 ≤ i, j ≤ k.
Remark 10.10. Notice that upon Proposition 10.8, we have that
p
p
|Cov(X, Y )| ≤ Var(X) Var(Y ).
Hence, the condition Var(X) < ∞ and Var(Y ) < ∞ is sufficient to ensure that Cov(X, Y )
is well defined.
Proposition 10.9. Let (Ω, F, P) be a probability space and X = (X1 , . . . , Xk ) be a random
vector, where for any i = 1, . . . , k, Var(Xi ) < ∞. Then, for any v = (v1 , . . . , vk ) ∈ Rk , the
random variable v t X has variance v t Σ(X)v. If k = 1, that is Var(vX) = v 2 Var(X), v ∈ R.
Proposition 10.10. Let (Ω, F, P) be a probability space and X = (X1 , . . . , Xk ) be a random vector s.t. for any i = 1, . . . , k, Var(Xi ) < ∞. Then, the covariance matrix Σ(X) is
symmetric and positive semidefinite.
Proof. By definition, Σ(X) is symmetric. Further, given any v1 , . . . , vk ∈ R, we have with
Proposition 10.9 that 0 ≤ Var(v t X) = v t Σ(X)v.
Remark 10.11. Let X1 , . . . , Xk be k random variables s.t. for any i = 1, . . . , k, Var(Xi ) <
∞. Then, if we set v = (1, . . . , 1) in Proposition 10.9, we obtain
k
X

Var

i=1

k
 X
Xi =
Var(Xi ) + 2
i=1

X

Cov(Xi , Xj ).

1≤i<j≤n

Pk
Pk
Hence, if X1 , . . . , Xk are pairwise uncorrelated, then, Var( i=1 Xi ) = i=1 Var(Xi ).

10.8

Characteristic function

Definition 10.13. Let (Ω, F, µ) be a measure space and f : Ω → C, i.e., for any ω ∈ Ω,
f (ω) = g(ω) + ih(ω), where g : Ω → R and h : Ω → R and i 2 = −1, the imaginary unit.
Then, f is said to be F measurable if g and h are F measurable. Further, if g and h are µ
integrable, f is µ integrable and we write
Z
Z
Z
f (ω)µ(dω) =
g(ω)µ(dω) + i
h(ω)µ(dω).
Ω

Ω

Ω

97

Definition 10.14. Let P be a probability measure on B(Rk ). The Fourier transform of P
is defined by
Z
t
Pb(v) =
eiv x P (dx), v ∈ Rk .
Rk

If (Ω, F, P) is a probability space and X a random vector with law PX on B(Rk ), the chart
acteristic function of X is defined by ΦX (v) = PbX (v), v ∈ Rk . That is, ΦX (v) = E[eiv X ].
Remark 10.12. Notice that for any v ∈ Rk , |ΦX (v)| ≤ 1 (cf. Exercise 8.6) and ΦX (0) = 1.
Further, by Proposition 8.12, v 7→ ΦX (v) is continuous on Rk .
As a well known example, the following proposition gives the characteristic function for
Gaussian random variables.
Proposition 10.11. Let (Ω, F, P) be a probability space and X ∼ N (µ, σ 2 ). Then,
ΦX (v) = eiµv−

σ2 v2
2

,

(32)

v ∈ R.

In general, the law of a random vector is determined by its characteristic function —
this is known as the uniqueness theorem of the characteristic function:
Proposition 10.12. Let P and P ′ be two probability measures on B(Rk ). If Pb(v) = Pb′ (v)
for any v ∈ Rk , then P = P ′ .
Combining the latter two propositions, (32) characterizes the law of a Gaussian random
variable — a summary is given in the following remark.
Remark 10.13. Let µ ∈ R and σ ≥ 0. Then, Propositions 10.11 and 10.12 show that a
random variable X is Gaussian with mean µ ∈ R and variance σ 2 ≥ 0 if and only if its
characteristic function is given by (32). Notice that if X has characteristic function given
by (32) with σ = 0, then if we define X ′ (ω) = µ for any ω ∈ Ω, we apply Proposition 10.12
and deduce that PX ′ = PX . Hence, P(X = µ) = P(µ = µ) = 1, i.e., X is again Gaussian
according to Definition 10.8.
Exercise 10.9. Show that if X ∼ N (µ, σ 2 ), then for any a, b ∈ R, a+bX ∼ N (a+bµ, b2 σ 2 ).
Conclude that if σ > 0, (X − µ)/σ is standard normal.

10.9

Solution to exercises

Solution 10.1 (Solution to Exercise 10.1). Clearly, #Ω = 62 = 36. We split
Ω = A ∪ Ac = A ∪ {(ω1 , ω2 ) ∈ Ω : ω2 < ω1 } ∪{(ω1 , ω2 ) ∈ Ω : ω1 = ω2 }.
{z
}
|
=A′

If ω = (ω1 , ω2 ) ∈ A, then (ω2 , ω1 ) ∈ A′ (and vice versa). This shows that #A = #A′ . Thus,
#Ω = 2#A + 6 = 36 ⇒ #A = 15.
Hence, P(A) = 15/36.
Solution 10.2 (Solution to Exercise 10.2). This is Exercise 2.5, we have that
(p + 1 − p)n = 1.

Pn

x=0

px =

Solution 10.3 (Solution to Exercise 10.3). This follows from the definition of ex , x ∈ R
(cf. Example 3.7). We have that
∞
X
λx e−λ
x=0

x!

= e−λ

∞
X
λx
x=0

98

x!

= e−λ eλ = 1.

Solution 10.4 (Solution to Exercise 10.4). Let g(x) = x − µ, x ∈ R. Then, for any
nonnegative and B(R) measurable function f : R → R,
Z
Z
(x−µ)2
u2
1
1
E[f (X − µ)] = E[f (g(X))] =
f (x − µ) √
e− 2σ2 dx =
e− 2σ2 du.
f (u) √
2πσ 2
2πσ 2
R
R
Thus, X − µ ∼ N (0, σ 2 ).
Solution 10.5 (Solution to Exercise 10.5). This is a simple consequence of Proposition 6.9.
We know that B(R) = σ(R), where R is the semiring of left-open intervals with the empty
set adjoined. By assumption, for any a, b ∈ R, a < b,
FX (b) − FX (a) = PX ((−∞, b]) − PX ((−∞, a]) = PX ((a, b]) = PY ((a, b]).
Thus, since PX and PY agree on R, they also agree on B(R).
Solution 10.6 (Solution to Exercise 10.6). We have that

0,
  1 Rt
1
FX (t) = PX ((−∞, t]) =
λ (−∞, t] ∩ [a, b] = b−a a dx =

b−a

1,

t−a
b−a ,

if t < a,
if a ≤ t < b, (33)
if t ≥ b.

Recall that λ is the Lebesgue measure on B(R). By (33), {t ∈ R : 0 < FX (t) < 1} = (a, b).
′
|(a,b) (t) > 0
Further, the restriction FX |(a,b) is strictly increasing since for any t ∈ (a, b), FX
(cf. Proposition 2.3). Therefore, by Proposition 10.6, FX |(a,b) : (a, b) → (0, 1) is a bijection,
i.e., for any p ∈ (0, 1), there exists a unique t ∈ (a, b) s.t. FX |(a,b) (t) = p. By (33),
−1
FX |(a,b) (t) = p is equivalent to (t−a)/(b−a) = p ⇔ t = a+p(b−a). Therefore, FX
|(a,b) (p) =
a + p(b − a), p ∈ (0, 1) (cf. Definition 2.6).
Solution 10.7 (Solution to Exercise 10.7). Let t ∈ R. We recall Definition 9.6 and obtain
Z t
Z t
Z −t
Z ∞
√
(−x)2
x2
u2
u2
2πFX (t) =
e− 2 dx =
e− 2 dx = −
e− 2 du =
e− 2 du.
−∞

−∞

∞

−t

Therefore,
1
FX (t) = √
2π

Z

∞

e−

x2
2

dx = P(X > −t) = 1 − P(X ≤ −t) = 1 − FX (−t).

−t

Solution 10.8 (Solution to Exercise 10.8). By definition, Var(a + X) = E[(a + X)2 ] − E[a +
X]2 . Developing the terms on the right of the latter equation gives the result.
Solution 10.9 (Solution to Exercise 10.9). We calculate the characteristic function of the
random variable a + bX: Given v ∈ R, we apply Proposition 10.11 and deduce that
Φa+bX (v) = E[eiv(a+bX) ]
= E[eiva ei(vb)X) ]
= eiva E[ei(vb)X) ] = eiva ΦX (vb) = eiva ei(bµ)v−

(σ 2 b2 )v 2
2

= ei(a+bµ)v−

(σ 2 b2 )v 2
2

.

Thus, by Proposition 10.12 (cf. Remark 10.13), a + bX ∼ N (a + bµ, b2 σ 2 ). It follows that,
X − µ ∼ N (0, σ 2 ) and hence (X − µ)/σ ∼ N (0, 1).

10.10

Additional exercises

Exercise 10.10. Let (Ω, F, P) be a probability space and X be a random variable s.t. X ∼
N (µ, σ 2 ), σ > 0. Show that P(X ≤ µ) = 1/2.
Hint: Consider first the case where X ∼ N (0, 1).
99

Exercise 10.11. Define

0



1 + 1x
ϕ(x) = 21 14

− x


2 4
0
(a) Show that

R
R

x < −2
−2 ≤ x < 0
0≤x<2
x ≥ 2.

ϕ(x)dx = 1.

Suppose that X is a random variable with law PX (dx) = ϕ(x)dx.
(b) Find the distribution function FX of X.
(c) Calculate the expected value and the variance of X.
Exercise 10.12. Suppose that X is a random variable with law PX (dx) = e−x 1[0,∞) (x)dx,
x ∈ R. That is PX is exponential with parameter λ = 1. Find the distribution function FX
of X. Verify that FX |[0,∞) is invertible and find its inverse.
Exercise 10.13. Let (Ω, F, P) be a probability space and X be a random variable s.t. X(Ω) ⊂
N. Verify that
E[X] =

∞
X

P(X ≥ n).

n=1

Hint: Proposition 3.11.
Exercise 10.14. Let (Ω, F, P) be a probability space and X be a random variable with
continuous distribution function FX that is strictly increasing on R. Find the law of ω 7→
FX (X)(ω).

100

11
11.1

Collections of random vectors
Independence

Regarding omitted proofs of this chapter, we refer to Appendix C.
Definition 11.1. Let (Ω, F, P) be a probability space and A1 , . . . , An be n sub-σ-fields on
Ω. A1 , . . . , An are said to be independent if for any A1 ∈ A1 , . . . , An ∈ An ,
P(A1 ∩ · · · ∩ An ) = P(A1 ) · . . . · P(An ).
Remark 11.1. If (Ω, F, P) is a probability space and A1 , . . . , An are n sets (events) s.t.
Ai ∈ F, i = 1, . . . , n. Then, A1 , . . . , An are said to be independent if the sub-σ-fields
σ(A1 ), . . . , σ(An ) are independent. Recall that σ(Ai ) = {Ai , Aci , Ω, ∅}, i = 1, . . . , n (cf.
Example 4.8).
Remark 11.2. Let (Ω, F, P) be a probability space. If A1 , . . . , An are independent sub-σfields on Ω, then
P(Ak1 ∩ · · · ∩ Akj ) = P(Ak1 ) · . . . · P(Akj ),
for any choice Ak1 ∈ Ak1 , . . . , Akj ∈ Akj , 1 ≤ k1 < k2 < · · · < kj ≤ n, 2 ≤ j ≤ n. This is
because for any i = 1, . . . , n, Ω ∈ Ai . Therefore, by Definition 11.1,
P(Ak1 ∩ · · · ∩ Akj ) = P(Ak1 ∩ · · · ∩ Akj ∩ Ω
· · ∩ Ω}) = P(Ak1 ) · . . . · P(Akj ).
| ∩ ·{z
n − j times

Definition 11.2. Let (Ω, F, P) be a probability space and Xi : Ω → Rki , i = 1, . . . , n,
be n random vectors on (Ω, F). X1 , . . . , Xn are said to be independent if the sub-σ-fields
σ(X1 ), . . . , σ(Xn ) are independent. By definition of σ(Xi ) = {Xi−1 (B) : B ∈ B(Rki )},
i = 1, . . . , n, that is equivalent to assume that for any B1 ∈ B(Rk1 ), . . . , Bn ∈ B(Rkn ),
P({X1 ∈ B1 } ∩ · · · ∩ {Xn ∈ Bn }) = P(X1 ∈ B1 ) · . . . · P(Xn ∈ Bn ).

(34)

Remark 11.3. We remark that the left hand side of (34) is written as
P({X1 ∈ B1 } ∩ · · · ∩ {Xn ∈ Bn }) = P(X1 ∈ B1 , . . . , Xn ∈ Bn ).
Notice also that by Definition 11.2 (cf. Remark 11.2), if X1 , . . . , Xn are n independent
random vectors, then they are pairwise independent, i.e., for any i, j = 1, . . . , n, i ̸= j, Xi
is independent of Xj .
In what follows we avoid to explicitly mention the underlying probability space and if
nothing else is mentioned, any random vector shall be defined on a common probability
space (Ω, F, P).
Example 11.1. Let E = {−5, −4, . . . , −1, 0, 1, . . . , 5}. Suppose that X1 and X2 are two
random variables with common law defined upon P(X1 = i) = P(X2 = i) = 1/11 for any
i ∈ E. That is, X1 and X2 have law that is discrete uniform on E (recall also Remark 10.2).
If we make the assumption that X1 and X2 are independent, then, for any i, j ∈ E, P({X1 =
i} ∩ {X2 = j}) = 1/112 . If we want to interpret the events {X1 = i} and {X2 = j}, i, j ∈ E,
as the outcome of two consecutive independent draws from an urn with balls labeled with
digits −5, . . . , 5, where each ball is equally likely to be drawn, then the number 1/112 gives
the chance to view label i in the first draw and label j in the second draw.
Exercise 11.1. Let X1 = X be as in Example 11.1. Let G be a discrete random variable
with law defined by
P(G = 1) = P(G = −1) = 1/2.
Suppose that G is independent of X. What is the law of Y = GX?
101

Exercise 11.2. Let X1 and X2 be as in Example 11.1 with the assumption that X1 and X2
are independent. What is the law of M = max{X1 , X2 }?
Remark 11.4. Let (Ω, F, P) be a probability space. Notice that if X1 , . . . , Xn are n random
vectors s.t. Xi = (Xi1 , . . . , Xiki ) : Ω → Rki , i = 1, . . . , n, then, the n-tuple of random vectors
X = (X1 , . . . , Xn ) is regarded as a function X : Ω → Rk1 ×· · ·×Rkn , where Rk1 ×· · ·×Rkn is
equipped with the product σ-field B(Rk1 ) ⊗ · · · ⊗ B(Rkn ). Then, since Xi are by assumption
F/B(Rki ) measurable for any i = 1, . . . , n, the map X is F/(B(Rk1 ) ⊗ · · · ⊗ B(Rkn ))
measurable. To see it, we recall that by definition of the product σ-field (cf. Definition 9.9),
B(Rk1 ) ⊗ · · · ⊗ B(Rkn ) = σ

 Y
n

Bi : Bi ∈ B(Rki ), i = 1, . . . , n


.

i=1

Thus, if B = B1 × · · · Bn , B1 ∈ B(Rk1 ), . . . , Bn ∈ B(Rkn ),
X −1 (B) = {ω ∈ Ω : X(ω) ∈ B} = X1−1 (B1 ) ∩ · · · ∩ Xn−1 (Bn ) ∈ F,
since Xi , i = 1, . . . , n, are random vectors. Then, we apply Proposition 7.1 and deduce that
for any B ∈ B(Rk1 ) ⊗ · · · ⊗ B(Rkn ), X −1 (B) ∈ F, i.e., X is F/(B(Rk1 ) ⊗ · · · ⊗ B(Rkn ))
measurable. The law of X is defined as
PX (B) = PX −1 (B) = P(X ∈ B),

B ∈ B(Rk1 × · · · × Rkn ) = B(Rk1 ) ⊗ · · · ⊗ B(Rkn ).

Therefore, by Proposition 9.1 for any B(Rk1 ) ⊗ · · · ⊗ B(Rkn ) measurable map f : Rk1 × · · · ×
Rkn → R s.t. f is either nonnegative or E[|f (X)|] < ∞, it follows that
Z
f (x)PX (dx).
(35)
E[f (X)] =
Rk1 ×···×Rkn

We show that the law of an independent collection of random vectors is precisely the
product measure of the individual laws of the random vectors (cf. Proposition 9.10).
Proposition 11.1. Let X = (X1 , . . . , Xn ) be an n-tuple of random vectors Xi : Ω → Rki ,
i = 1, . . . , n. Then, X1 , . . . , Xn are independent if and only if
PX = PX1 ⊗ · · · ⊗ PX1 ,
where PX1 ⊗ · · · ⊗ PX1 is the product measure on B(Rk1 ) ⊗ · · · ⊗ B(Rkn ).
Proof. Suppose that X1 , . . . , Xn are independent. Then, for any B = B1 × · · · × Bn , Bi ∈
B(Rki ), i = 1, . . . , n,
PX (B) = PX1 (B1 ) · . . . · PX1 (B1 ) = PX1 ⊗ · · · ⊗ PX1 (B).

(36)

By Proposition 9.10, PX1 ⊗ · · · ⊗ PX1 is the unique measure on B(Rk1 ) ⊗ · · · ⊗ B(Rkn ) that
satisfies (36). Thus, PX = PX1 ⊗ · · · ⊗ PX1 . The other direction follows readily, it is a
consequence of the definition of PX1 ⊗ · · · ⊗ PX1 on B(Rk1 ) ⊗ · · · ⊗ B(Rkn ).
Proposition 11.2. Let X1 , . . . , Xn be n random vectors s.t. Xi : Ω → Rki , i = 1, . . . , n.
Suppose that X1 , . . . , Xn are independent. Then, if for any i = 1, . . . , n, fi : Rki → R are
nonnegative and B(Rki ) measurable,
Y
 Y
n
n


E
fi (Xi ) =
E fi (Xi ) .
i=1

(37)

i=1

If fi : Rki → R are not necessarily nonnegative but s.t. E[|fi (Xi )|] < ∞ for any i = 1, . . . , n,
(37) remains valid.
102

Example 11.2. If X1 , . . . , Xn are independent random variables s.t. E[|Xi |] < ∞ for any
i = 1, . . . , n, then
Y
 Y
n
n
 
E
Xi =
E Xi .
i=1

i=1

Another consequence of the Proposition 11.2 is the following:
Proposition 11.3. Let X and Y be two independent random variables s.t. Var(X) < ∞
and Var(Y ) < ∞. Then, X and Y are uncorrelated, i.e., Cov(X, Y ) = 0.
Remark 11.5. We note that the converse of the latter proposition is generally not true. As
an example, let X ∼ N (0, 1). Define G as in Exercise 11.1 and assume that G is independent
of X. Let Y = GX. One can show that Y ∼ N (0, 1) as well (cf. Exercise 11.3). Further,
Cov(X, Y ) = E[XY ] − E[X]E[Y ] = E[GX 2 ]. Since E[|GX 2 |] < ∞ and X and G are
independent we apply Proposition 11.2 and obtain that E[GX 2 ] = E[G]E[X 2 ]. Hence, since
E[G] = 0, Cov(X, Y ) = 0. Thus X and Y are uncorrelated. Assume by contradiction that
X and Y are independent. Then it must be the case that
P({0 < X < 1/2} ∩ {Y > 1}) = P(0 < X < 1/2)P(Y > 1).
where the expression on the right is not equal to zero since X, Y ∼ N (0, 1). On the other
hand, suppose that ω ∈ {0 < X < 1/2} ∩ {Y > 1}. Then, Y (ω) = G(ω)X(ω) > 1 and
X(ω) > 0. Hence, G(ω) = 1 (otherwise we would have Y (ω) = −X(ω) < 0, which is not
possible). Therefore, ω ∈ {0 < X < 1/2} ∩ {Y > 1} implies that X(ω) > 1. Hence,
{0 < X < 1/2} ∩ {Y > 1} ⊂ {0 < X < 1/2} ∩ {X > 1} = ∅.
Thus P({0 < X < 1/2} ∩ {Y > 1}) = 0, which gives a contradiction. In conclusion, X and
Y are uncorrelated but not independent.
Exercise 11.3. Let X, G and Y be as in Remark 11.5. Verify that Y ∼ N (0, 1).
Proposition 11.4. Let X1 , . . . , Xn be n random variables.
(i) Suppose that for any i = 1, . . . , n, PXi (dx) = ϕi (x)dx, i.e., PXi has probability density
function ϕi . Then, if X1 , . . . , Xn are independent, the law of the random vector X =
(X1 , . . . , Xn ) has probability density function
ϕ(x) =

n
Y

ϕi (xi ),

x = (x1 , . . . , xn ) ∈ Rn .

i=1

(ii) Suppose Q
that the random vector X = (X1 , . . . , Xn ) is s.t. PX (dx) = ϕ(x)dx, with
n
ϕ(x) = i=1 ϕi (xi ), = (x1 , . . . , xn ) ∈ Rn , where for any i = 1, . . . , n, ϕi are nonnegative and B(R) measurable. Then, X1 , . . . , Xn are independent where for any
i = 1, . . . , n, PXi has probability density function fi = Ki ϕi , with Ki ∈ R, Ki > 0.
Proof. By Proposition 11.1, if X1 , . . . , Xn are independent, the law of the random vector X
is given by PX = PX1 ⊗ · · · ⊗ PXn on B(Rn ). Thus, by Proposition 10.3, for any B ∈ B(Rn ),
Z
Z
PX (B) =
1B (x)PX1 ⊗ · · · ⊗ PXn (dx) =
1B (x)ϕ(x)dx,
Rn

Rn

Qn

where ϕ(x) = i=1 ϕi (xi ). This shows (i). With regard to (ii), we first notice that
Z
Y


Z
Z
1=
ϕ(x)dx =
ϕi (x)dx
ϕi (xi ) d(x1 , . . . , xi−1 , xi+1 , . . . , xn ) .
Rn

R

Rn−1

j̸=i

103

R
Define Ci = R ϕi (x)dx, i = 1, . . . , n. Upon Example 10.19 we deduce that for any i =
1, . . . , n, the probability density function of PXi is
Z
fi (xi ) =

Y
n

Rn−1


ϕi (xi ) d(x1 , . . . , xi−1 , xi+1 , . . . , xn ) = Ci−1 ϕi (xi ).

i=1

Hence, we obtain that
ϕ(x) =

n
Y

ϕi (xi ) =

i=1

Then, for any B ∈ B(Rn ),
Z
Z
PX (B) =
PX (dx) =
Rn

n
Y

fi (xi ),

x = (x1 , . . . , xn ) ∈ Rn .

i=1

Z
PX1 ⊗ · · · ⊗ PXn (dx) = PX1 ⊗ · · · ⊗ PXn (B),

ϕ(x)dx =

Rn

Rn

and by Proposition 11.1, X1 , . . . , Xn are independent.
Example 11.3. The random vector X = (X1 , X2 ) of Example 10.11 is s.t. X1 and X2 are
independent. This is either seen by (26) under application of Propositions 9.10 and 11.1 or
by applying (ii) of Proposition 11.4.
Example 11.4. Let U have law that is continuous uniform on [0, 1], i.e., PU (du) =
1[0,1] (u)du. Suppose that R is independent of U with law that is exponential
with pa√
−r/2
rameter λ = 1/2, i.e., PR (dr) = (1/2) e
1[0,∞) (r)dr. Define X = R cos(2πU ) and
√
Y = R sin(2πU ). Then, X and Y are independent and identically distributed with law
N (0, 1). To see that X and Y are independent, let h : R2 → R be any nonnegative and
B(R2 ) measurable function. In particular,
√
√
h(X, Y ) = h( R cos(2πU ), R sin(2πU )) = h(g(U, R)),
√
√
with g(u, r) = ( r cos(2πu), r sin(2πu))1[0,1]×[0,∞) (u, r), (u, r) ∈ R2 . Thus, by Proposition 10.3,

Z ∞Z 1
√
√
−1 −r/2
du dr,
E[h(X, Y )] =
h( r cos(2πu), r sin(2πu))2 e
0

0

where we used the assumption that U and R are independent. We substitute θ = 2πu and
√
r = ρ obtain:

Z ∞  Z 2π
1
−ρ2 /2
E[h(X, Y )] =
h(ρ cos(θ), ρ sin(θ)) e
ρdθ dρ.
2π 0
0
2

2

Thus, we apply Proposition 9.15 with f (x, y) = h(x, y) e−(x +y )/2 , (x, y) ∈ R2 and obtain:
Z
(x2 +y 2 )
1
h(x, y) e− 2 d(x, y)
E[h(X, Y )] =
2π R2
Therefore (cf. Remark 10.6), the law of (X, Y ) has probability density function



1 − x2
1 − y2
1 − (x2 +y2 )
2
2
2
√ e
ϕ(x, y) =
e
= √ e
, (x, y) ∈ R2 .
2π
2π
2π
Upon (ii) of Proposition 11.4, X and Y are independent and s.t. X ∼ N (0, 1) and Y ∼
N (0, 1).

104

Remark 11.6. Notice that if X1 , . . . , Xn are n discrete random variables with support
E1 , . . . , En , respectively, then it follows from Proposition 11.1 that X1 , . . . , Xn are independent if and only if for any (x1 , . . . , xn ) ∈ Rn , the law of X = (X1 , . . . , Xn ) satisfies
PX ({x1 } × · · · × {xn }) = PX1 ({x1 }) · . . . · PXn ({x1 }).
The following result shows how independence is determined by the characteristic function:
Proposition 11.5. Let X1 , . . . , Xn be n random variables. Then, X1 , . . . , Xn are independent if and only if the characteristic function ΦX of the random vector X = (X1 , . . . , Xn )
satisfies:
ΦX (v) =

n
Y

ΦXi (vi ),

v = (v1 , . . . , vn ) ∈ Rn ,

i=1

where ΦXi is the characteristic function of Xi , i = 1, . . . , n.
A more general definition for independence, allowing for a notion of independence of
tuples of random vectors reads as follows:
Definition 11.3. Let Y1 , . . . , YN be a collection of N tuples of random vectors, i.e., for any
i = 1, . . . , N , Yi is the ni -tuple,
Yi = (X1i , . . . , Xni i )
where for any j = 1, . . . , ni , Xji : Ω → Rkij is a random vector. Then, Y1 , . . . , YN are said
to be independent if the σ-fields σ(Y1 ), . . . , σ(YN ) are independent.
Remark 11.7. Recall that by Remark 11.4, for any i = 1, . . . , N , the tuple Yi in the latter
definition is a F/B(Rki1 ) ⊗ · · · ⊗ B(Rkini ) measurable mapping from Ω to Rki1 × · · · × Rkini .
The following result supports our intuitive understanding of independence (a proof is
given in Section C.5 of the appendix).
Proposition 11.6. Let X1 , . . . , Xn be independent random vectors s.t. Xi : Ω → Rki , i =
1, . . . , n. Then, for any n0 = 0 < n1 < n2 < · · · < np = n, the tuples
Y1 = (X1 , . . . , Xn1 ), Y2 = (Xn1 +1 , . . . , Xn2 ), . . . , Yp = (Xnp−1 +1 , . . . , Xn )
are independent. In particular, for any collection of functions
fi : Rkni +1 × · · · × Rkni+1 → R,

i = 0, . . . , p − 1,

each of which is B(Rkni +1 ) ⊗ · · · ⊗ B(Rkni+1 ) measurable, the random variables
T1 = f1 (Y1 ), . . . , Tp = fp (Yp ),
are independent.
Example 11.5. Suppose that X1 , X2 , X3 are independent random variables. Then, X12 and
X2 + X3 are independent. In particular, if X1 , . . . , Xn are n independent random vectors
s.t. Xi : Ω → Rk for any i = 1, . . . , n, X1 + · · · + Xn−1 is independent of Xn . Another
application of the latter proposition is that if two random vectors X = (X1 , . . . , Xk ) and
Y = (Y1 , . . . , Yk ) are independent, then, for any i, j ∈ {1, . . . , k}, the random variables Xi
and Yj are independent. To see it, we define the coordinate map πi : Rk → R (i = 1, . . . , k),
πi (x) = xi ,

x = (x1 , . . . , xk ),

and notice that upon
R × · · · × R × B × R · · · × R = πi−1 (B),

B ∈ B(R),

that for any i = 1, . . . , k, πi is B(Rk )/B(R) measurable. Then, the result follows by Proposition 11.6, with Y1 = X and Y2 = Y and T1 = πi (X) and T2 = πj (Y ).
105

Finally we note that the definition of independence can be extended to arbitrary collections of sub-σ-fields and random vectors (or tuples of random vectors).
Definition 11.4. Let (Ω, F, P) be a probability space and I be a non empty set.
(i) A collection Ai , i ∈ I, of sub-σ-fields on Ω is referred to as independent if for any
i1 , . . . , ik , Ai1 , . . . , Aik are independent;
(ii) a collection of events {Ai : i ∈ I} ⊂ F is said to be independent if σ(Ai ), i ∈ I, is
independent;
(iii) a collection of random vectors (Xi )i∈I is said to be independent if σ(Xi ), i ∈ I, is
independent;
(iv) a collection of random vectors (Xi )i∈I is said to be independent and identically distributed (i.i.d.) if (Xi )i∈I is independent and for any i ∈ I, Xi has law PX1 ;
(v) a collection of tuples of random vectors (Xi )i∈I is said to be independent if σ(Xi ),
i ∈ I, is independent;
(vi) a collection of tuples of random vectors (Xi )i∈I is said to be independent and identically
distributed (i.i.d.) if (Xi )i∈I is independent and for any i ∈ I, Xi has law PX1 ;
Remark 11.8. Notice that items (iii) and (iv) of the latter definition are special cases of
items (v) and (vi).

11.2

Sums of independent random vectors

Definition 11.5. Let X1 , . . . , Xn be n random vectors s.t. Xi : Ω → Rk , i = 1, . . . , n. We
define the measure
PX1 ∗ · · · ∗ PXn (B) = (PX1 ⊗ · · · ⊗ PXn )s−1 (B),

B ∈ B(Rk ), s(x1 , . . . , xn ) =

n
X

xi .

i=1

Remark 11.9. We note that the map s : Rk × · · · × Rk → Rk given in Definition 11.2 is
B(Rk )⊗· · ·⊗B(Rk ) measurable (cf. Proposition B.7). Further, PX1 ⊗· · ·⊗PXn is a measure
on B(Rk ) ⊗ · · · ⊗ B(Rk ). Thus, PX1 ∗ · · · ∗ PXn is well defined. In particular, PX1 ∗ · · · ∗ PXn
is the pushforward measure of PX1 ⊗ · · · ⊗ PXn (cf. Definition 9.1).
Proposition 11.7. Assume
X1 , . . . , Xn are n independent random vectors s.t. Xi : Ω →
Pthat
n
Rk , i = 1, . . . , n. Let Z = i=1 Xi .
(i) The law of Z is PX1 ∗ · · · ∗ PXn ;
(ii) if PXi has probability density function ϕi , i = 1, . . . , n, then, the law of Z has probability density function ϕZ (z) = ϕ1 ∗ · · · ∗ ϕn (z), z ∈ Rk (cf. Example 9.11). That is, the
probability density function of the law of Z is the n-fold convolution of the probability
density functions ϕ1 , . . . , ϕn of PX1 , . . . , PXn , respectively.
Proof. By Proposition 11.1, the law of the n-tuple X = (X1 , . . . , Xn ) is given by the product
measure PX1 ⊗· · ·⊗PXn . Hence, for any nonnegative B(Rk ) measurable function f : Rk → R,
Z
E[f (Z)] = E[f (s(X)] =
f (s(x1 , . . . , xn ))PX1 ⊗ · · · ⊗ PXn (d(x1 , . . . , xn )),
Rk ×···×Rk

with s(x1 , . . . , xn ) =
Z
E[f (Z)] =

Pn

xi . Therefore, by Proposition 9.1,
Z
f (z)PX1 ⊗ · · · ⊗ PXn s−1 (dz) =
f (z)PX1 ∗ · · · ∗ PXn (dz).
i=1

Rk

Rk

106

This shows (i). In order to show (ii), we notice that it is enough to consider the case
where n = 2, since for a general n, the argument follows by induction under application of
Proposition 11.6 (cf. Example 11.5) and (22) of Example 9.11. By (i), the law of X1 + X2
is given by PX1 ∗ PX2 . Thus, again by Proposition 9.1, with s(x1 , x2 ) = x1 + x2 , for any
B ∈ B(Rk ),
Z
Z
PX1 +X2 (B) =
1B (z)PX1 ∗ PX2 (dz) =
1B (s(x1 , x2 ))PX1 ⊗ PX2 (d(x1 , x2 ))
Rk
Rk ×Rk

Z Z
=
1B (x1 + x2 )PX1 (dx1 ) PX2 (dx2 )
Rk
Rk

Z Z
=
1B (x1 + x2 )ϕ1 (x1 )dx1 ϕ2 (x2 )dx2
Rk
Rk

Z Z
=
1B (z)ϕ1 (z − x2 )ϕ2 (x2 )dz dx2
Rk
Rk
Z

Z
=
1B (z)
ϕ1 (z − x2 )ϕ2 (x2 )dx2 dz.
Rk

Rk

R
Finally, we recall that Rk ϕ1 (z−x2 )ϕ
R 2 (x2 )dx2 = ϕ1 ∗ϕ2 (z) λk a.e. (cf. Example 9.11). Hence,
for any B ∈ B(Rk ), PX1 +X2 (B) = B ϕ1 ∗ ϕ2 (z)dz, i.e., PX1 +X2 (dz) = ϕ1 ∗ ϕ2 (z)dz.
Remark 11.10. Suppose that X1 and X2 are two independent discrete random vectors s.t.
X1 , X2 : Ω → Rk . Let E1 and E2 be the support of X1 and X2 , respectively. We remark
that by Proposition 11.1 (i.e., P(X1 ,X2 ) = PX1 ⊗ PX2 ), the support of (X1 , X2 ) is E1 × E2 .
In particular, the support of X1 + X2 is E1 + E2 = {x1 + x2 : (x1 , x2 ) ∈ E1 × E2 }. This is
because by item (i) of Proposition 11.7,
PX1 +X2 (E1 + E2 ) = PX1 ⊗ PX2 ({(x1 , x2 ) ∈ Rk × Rk : x1 + x2 ∈ E1 + E2 })
= PX1 ⊗ PX2 (E1 × E2 ) = 1.
We further deduce that
PX1 +X2 ({z}) = P(X1 ,X2 ) ({(x1 , x2 ) ∈ Rk × Rk : x1 + x2 = z}),

z ∈ E1 + E2 .

Then, {(x1 , x2 ) ∈ Rk × Rk : x1 + x2 = z} = {z − x2 } × Rk . Hence, by Proposition 10.2,
X
PX1 +X2 ({z}) =
PX1 ({x1 })PX2 ({x2 })
(x1 ,x2 )∈({z−x2 }∩E1 )×E2

X

=

PX1 ({z − x2 })PX2 ({x2 }),

z ∈ E1 + E2 .

(38)

x2 ∈E2

As with the continuous case, for 3 independent and discrete random vectors X1 , X2 and X3
with support E1 , E2 and E3 , respectively, we obtain for z ∈ E1 + E2 + E3 ,

X  X
PX1 +X2 +X2 ({z}) =
PX1 ({z − x3 − x2 })PX2 ({x2 }) PX3 ({x3 }).
x3 ∈E3

x2 ∈E2

k
Generally, if X1 , . . . , Xn are n independent and discrete
vectors with
Pn Xi : Ω → R
Prandom
n
and Xi has support Ei , i = 1, . . . , n, we obtain for z ∈ i=1 Ei , with Z = i=1 Xi ,

 
X   X  X
PZ ({z}) =
···
p1 (z − (x2 + · · · + xn ))p2 (x2 ) p3 (x3 ) · · · pn (xn ),
xn ∈En

x3 ∈E3

x2 ∈E2

where pi (y) = PXi ({y}), y ∈ Rk .
107

Example 11.6. Suppose that X1 and X2 are independent where the law of X1 is Binomial
with parameters n − 1 and p and X2 has Bernoulli law with parameter p. Then, X1 + X2
is Binomial with parameters n and p. To see it, we first notice that X1 + X2 has support
{0, . . . , n} (cf. Remark 11.10). Thus, let z ∈ {0, . . . , n}. We apply (38) and obtain
PX1 +X2 ({z}) = PX1 ({z − 0})PX2 ({0}) + PX1 ({z − 1})PX2 ({1})




n−1 z
n − 1 z−1
n−1−z
=
p (1 − p)
(1 − p) +
p (1 − p)n−1−(z−1) p
z
z−1

 

n−1
n−1
=
+
pz (1 − p)n−z .
z
z−1



n
Then, we rely on Exercise 1.12 and obtain n−1
+ n−1
z
z−1 = z . In conclusion, for any

z ∈ {0, . . . , n}, P(X1 + X2 = z) = nz pz (1 − p)n−z . This shows that the law of X1 + X2
is Binomial with parameters n and p. We remark that upon an argument by induction, we
have shown that if X1 , . . . , Xn are n independent
Pn random variables with common law that is
Bernoulli with parameter p, then the law of i=1 Xi is Binomial with parameters n and p.
Example 11.7. Suppose that X1 and X2 are two independent random variables where for
i = 1, 2, the law of Xi is exponential with parameter λ > 0, i.e.,
PXi (dx) = 1[0,∞) (x)λ e−λx dx,
{z
}
|

i = 1, 2.

=ϕ(x)

Apart from a set of Lebesgue measure zero, we have that
Z
ϕ ∗ ϕ(z) =
ϕ(z − x)ϕ(x)dx
ZR
=
1[0,∞) (z − x)λ e−λ(z−x) 1[0,∞) (x)λ e−λx dx
R
Z z 
= 1[0,∞) (z)λ2 e−λz
dx
0

= 1[0,∞) (z)λ2 z e−λz .
We apply item (ii) of Proposition 11.7 and deduce that the probability density function of
the law of Z = X1 + X2 is given by ϕ ∗ ϕ(z), z ∈ R. We remark that a random variable with
law PZ (dz) = ϕZ (z)dz is referred to as Gamma distributed with parameters 2 and λ.
Exercise 11.4. Suppose that X1 and X2 are two independent random variables with law that
is geometric with parameter p, i.e., X1 and X2 have support N and P(Xi = k) = (1−p)k−1 p,
k ∈ N, i = 1, 2. Find the law of X1 + X2 .
The following result is helpful in characterizing the law of the sum of independent random
vectors:
Proposition 11.8. Assume
X1 , . . . , Xn are n independent random vectors s.t. Xi : Ω →
Pthat
n
Rk , i = 1, . . . , n. Let Z = i=1 Xi . Then,
ΦZ (v) =

n
Y

ΦXi (v),

v ∈ Rk ,

i=1

i.e., the characteristic function of Z equals the product of the characteristic functions of Xi ,
i = 1, . . . , k.

108

Example 11.8. Upon the latter result we readily check that
X1 , . . . , XnP
are n independent
Pif
Pn
n
n
random variables s.t. Xi ∼ N (µi , σi2 ), i = 1, . . . , n, then i=1 Xi ∼ N ( i=1 µi , i=1 σi2 ).
To see it, we apply Proposition 11.8 and obtain with Proposition 10.11 that for any v ∈ R,
Pn

ΦPni=1 Xi (v) = ei(
Then,
Proposition 10.12, the sum
Pn by
2
.
σ
i=1 i

11.3

Pn

i=1

i=1

µi )v−

P
2 2
( n
i=1 σi )v
2

.

Xi is Gaussian with mean

Pn

i=1

µi and variance

Gauss vectors

Definition 11.6. A random vector X = (X1 , . . . , Xk ) is said to be a Gauss vector if and
only if for any v ∈ Rk , the random variable
v t X = v1 X1 + · · · vk Xk ,
is Gaussian.
Remark 11.11. Regarding the previous definition, several notes are helpful.
(i) If X = (X1 , . . . , Xk ) is a Gauss vector, then for any i = 1, . . . , k, Xi is Gaussian.
We take v = (0, . . . , 0, 1, 0, . . . , 0) = ei , i = 1, . . . , k, and obtain that eti X = Xi is
Gaussian.
(ii) If for any i = 1, . . . , k, Xi is Gaussian, then X = (X1 , . . . , Xk ) is not necessarily a
Gauss vector. For a counter example, let X1 ∼ N (0, 1) and X2 = GX1 , with G as in
Example 11.1. That is, X1 and X2 are as in Remark 11.5 and we already know that
X2 is Gaussian as well. We have that
P(X1 + X2 = 0) = P(X1 (1 + G) = 0)
= P(X1 (1 + G) = 0, X1 = 0) + P(X1 (1 + G) = 0, X1 ̸= 0)
= P(X1 (1 + G) = 0, X1 ̸= 0) = P(G = −1) = 1/2.
Thus, X1 + X2 is not Gaussian and hence (X1 , X2 ) is not Gaussian.
(iii) If X1 , . . . , Xk are independent Gaussian random variables, then X = (X1 , . . . , Xk ) is
a Gauss vector. This is Example 11.8 (see also Exercise 10.9). It is not sufficient that
X1 , . . . , Xk are pairwise uncorrelated (cf. Remark 11.5). However, we will see later
that if X is a Gauss vector, then X1 , . . . , Xk are independent if and only if X1 , . . . , Xk
are pairwise uncorrelated (cf. Proposition 11.10).
Definition 11.7. We use the notation X ∼ N (µ, Σ(X)) to indicate that X is a Gauss
vector with mean vector µ and covariance matrix Σ(X). If µ = 0 and Σ(X) = I, where


1 0 ... 0
0 1 . . . 0


I = . . .
,
. . ... 
 .. ..

0 0 ... 1
X is referred to as a standard Gauss vector.
Proposition 11.9. Let X = (X1 , . . . , Xk ) be a Gauss vector with mean µ = (µ1 , . . . , µk )
and covariance matrix Σ(X). Then, the characteristic function of X is given by
t

ΦX (v) = eiµ

v−

v t Σ(X)v
2

109

,

v ∈ Rk .

Proof. Let v ∈ Rk . Since X is a Gauss vector, v t X is a Gaussian random variable with expectation µt v and variance v t Σ(X)v (cf. Proposition 10.9). Therefore, by Proposition 10.11,
ΦX (v) = E[eiv

t

X

t

] = Φvt X (1) = ei(µ

v)−

(v t Σ(X)v)
2

.

Exercise 11.5. Suppose that X ∼ N (µ, Σ(X)), µ = (µ1 , . . . , µk ) and Σ(X)i,i = σi2 , i =
1, . . . , k. Show that Xi ∼ N (µi , σi2 ), i = 1, . . . , k.
Proposition 11.10. Suppose that X = (X1 , . . . , Xk ) ∼ N (µ, Σ(X)). Then, X1 , . . . , Xk are
independent if and only if

 2
σ1,1
0
...
0
2
 0
σ2,2
...
0 


Σ(X) =  .
.
..  ,
.
..
..
 ..
. 
2
0
0
. . . σk,k
i.e., Σ(X) is diagonal.
Proof. Suppose that X1 , . . . , Xk are independent. Then, for any i, j = 1, . . . , k, i ̸= j,
Cov(Xi , Xj ) = 0 (cf. Remark 11.3 and Proposition 11.3). In particular, Σ(X) is diagonal.
For the other direction, assume that Σ(X) is diagonal with Σ(X)i,i = σi2 , i = 1, . . . , k.
Then, for any v = (v1 , . . . , vk ) ∈ Rk , by Proposition 11.9,
ΦX (v) = eiµ

t

v−

v t Σ(X)v
2

Pk

=e

i=1

iµi vi −

σi2 vi2
2



=

k
Y

eiµi vi −

σi2 vi2
2

.

i=1

Then, since Xi ∼ N (µi , σi2 ) (cf. Exercise 11.5), it follows that ΦX (v) =
Hence, we apply Proposition 11.5 and the proposition is proven.

Qk

i=1

ΦXi (vi ).

Remark 11.12. Upon Remark 11.5, it is possible that X1 ∼ N (0, 1) and X2 ∼ N (0, 1) s.t.
Σ(X) = I, X = (X1 , X2 ), but X1 and X2 are not independent. Thus, we already know that
Proposition 11.10 is not true in general (i.e. it holds for Gauss vectors).
Proposition 11.11. Assume that X ∼ N (µ, Σ(X)), where Σ(X) is positive definite. Then,
the law of X has probability density function ϕ(x), x ∈ Rk , given by (27), i.e., PX is
multivariate normal with probability density function
ϕ(x) = p

1
(2π)k

det Σ(X)

t

1

e− 2 (x−µ)

Σ(X)−1 (x−µ)

,

x ∈ Rk .

Remark 11.13. Assuming that Σ(X) is positive definite implies that the k eigenvalues of
Σ(X) are strictly positive (recall that Σ(X) is symmetric). In particular, if λ1 , . . . , λk are
Qk
the k eigenvalues of Σ(X), det Σ(X) = i=1 λi ̸= 0. That is, Σ(X) is invertible.
A proof of Proposition 11.11 is given in Section C.6 of the appendix.

11.4

A note on conditional probabilities

Let (Ω, F, P) be a probability space and B ∈ F s.t. P(B) > 0. Then, define the function
PB (A) = P(A | B) =

P(A ∩ B)
,
P(B)

A ∈ F.

We readily verify that A 7→ PB (A) defines a new measure on F according to Definition 5.1.
In particular, PB (Ω) = 1, i.e., A 7→ PB (A) is a probability on F. The latter measure is
110

referred to as the conditional probability given the event B. If X is a random variable,
either nonnegative or integrable with respect to P, then the conditional expectation of X
given the event B is defined as
E[X | B] =

E[X 1B ]
.
P(B)

We remark that by Exercise 8.8, if we set µB (A) = P(A ∩ B), A ∈ F, we deduce that
R
Z
X(ω)µB (dω)
= E[X | B].
X(ω)PB (dω) = Ω
P(B)
Ω
Thus, the expectation of X with respect to the conditional measure PB is the conditional
expectation of X given the event B. For further reading on conditional probabilities we
refer to [1] and [2].

11.5

Solution to exercises

Solution 11.1 (Solution to Exercise 11.1). Suppose that i ∈
/ E, then P(Y = i) = 0. Hence,
Y has support E. Let i ∈ E. Using the assumption that X and G are independent, we have
that
P(Y = i) = P({Y = i} ∩ {G = 1}) + P({Y = i} ∩ {G = −1})
= P({X = i} ∩ {G = 1}) + P({X = −i} ∩ {G = −1})
= P(X = i)P(G = 1) + P(X = −i)P(G = −1) = 1/11.
Thus, Y has the same law as X.
Solution 11.2 (Solution to Exercise 11.2). Let m ∈
/ E. We have that P(M = m) = 0.
Thus, M has support E. Let m ∈ E, m ≥ −4. We recall Remark 10.7 and notice that
P(M = m) = P(M ≤ m) − P(M ≤ m − 1).
Then, since X1 and X2 are assumed to be independent with same law,
P(M ≤ m) = P({X1 ≤ m} ∩ {X2 ≤ m}) = P(X1 ≤ m)2 .
We calculate
P(X1 ≤ m) =

X

P(X1 = i)

{i∈E : i≤m}

#{i ∈ E : i ≤ m}
11
#{i : − 5 ≤ i ≤ m}
#{i : − 5 + 5 + 1 ≤ i ≤ m + 5 + 1}
m+5+1
=
=
=
.
11
11
11
The same argument shows that P(X1 ≤ m − 1) = (m + 5)/11. Therefore, for m ∈ E,
m ≥ −4,


1
2m + 11
P(M = m) = 2 (m + 5 + 1)2 − (m + 5)2 =
.
(39)
11
121
If m = −5, P(M = m) = P({X1 = −5} ∩ {X2 = −5}) = 1/121 = (2m + 11)/121. In
conclusion, for any m ∈ E, the law of M is given by (39).
=

Solution 11.3 (Solution to Exercise 11.3). Given any t ∈ R, using the assumption that G
and X are independent, we have that
P(Y ≤ t) = P(Y ≤ t, G = −1) + P(Y ≤ t, G = 1)
= P(X ≥ −t)P(G = −1) + P(X ≤ t)P(G = 1)
1
1
= 1 − FX (−t) + FX (t) .
2
2
111

Thus, by Exercise 10.7, we deduce that for any t ∈ R, FY (t) = FX (t). Hence, upon Exercise 10.5, this shows that Y ∼ N (0, 1).
Solution 11.4 (Solution to Exercise 11.4). The support of X1 + X2 is N + N = N \ {1}.
Given z ∈ X1 + X2 , we have
X
P(X1 + X2 = z) =
P(X1 = z − k)P(X2 = k)
k∈N

=

z−1
X

P(X1 = z − k)P(X2 = k) = (z − 1)p2 (1 − p)z−2 .

k=1

Solution 11.5 (Solution to Exercise 11.5). Let i = 1, . . . , k. We know that Xi is Gaussian
(cf. item (i) of Remark 11.11). Define the random vector
Yi = (0, . . . , 0, Xi , 0, . . . , 0).
We have that E[Yi ] = (0, . . . , 0, µi , 0, . . . , 0) and
(
σi2 , if j = k = i,
Σ(Yi )j,k =
0,
otherwise.
We deduce that for any v = (v1 , . . . , vk ) ∈ Rk ,
ΦYi (v) = E[eivi Xi ] = E[eiw

t

X

] = ΦX (w),

with w = (0, . . . , 0, vi , 0, . . . , 0). Thus, by Proposition 11.9, ΦYi (v) = eiµi vi −
for any a ∈ R, with b = (b1 , . . . , bi−1 , a, bi+1 , . . . , bk ),
ΦXi (a) = E[eiaXi ] = E[eib

t

Yi

] = ΦYi (b) = eiµi a−

a2 σi2
2

vi2 σi2
2

. Therefore,

.

Thus, by Proposition 10.12, Xi ∼ N (µi , σi2 ).

11.6

Additional exercises

Exercise 11.6. Let X1 , . . . , Xn be n random variables. Verify that if X1 , . . . , Xn are independent, then for any t1 , . . . , tn ∈ R,
P(X1 ≤ t1 , . . . , Xn ≤ tn ) =

n
Y

P(Xi ≤ ti ).

(40)

i=1

Hint: Proposition 11.1.
Note: One can also verify the converse of the latter statement, i.e., if (40) holds, then
X1 , . . . , Xn are independent.
Exercise 11.7. Let X1 , . . . , Xn be a n independent discrete random variables where for
any i = 1, . . . , n, the law of Xi is discrete uniform on {1, . . . , p}, p ∈ N. Find the law of
M = max{X1 , . . . , Xn }.
Exercise 11.8. Let X1 and X2 be two independent random variables s.t. X1 and X2 have
Poisson law with parameters λ and µ, respectively. Show that the law of X1 + X2 is Poisson
with parameter λ + µ.
Exercise 11.9. Let X = (X1 , . . . , Xk ) and Y = (Y1 , . . . , Yk ) be two independent random
vectors s.t. for any i = 1, . . . , k, Var(Xi ) and Var(Yi ) are finite. Let Σ(X) and Σ(Y ) be the
covariance matrices of X and Y , respectively. Show that Σ(X + Y ) = Σ(X) + Σ(Y ), where
Σ(X + Y ) is the covariance matrix of X + Y .
112

Exercise 11.10. Let X and Y be two random variables.
(a) Show that the characteristic function ΦX of X is real valued (i.e., ΦX (v) ∈ R for any
v ∈ R) if and only if PX = P−X , i.e., the law of X is symmetric around the origin.
Hint: Recall that the maps x 7→ cos(x) and x 7→ sin(x) are even and odd, respectively (cf.
Example 9.3).
(b) Show that if X and Y are independent with equal law, then the random variable Z =
X − Y has law that is symmetric around the origin.

113

12
12.1

Convergence of random vectors
General notions of Convergence

We recall that if nothing else is mentioned, any collection of random vectors is defined on
a common probability space (Ω, F, P). Further, if not specified otherwise, any sequence of
random vectors (Xn )n∈N is s.t. Xn : Ω → Rk for any n ∈ N. If k = 1, (Xn )n∈N is a sequence
of random variables. We also keep in mind Sections 3.4 and 7.3.
Definition 12.1. Let (Xn )n∈N be s sequence of random vectors.
Almost sure convergence: (Xn )n∈N converges almost surely to a random vector X if
n→∞

n→∞

P({ω ∈ Ω : Xn (ω) −−−−→ X(ω)}) = P(Xn −−−−→ X) = P( lim Xn = X) = 1.
n→∞

To indicate that (Xn )n∈N converges almost surely to X, we use the notation Xn →a.s. X.
L1 and L2 convergence: Let p = 1, 2. Assume that E[∥Xn ∥p ] < ∞ for any n ∈ N and
suppose that X is a random vector s.t. E[∥X∥p ] < ∞. Then, (Xn )n∈N converges in Lp to
X if
lim E[∥Xn − X∥p ] = 0.
(41)
n→∞

To indicate that (Xn )n∈N converges in Lp to X, we use the notation Xn →Lp X.
Convergence in probability: (Xn )n∈N converges in probability to a random vector X if
for any ε > 0
lim P(∥Xn − X∥ > ε) = 0.

n→∞

To indicate that (Xn )n∈N converges in probability to X, we use the notation Xn →P X.
Remark 12.1. In either case, Xn →a.s. X, Xn →Lp X or Xn →P X, the limit X is
assumed to be a random vector, i.e., X is F/B(Rk ) measurable. In particular, by Proposin→∞
tion 7.9, the set {Xn −−−−→ X} is an element of F. Notice that almost sure convergence
Xn →a.s. X is a special case of a.e. convergence of a sequence of measurable function Xn ,
n ∈ N, to X where the measure is a probability and the limit is a measurable function as
well. If p = 1, then upon the triangular inequality (cf. Proposition 2.10), E[∥X∥] < ∞ and
E[∥X∥] < ∞ imply that E[∥Xn − X∥] < ∞. If p = 2, then,
X
 X
k
k
n
2
E[∥Xn − X∥ ] = E
(Xi − Xi ) =
E[(Xin − Xi )2 ],
2

i=1

i=1

where Xn = (X1n , . . . , Xkn ) and X = (X1 , . . . , Xk ). Hence, by Proposition 10.8, E[∥Xn ∥2 ] <
∞ and E[∥X∥2 ] < ∞ imply that E[∥Xn − X∥2 ] < ∞. Further, if Xn →L2 X, then Xn →L1
X. This is because E[∥Xn ∥2 ] < ∞ and E[∥X∥2 ] < ∞ imply that E[∥Xn ∥] < ∞ and E[∥X∥] <
∞ (cf. Proposition 8.5) and
Var(∥Xn − X∥) = E[∥Xn − X∥2 ] − (E[∥Xn − X∥])2 ≥ 0,

(42)

i.e., E[∥Xn − X∥] ≤ (E[∥Xn − X∥2 ])1/2 . Finally we remark that Lp convergence is not
restricted to p = 1, 2. Generally, (Xn )n∈N converges in Lp (p ≥ 1) to X if (41) is satisfied.
When studying the convergence of random vectors, the following statement is helpful.
The given result is known as the Borel-Cantelli lemma.
Proposition 12.1. Let {An : n ∈ N} ⊂ F be a sequence of events. Define

∞  [
∞
\
lim sup An =
Ak .
n→∞

n=1

114

k=n

(i) If

P∞

n=1

P(An ) < ∞, then P(lim supn→∞ An ) = 0.

(ii) If {An : n ∈ N} is independent (cf. Definition 11.4) and
P(lim supn→∞ An ) = 1.

P∞

n=1

P(An ) = ∞, then,

Exercise 12.1. Show that lim supn→∞ An = {ω ∈ Ω : ω ∈ An for infinitely many n}.
Remark 12.2. Upon Exercise 12.1, if {An : n ∈ N} ⊂ F is a sequence of events s.t.
P
∞
n=1 P(An ) < ∞, (i) of Proposition 12.1 shows that
P({ω ∈ Ω : ω ∈ An for finitely many n}) = 1.
P∞
If {An : n ∈ N} is independent and n=1 P(An ) = ∞, then, by (ii) of Proposition 12.1,
P({ω ∈ Ω : ω ∈ An for infinitely many n}) = 1.
Proof of Proposition 12.1. We notice that by Proposition 8.4,
X

∞
∞
∞
X
X
P(An ) =
E[1An ] = E
1A n .
n=1

n=1

i=1

Thus, if n=1 P(An ) < ∞, then, by Proposition 8.5, i=1 1An < ∞ P a.s. This implies
that P(lim supn→∞ An ) = 0 (cf. Exercise
P∞12.1). This shows (i). For the remaining, assume
that {An : n ∈ N} is independent and n=1 P(An ) = ∞. Notice first that by Example A.5,
we have that for any x ∈ R, 1 − x ≤ e−x . Hence, for any N ∈ N,
 \

n
n
n
Y
Y
Pn
c
P
Ak =
P(Ack ) =
(1 − P(Ak )) ≤ e− k=N P(Ak ) .
P∞

P∞

k=N

k=N

k=N

P∞

n
c
Then, since by assumption,
n=1 P(An ) = ∞, it follows that limn→∞ P(∩k=N Ak ) = 0.
∞
c
Therefore, by Proposition 5.1, for any N ∈ N, P(∩k=N Ak ) = 0. Hence (cf. Proposition 5.1),
 [
 X
 \

∞  \
∞
∞
∞
P
Ack
≤
P
Ack = 0.
N =1

k=N

N =1

k=N

This shows that P((lim supn→∞ An )c ) = 0 and completes the proof of (ii).
The following two propositions show that convergence in probability is the weakest form
of the three notions of convergence given in Definition 12.1.
Proposition 12.2. Let p = 1, 2. Suppose that Xn →Lp X. Then, Xn →P X.
Proof. Since Xn →L2 X implies that Xn →L1 X (cf. Remark 12.1) it is enough to assume
that p = 1. Let ε > 0. The proposition is a consequence of Proposition 10.4, we have that
P(∥Xn − X∥ > ε) ≤

E[∥Xn − X∥]
.
ε

Proposition 12.3. Suppose that Xn →a.s. X. Then, Xn →P X.
Proof. Consider the real valued sequence dn = E[min{∥Xn − X∥, 1}], n ∈ N. We notice that
if limn→∞ dn = 0, then Xn →P X. To see it, we rely on Proposition 10.4 and deduce that
for any ε ∈ (0, 1),
P(∥Xn − X∥ > ε) ≤ P(min{∥Xn − X∥, 1} > ε) ≤

dn
.
ε

Therefore, it is sufficient to show that Xn →a.s. X implies that limn→∞ dn = 0. Upon
Xn →a.s. X it follows that min{∥Xn −X∥, 1} →a.s. 0. Hence, by the dominated convergence
theorem (cf. Proposition 8.10), limn→∞ dn = 0.
115

Proposition 12.4. If Xn →P X and Xn →P Y , then X = Y P a.s. The same is true if
Xn →a.s. X and Xn →a.s. Y or Xn →Lp X and Xn →Lp Y .
Proof. By Propositions 12.2 and 12.3 it is sufficient to show that if Xn →P X and Xn →P Y ,
then X = Y P a.s. Given ε > 0, we have that
P({∥Xn − X∥ > ε} ∪ {∥Xn − Y ∥ > ε}) ≤ P(∥Xn − X∥ > ε) + P(∥Xn − Y ∥ > ε).
Thus, if Xn →P X and Xn →P Y , we deduce that
lim P({∥Xn − X∥ > ε} ∪ {∥Xn − Y ∥ > ε}) = 0.

n→∞

In particular,
lim P({∥Xn − X∥ ≤ ε} ∩ {∥Xn − Y ∥ ≤ ε}) = 1.

n→∞

(43)

Therefore, if ω ∈ {∥Xn − X∥ ≤ ε/2} ∩ {∥Xn − Y ∥ ≤ ε/2}, it follows that
∥X(ω) − Y (ω)∥ = ∥X(ω) − Xn (ω) + Xn (ω) − Y (ω)∥ ≤ ∥Xn − X∥ + ∥Xn − Y ∥ ≤ ε.
Since P(∥X(ω) − Y (ω)∥ ≤ ε) is constant in n, it follows from (43) that
P(∥X(ω) − Y (ω)∥ ≤ ε) = 1.
Therefore,

P

P(∥X(ω) − Y (ω)∥ > 1/n) = 0. Hence, by item (i) of Proposition 12.1,

[
∞  \
∞
{∥X(ω) − Y (ω)∥ ≤ 1/k}
= 1.
P(X = Y ) = P

n∈N

n=1

k=n

Example 12.1. Let (Xn )n∈N be a sequence of random variables s.t. for any n ∈ N, Xn
takes the values 1 − (1/n) and 1 + (1/n) with probability 1/2, i.e., for any n ∈ N, the law of
Xn is s.t. PXn ({1 − (1/n)}) = PXn ({1 + (1/n)}) = 1/2. We have that
E[|Xn − 1|2 ] =

1 n→∞
−−−−→ 0.
n2

Hence, Xn →L2 1. In particular, Xn →L1 1 (cf. Remark 12.1).
P∞ Upon Proposition 12.2,
Xn →P 1. Let An = {|Xn − 1| > 1/n}, n ∈ N. We have that n=1 P(An ) = 0. Hence, by
item (i) of Proposition 12.1,
[

∞  \
∞
n→∞
1=P
{|Xk − 1| ≤ 1/k}
= P(Xn −−−−→ 1).
n=1

k=n

Example 12.2. Assume that (Xn )n∈N is an independent sequence of random variables (cf.
Definition 11.4) s.t. for any n ∈ N,
P(Xn = 0) = 1 −

1
n

and

P(Xn = 1) =

1
.
n

We have that
2

E[|Xn − 0| ] =




1 2 1 2 n→∞
1−
0 + 1 −−−−→ 0,
n
n

i.e., P
Xn →Lp 0, p =
2, and in particular Xn →P 0. Set An = {Xn = 1}. We have
P1,
∞
∞
that n=1 P(An ) = n=1 1/n = ∞ (cf. Example 3.5). Therefore, by item (ii) of Proposition 12.1,
\

∞  [
∞
P
{Xk = 1}
= 1.
n=1

k=n

116

Thus, P(Xn = 1 for infinitely many n) = 1. In particular, since



Xn = 1 for infinitely many n ⊂ lim sup Xn ≥ 1 ⊂ lim Xn ̸= 0 ,
n→∞

n→∞
n→∞

we obtain P(Xn −−−−→ 0) = 0. That is, (Xn )n∈N does not converges almost surely to 0.
Example 12.3. Assume that (Xn )n∈N is a sequence of random variables s.t. for any n ∈ N,
P(Xn = 0) = 1 −

1
2n

and

P(Xn = 2n+1 ) =

1
.
2n

Then, for anyP
n ∈ N, E[|Xn − 0|] = 2, i.e., it is not true that Xn →Lp 0, p = 1, 2. However,
∞
we have that n=1 P(Xn ̸= 0) = 1 < ∞, i.e., by item (i) of Proposition 12.1,
P(Xn ̸= 0 for infinitely many n) = 0.
We observe that
{Xn ̸= 0 for infinitely many n}c ⊂ {∃ N s.t. Xn = 0 ∀ n ≥ N }.
This is because {∃ N s.t. Xn = 0 ∀ n ≥ N }c ⊂ {Xn ̸= 0 for infinitely many n}. In conclusion, P({∃ N s.t. Xn = 0 ∀ n ≥ N }) = 1 and hence Xn →a.s. 0.
Exercise 12.2. Let (Xn )n∈N be a sequence of random variables s.t. for any n ∈ N,
P(Xn = n) = 1 −

1
2n

and

P(Xn = 1/n) =

1
.
2n

Show that there exists no random variable X s.t. (Xn )n∈N converges to X in probability.
Note: This implies that (Xn )n∈N can not converge in L1 or almost surely (cf. Propositions 12.2 and 12.3).
Exercise 12.3. Let (Xn )n∈N be a sequence of independent random variables s.t. for any
n ∈ N,
P(Xn = 0) = 1 −

1
n

and

P(Xn = n) =

1
.
n

Show that Xn →P 0 but (Xn )n∈N neither converges in L1 nor almost surely to zero.
Remark 12.3. By Exercise 12.2, it is possible that (Xn )n∈N converges in L2 to a random
variable X but it does not hold that (Xn )n∈N converges almost surely to X. In addition,
by Example 12.3, it is possible that Xn →a.s. X where the convergence is not in L1 . By
Exercise 12.3, there exists (Xn )n∈N that converge in probability to X but the convergence is
neither in L1 nor almost surely.
The following proposition shows that given a sequence of random vectors that converges
in probability, one can always extract a subsequence that converges almost surely.
Proposition 12.5. Let (Xn )n∈N be a sequence of random vectors s.t. Xn →P X. Then,
there exists a subsequence (Xs(n) )n∈N s.t. Xs(n) →a.s. X.
Proof. Define εm = 1/m and am = 2−m , m ∈ N. Then, given any m ∈ N, since Xn →P X,
lim P(∥Xn − X∥ > εm ) = 0.

n→∞

By the latter convergence, we set m = 1 and find s(1) ∈ N s.t. P(∥Xs(1) − X∥ > ε1 ) ≤ a1 .
Then, for m = 2, we find s(2) > s(1) s.t. P(∥Xs(2) − X∥ > ε2 ) ≤ a2 . If we continue like
this, we obtain a subsequence (Xs(n) )n∈N s.t. for any n ∈ N, P(∥Xs(n) − X∥ > εn ) ≤ an .
117

P
P∞
We notice that n∈N P(∥Xs(n) − X∥ > εn ) ≤ n=1 2−n = 1. Thus, by the first item of the
Borel-Cantelli lemma (item (i) of Proposition 12.1),
1=P

[ \
∞


{∥Xs(k) − X∥ ≤ εk }

= P(∃ N ∈ N s.t. ∀ n ≥ N ∥Xs(n) − X∥ ≤ εn ).

n∈N k=n

Thus, Xs(n) →a.s. X.
A consequence for sequences of random variables is the following result:
Proposition 12.6. Let (Xn )n∈N be a sequence of random variables s.t. Xn →P X. Suppose
that there exists a random variable Y s.t. E[|Y |] < ∞ and for any n ∈ N, |Xn | ≤ Y P a.s.
Then, Xn →L1 X.
Proof. Let (Xs(n) )n∈N be any subsequence of (X(n) )n∈N . Since Xn →P X, we readily check
that Xs(n) →P X as well. Notice that given any ε > 0, (P(|Xs(n) − X| > ε))n∈N is a
subsequence of (P(|Xn − X| > ε))n∈N . Since Xs(n) →P X, we rely on Proposition 12.5
and find a subsequence (Xt(s(n)) )n∈N s.t. Xt(s(n)) →a.s. X. Then, by assumption, for any
n ∈ N, |Xt(s(n)) | ≤ Y P a.s. Hence, upon Lebesgues dominated convergence theorem
(cf. Proposition 8.10), X is integrable with respect to P, i.e., E[|X|] < ∞. Similarly, since
n→∞
|Xt(s(n)) −X| ≤ 2|Y | P a.s. and |Xt(s(n)) −X| −−−−→ 0 P a.s., we apply Lebesgues dominated
convergence theorem to the sequence (|Xt(s(n)) − X|)n∈N and deduce that
(44)

lim E[|Xt(s(n)) − X|] = 0.

n→∞

This shows that Xn →L1 X since we started with an arbitrary subsequence (E[|Xs(n) −
X|])n∈N of (E[|Xn − X|])n∈N and found a subsequnece (E[|Xt(s(n)) − X|])n∈N s.t. (44) holds
(cf. Proposition 3.24).
Proposition 12.7. Let Xn = (X1n , . . . , Xkn ), n ∈ N, be a sequence of random vectors and
X = (X1 , . . . , Xk ) be a random vector.
(i) Xn →a.s. X if and only if for any i = 1, . . . , k, Xin →a.s. Xi ;
(ii) if Xn →a.s. X, then for any continuous function g : Rk → Rm , g(Xn ) →a.s. g(X);
(iii) Xn →P X if and only if for any i = 1, . . . , k, Xin →P Xi ;
(iv) if Xn →P X, then for any continuous function g : Rk → Rm , g(Xn ) →P g(X).
Proof. We leave items (i) and (ii) as an exercise (cf. Exercise 12.6). We show item (iii).
Suppose that Xn →P X. Let ε > 0. Given any i = 1, . . . , k, we have that
n→∞

P(|Xin − Xin | > ε) ≤ P(∥Xn − X∥ > ε) −−−−→ 0.
For the other direction, suppose that for any i = 1, . . . , k, Xin →P Xi . Let ε > 0. We have
that
P(∥Xn − X∥ > ε) ≤ P

[
k 
i=1

≤

k
X

ε
|Xin − Xi | > √
k



√  n→∞
P |Xin − Xi | > ε/ k −−−−→ 0.

i=1

Therefore, Xn →P X. With regard to (iv), suppose that Xn →P X and let g : Rk → Rm
be continuous. Let (Xs(n) )n∈N be an arbitrary subsequence of (Xn )n∈N . As in the proof of
Proposition 12.6, Xs(n) →P X. By Proposition 12.5, we find a subsequence (Xt(s(n)) )n∈N
118

s.t. Xt(s(n)) →a.s. X. By (i), g(Xt(s(n)) ) →a.s. g(X) and in particular, g(Xt(s(n)) ) →P g(X).
Let ε > 0. We use the notation ∥·∥m for the Eucildean norm on Rm . We have shown
that for any arbitrary subsequnece P(∥g(Xs(n) ) − g(X)∥m > ε), n ∈ N, there exists a
subsequence P(∥g(Xt(s(n)) ) − g(X)∥m > ε), n ∈ N, s.t. limn→∞ P(∥g(Xt(s(n)) ) − g(X)∥m >
ε) = 0. This shows that limn→∞ P(∥g(Xn ) − g(X)∥m > ε) = 0, i.e., g(Xn ) →P g(X) (cf.
Proposition 3.24).
Exercise 12.4. Let Xn = (X1n , . . . , Xkn ), n ∈ N, and X = (X1 , . . . , Xk ) be random vectors.
Given p = 1, 2, show that Xn →Lp X if and only if for any i = 1, . . . , k, Xin →Lp Xi .
Exercise 12.5. Let (Xn )n∈N be a sequence of random variables s.t. Xn →L1 X. Show that
for any g : R → R continuous and bounded, g(Xn ) →L1 g(X).
Remark 12.4. One can show that the result of the previous exercise is not true in general
if g is only assumed to be continuous but not necessarily bounded.
The following is known as Scheffé’s lemma:
Proposition 12.8. Let (Xn )n∈N be a sequence of random variables. Suppose that for any
n→∞
n ∈ N, E[|Xn |] < ∞ and Xn →P X where E[|X|] < ∞. Then, E[|Xn |] −−−−→ E[|X|] implies
that Xn →L1 X.
Proof. Let (Xs(n) )n∈N be an arbitrary subsequence of (Xn )n∈N . Since Xs(n) →P X, we
apply Proposition 12.5 and find a subsequnece (Xt(s(n)) )n∈N s.t. Xt(s(n)) →a.s. X. Define
Yn = |Xt(s(n)) | + |X| − |Xt(s(n)) − X|,

n ∈ N.

We have that Yn (ω) ≥ 0 for any ω ∈ Ω and Yn →a.s. 2|X|. By Fatou’s lemma (cf. Proposition 8.9),
2E[|X|] = E[lim inf Yn ] ≤ lim inf E[Yn ].
n→∞

n→∞

n→∞

Since by assumption, E[|Xn |] −−−−→ E[|X|], it follows that (cf. Proposition A.4)
lim inf E[Yn ] = 2E[|X|] − lim sup E[|Xt(s(n)) − X|].
n→∞

n→∞

Hence,
2E[|X|] ≤ 2E[|X|] − lim sup E[|Xt(s(n)) − X|],
n→∞

and hence, lim supn→∞ E[|Xt(s(n)) − X|] = lim supn→∞ E[|Xt(s(n)) − X|] = 0. This shows
that Xt(s(n)) →L1 X. In particular, by Proposition 3.24, Xn →L1 X.
Remark 12.5. Notice that if (Xn )n∈N is a sequence of random variables s.t. Xn →L1 X,
then, upon Exercise 8.6 and the reverse triangular inequality,


E[|Xn |] − E[|X|] ≤ E |Xn | − |X| ≤ E[|Xn − X|],
n→∞

n→∞

and hence E[|Xn |] −−−−→ E[|X|]. However, in general, E[|Xn |] −−−−→ E[|X|] does not imply
that Xn →L1 X. As an example, let Xn , n ∈ N, be s.t. P(Xn = 1) = 1/n and P(Xn =
n→∞
−1) = 1 − (1/n). Then, E[|Xn |] −−−−→ 1. However, limn→∞ E[|Xn − 1|] = 2 ̸= 0.
The following is known as the (strong) law of large numbers (a proof is given in Section C.7 of the appendix).
Proposition 12.9. Let (Xn )n∈N be an i.i.d. (cf. Definition 11.4) sequence of random variables s.t. E[|X1 |] < ∞. Then,
1
(X1 + · · · + Xn ) →a.s. E[X1 ].
n
119

Example 12.4. Let (Xn )n∈N be an i.i.d. sequence of random variables s.t. E[|X1 |] < ∞.
Assume that E[X1 ] = µ and Var(X1 ) = σ 2 , µ, σ 2 ∈ R, σ 2 > 0. Define, X n = n−1 (X1 +
· · · + Xn ), n ∈ N. Then,
n
2
1X
Xi − X n →a.s. σ 2 .
(45)
n i=1
To see it, we write
n

n

2
2
1X
1X
Xi − X n =
Xi − µ + µ − X n
n i=1
n i=1

n 
1X
(Xi − µ)2 + 2(Xi − µ)(µ − X n ) − (µ − X n )2
=
n i=1
n

n

=

1X
1X
(Xi − µ)2 + 2(µ − X n )
(Xi − µ) + (µ − X n )2
n i=1
n i=1

=

1X
(Xi − µ)2 − (µ − X n )2 .
n i=1

n

By Proposition 11.6, the sequence of random variables ((Xn − µ)2 )n∈N is an independent
sequence of random variables. Clearly, given any n ∈ N, the law of (Xn − µ)2 is the same
as the law of (X1 − µ)2 (cf. Proposition 10.3). Thus, ((Xn − µ)2 )n∈N is an i.i.d. sequence of
random variables s.t. E[|(X1 − µ)2 |] = E[(X1 − µ)2 ] = σ 2 . Upon the law of large numbers,
n

1X
(Xi − µ)2 →a.s. σ 2 .
n i=1
By the law of large number again, it also follows that µ − X n →a.s. 0 and in particular, by
Proposition 12.7, (µ − X n )2 →a.s. 0. In conclusion, we apply Proposition 12.7 once more
and (45) follows.
Remark 12.6. If Xn = (X1n , . . . , Xkn ), n ∈ N, is a sequence of i.i.d. random vectors s.t.
E[|Xi1 |] < ∞, i = 1, . . . , k. Then, for any i = 1, . . . , k, (Xin )n∈N is a sequence of i.i.d. random variables (independence follows from Proposition 11.6 with fi1 (X1 ) = Xi1 , . . . , fin (Xn ) =
Xin , n ∈ N, and Xin , n ∈ N, are identically distributed because of Proposition 10.3 upon the
identification of Xi1 , . . . , Xin with the coordinate functions fi1 , . . . , fin , as above). In particular, for any i = 1, . . . , k, we apply the law of large numbers (cf. Proposition 12.9) to
(Xin )n∈N and obtain that n−1 (X1 + · · · + Xn ) →a.s. E[X1 ].

12.2

A note on convergence in distribution

Definition 12.2. A sequence of random vectors Xn = (X1n , . . . , Xkn ), n ∈ N, converges in
distribution to a random vector X (we write Xn →d X) if for any continuous and bounded
function φ : Rk → R,
n→∞

E[φ(Xn )] −−−−→ E[X].
That is to say that the sequence of measures (PXn )n∈N converges weakly to the measure PX .
The following proposition shows that convergence in distribution is the weakest form of
the types of convergence we have seen so far.
Proposition 12.10. Let (Xn )n∈N be a sequence of random vectors s.t. Xn →P X. Then,
Xn →d X.

120

To conclude, we list some results regarding convergence in distribution (for further reading we refer to [1] and [2]).
Remark 12.7. Let Xn = (X1n , . . . , Xkn ), n ∈ N, be a sequence of random vectors and
X = (X1 , . . . , Xk ) be a random vector.
n→∞

(i) Xn →d X does not imply that PXn (B) −−−−→ PX (B) for any B ∈ B(Rk ).
Qk
n→∞
(ii) If Xn →d X, then for any rectangle Rk = i=1 [ai , bi ], ai , bi ∈ R, PXn (Rk ) −−−−→
PX (Rk ).
(iii) Let X be a random vector and A = {t ∈ Rk : FX is continuous at t}. Then, Xn →d X
n→∞
if and only if FXn (t) −−−−→ FX (t) for any t ∈ A.
(iv) Let c ∈ Rk and set X(ω) = c for any ω ∈ Ω. If Xn →d c, then Xn →P c. That
is, convergence in distribution to a constant implies convergence in probability to the
given constant.
n→∞

(v) Xn →d X if and only if ΦXn (v) −−−−→ ΦX (v) for any v ∈ Rk . This is known as Lévy’s
theorem. It shows that convergence in distribution of a sequence of random vectors
(Xn )n∈N to X is equivalent to the pointwise convergence of the respective sequence of
characteristic functions (ΦXn )n∈N to the characteristic function of X.
(vi) Suppose that (Xn )n∈N are i.i.d. and s.t. Var(Xin ) < ∞ for any i = 1, . . . , k. Then,
X1 + · · · + Xn − nE[X1 ]
√
→d N (0, Σ(X1 )).
n

(46)

For k = 1, (46) reads as n−1/2 (X1 + · · · + Xn − nE[X1 ]) →d N (0, Var(X1 )). The result
given in (46) is known as the central limit theorem.

12.3

Solution to exercises

Solution 12.1 (Solution to Exercise 12.1). Let ω ∈ lim supn→∞ An . Then, for any n ∈ N,
there exists kn ≥ n s.t. ω ∈ Akn , i.e., ω ∈ Akn , n ∈ N. For the other inclusion, suppose that
ω ∈ Ω is s.t. ω ∈ Ak , k ∈ N. Then, for any n ∈ N, there exists k ≥ N , s.t. ω ∈ Ak . Thus,
ω ∈ lim supn→∞ An .
Solution
12.2 P
(Solution to Exercise 12.2). Define An = {Xn ̸= n}. We deduce that
P∞
∞
n
P(A
)
=
n
n=1
n=1 (1/2) = 1 (cf. Exercise 3.14). Therefore, by item (i) of Proposition 12.1,
P(Xn ̸= n for infinitely many n) = 0.
Then, we notice that
{Xn ̸= n for infinitely many n}c ⊂ {∃ N s.t. Xn = n ∀ n ≥ N }.
Hence, P({∃ N s.t. Xn = n ∀ n ≥ N }) = 1. Then, assume by contradiction that X is a
random variable s.t. Xn →P X. Let ω ∈ {∃ N s.t. Xn = n ∀ n ≥ N }. Find N ∗ ∈ N s.t.
N ∗ ≥ N and |Xn (ω) − X(ω)| > 1 for any n ≥ N ∗ . This shows that
{∃ N s.t. Xn = n ∀ n ≥ N } ⊂ {∃ N ∗ s.t. |Xn − X| > 1 ∀ n ≥ N ∗ }.
Write A = {∃ N ∗ s.t. |Xn − X(ω)| > 1 ∀ n ≥ N ∗ }. Given any k ≥ N ∗ , we obtain
1 = P(A) = P({|Xk − X| > 1} ∩ A) ≤ P(|Xk − X| > 1).
Therefore, for any k ≥ N ∗ , P(|Xk − X| > 1) = 1. This contradicts Xn →P X.
121

Solution 12.3 (Solution to Exercise 12.3). As in Example 12.2, we apply item (ii) of
Proposition 12.1 and deduce that
P(Xn = n for infinitely many n) = 1.
Hence, it is not possible that Xn converges almost surely to zero. Additionally, E[|Xn |] = 1
for any n ∈ N, i.e., it is also not true that Xn converges in L1 to zero. Let ε > 0, we have
n→∞
that P(|Xn | > ε) = 1/n −−−−→ 0. Thus, Xn →P 0.
Solution 12.4 (Solution to Exercise 12.4). Let p = 2. Suppose that for any i = 1, . . . , k,
Xin →L2 Xi . We have that
E[∥Xn − X∥2 ] =

k
X

n→∞

E[|Xin − Xi |2 ] −−−−→ 0.

i=1

Therefore Xn →L2 X. For the other direction, if Xn →L2 X, then by the previous display,
E[|Xin − Xi |2 ] ≤ E[∥Xn − X∥2 ], i = 1, . . . , k, i.e., Xin →L2 Xi for any i = 1, . . . , k. If p = 1
we readily check that Xn →L1 X implies that Xin →L1 Xi for any i = 1, . . . , k (keep in mind
that E[∥Xn − X∥] ≥ E[|Xin − Xi |], i = 1, . . . , k). We also notice that

E[∥Xn − X∥] ≤ k 1/2 E

max |Xin − Xi |2

i=1,...,k

1/2 



= k 1/2 E max |Xin − Xi | .
i=1,...,k

Hence, if Xin →L1 Xi for any i = 1, . . . , k, Xn →L1 X as well.
Solution 12.5 (Solution to Exercise 12.5). Since Xn →L1 X it follows that Xn →P X
(cf. Proposition 12.2). By item (iv) of Proposition 12.7, g(Xn ) →P g(X). Also, since
g is bounded, |g(Xn (ω))| ≤ C, ω ∈ Ω, where C ∈ R. Therefore, by Proposition 12.6,
g(Xn ) →L1 g(X).

12.4

Additional exercises

Exercise 12.6. Verify items (i) and (ii) of Proposition 12.7.
Exercise 12.7. Let (Xn )n∈N and (Yn )n∈N be two sequences of random variables. Verify the
following:
(a) If Xn →a.s. X and Yn →a.s. Y , then Xn + Yn →a.s. X + Y and Xn Yn →a.s. XY ;
(b) If Xn →P X and Yn →P Y , then Xn + Yn →P X + Y and Xn Yn →P XY .
Exercise 12.8. Let {An : n ∈ N} be a collection of independent events (cf. Definition 11.4)
s.t. P(An ) = P(A1 ) for any n ∈ N. Show that
n

1X
1A →a.s. P(A1 )
n i=1 i
Exercise 12.9. Let p ∈ [0, 1]. Show that for any continuous function f : [0, 1] → R,
lim

n→∞

n  
X
n
k=0

k

pk (1 − p)n−k f (k/n) = f (p).

Hint: You might want to apply the law of large numbers (cf. Proposition 12.9).
Exercise 12.10. Prove Proposition 12.10.

122

A
A.1

Results from analysis
On infima and suprema: arithmetic set operations

We derive further results on the infimum and supremum of subsets of the real numbers.
With regard to arithmetics on sets, we make the following definition:
Definition A.1. Let ∅ =
̸ A ⊂ R. Then,
(1.) −A = {−x : x ∈ A};
(2.) cA = {ca : a ∈ A}, c ∈ R;
(3.) A + B = {a + b : a ∈ A, b ∈ B}.
Proposition A.1. Let ∅ =
̸ A ⊂ R. be bounded from above.
(i) If A is bounded from above, then −A is bounded from below and inf −A = − sup A;
(ii) if A is bounded from below, then −A is bounded from above and sup −A = − inf A.
Proof. We only verify item (i) (the argument for item (ii) is similar). We notice first that
since A is bounded from above, we rely on Proposition 1.5 and know that sup A ∈ R. Hence,
since sup A is an upper bound for A, it follows that for any x ∈ A, x ≤ sup A. In particular,
for any x ∈ A. −x ≥ − sup A. Thus, − sup A is a lower bound of −A. By Proposition 1.5,
the infimum of −A exists as an element of the real numbers. We thus write L = inf −A.
Then, we show that L = − sup A. Clearly, since L is the infimum of −A and − sup A is a
lower bound of −A it follows that L ≥ − sup A (L is the greatest lower bound). On the
other hand, given any x ∈ A, −x ≥ L, it follows that x ≤ −L and hence −L is an upper
bound for A. This leads to sup A ≤ −L and hence − sup A ≥ L.
Proposition A.2. Let ∅ =
̸ A ⊂ R and c > 0.
(i) If sup(cA) < ∞, then sup A < ∞ and sup(cA) = c sup A;
(ii) if inf(cA) > −∞, then inf A > −∞ and inf(cA) = c inf(A).
Proof. Given any a ∈ A, ca ≤ sup(cA). Hence, since c > 0, a ≤ sup(cA)/c. Thus, since by
assumption sup(cA) < ∞ and a ∈ A was arbitrary, it follows that sup A ≤ sup(cA)/c < ∞.
Notice that the latter inequality shows that c sup A ≤ sup(cA). Also, since c > 0, ca ≤
c sup A for any a ∈ A, hence, sup(cA) ≤ c sup A and we conclude that sup(cA) = c sup A.
This shows (i). The argument for (ii) is similar.
Proposition A.3. Let A, B ⊂ R, A and B not empty.
(i) If sup(A + B) < ∞, then sup A < ∞, sup B < ∞ and sup(A + B) = sup A + sup B;
(ii) If inf(A + B) > −∞, then inf A > −∞, inf B > −∞ and inf(A + B) = inf A + inf B.
Proof. We show item (i). Notice that since sup(A + B) < ∞, it follows that for any a ∈ A,
a + b ≤ sup(A + B) and hence a ≤ sup(A + B) − b. Therefore, since a ∈ A was arbitrary,
sup A ≤ sup(A + B) − b < ∞ and we conclude that sup A < ∞. A similar argument
shows that sup B < ∞. We readily see that sup(A + B) ≤ sup A + sup B. Now either
sup(A + B) < sup A + sup B or sup(A + B) = sup A + sup B. We show that if we assume
that sup(A + B) < sup A + sup B, then we arrive at a contradiction. Hence, suppose that
sup(A + B) < sup A + sup B. Let δ = sup A + sup B − sup(A + B) > 0. By Proposition 1.10,
there exists a ∈ A s.t. a > sup A − (δ/2). Similarly, there exists b ∈ B s.t. b > sup B − (δ/2).
Hence,
a + b > sup A + sup B − δ = sup(A + B),
which is a contradiction. Therefore, sup(A + B) = sup A + sup B. The argument for (ii) is
similar.
123

A.2

On limit inferior and limit superior

We derive further properties of the limit inferior and limit superior.
Proposition A.4. Let (bn )n∈N be a real valued sequence s.t. limn→∞ bn = b. Then,
(i) lim inf n→
− ∞ (bn + an ) = b + lim inf n→
− ∞ an and lim inf n→
− ∞ (−an ) = − lim supn→
− ∞ an ;
(ii) lim supn→
− ∞ an .
− ∞ (bn +an ) = b+lim supn→
− ∞ an and lim supn→
− ∞ (−an ) = − lim inf n→
Proof. We only show (i), since the arguments for (ii) are similar. Assume first that (an )n∈N
is bounded from below. We have that for any n ∈ N and any given j ≥ n, inf k≥n bk +
inf k≥n ak ≤ bj + aj . Therefore, inf k≥n bk + inf k≥n ak ≤ inf k≥n (bk + ak ). Hence,
b + lim inf an = lim ( inf bk + inf ak ) ≤ lim inf (bk + ak ) = lim inf (bn + an ).
n→
−∞
n→∞ k≥n
n→∞ k≥n
n→
−∞
k≥n
If (an )n∈N is not bounded from below, then by definition, −∞ = b + lim inf n→
− ∞ an =
lim inf n→
− ∞ (bn + an ) (where we used the convention that −∞ + x = −∞ for x ∈ R). For
the other inequality we notice that by the previous inequality,
lim inf an = lim inf (bn + an − bn ) ≥ lim inf (bn + an ) + lim inf (−bn ) = lim inf (bn + an ) − b.
n→
−∞
n→
−∞
n→
−∞
n→
−∞
n→
−∞
Thus also lim inf n→
− ∞ (bn + an ) ≤ b + lim inf n→
− ∞ an . Let us show that lim inf n→
− ∞ (−an ) =
− lim supn→
a
.
We
assume
first
that
(a
)
is
bounded
from
above.
By
Proposition
A.1,
n n∈N
−∞ n
we know that {−an : n ∈ N} is bounded from below and inf k≥n (−ak ) = − supk≥n ak . Hence,
lim inf (−an ) = lim inf (−ak ) = − lim sup ak = − lim sup an .
n→
−∞
n→∞ k≥n
n→∞ k≥n
n→
−∞
If (an )n∈N is not bounded from above, then {−an : n ∈ N} is not bounded from below and
by definition of the limit inferior and limit superior lim inf n→
− ∞ (−an ) = − lim supn→
− ∞ an =
−∞.
Proposition A.5. Let fn : A → R, n ∈ N, be a sequence of functions. Define the sequences
of functions gn = inf k≥n fk and hn = supk≥n fk , n ∈ N. Then,
(i) for any x ∈ A, (gn (x))n∈N is increasing and gn (x) ↑ lim inf n→
− ∞ fn (x);
(ii) for any x ∈ A, (hn (x))n∈N is decreasing and hn (x) ↓ lim supn→
− ∞ fn (x).
Proof.
(i) Let x ∈ A. Suppose that (gn (x)) is bounded from below. Then, using Exercise 3.7 and
Proposition 3.18, (gn (x)) is increasing with limit lim inf n→
− ∞ fn (x). If (gn (x)) is not
bounded from below, still, for any n ∈ N, gn+1 (x) = inf k≥n+1 fk (x) ≥ inf k≥n fk (x) =
gn (x), i.e., (gn (x)) is increasing. Suppose that there exists N ∈ N s.t. (gN (x)) > −∞.
Then, we rely on the sequence gn∗ (x) = gn−1+N (x), n ∈ N, and repeat the arguments
given in the proof of Proposition 3.18 to show that limn→∞ gn∗ (x) = supn∈N gn∗ (x).
Therefore, limn→∞ gn (x) = supn∈N gn∗ (x). Since supn∈N gn (x) ≤ supn∈N gn∗ (x), this
shows that limn→∞ gn (x) ≥ supn∈N gn (x). The other inequality, limn→∞ gn (x) ≤
supn∈N gn (x), is obtained from the arguments already given in the proof of Proposition 3.18. Finally, if for any n ∈ N, gn (x) = −∞, limn→∞ gn (x) = −∞ =
lim inf n→
− ∞ fn (x) (cf. Definition 3.10).
(ii) We may repeat a similar argument as in (i).

124

A.3

On convergent sequences

Proposition A.6. Let (an )n∈N be a real-valued sequence s.t. for any n ∈ N, |an | > n.
Then, (an )n∈N has no convergent subsequence.
Proof. This follows from the fact that any subsequence (as(n) )n∈N of (an )n∈N is not bounded.
Notice that if (as(n) )n∈N is a subsequence of (an )n∈N , then for any n ∈ N, |as(n) | > s(n).
Since s(n) < s(n + 1) for any n ∈ N the set {s(n) : n ∈ N} is countably infinite and hence
not bounded. Thus, sup{s(n) : n ∈ N} = ∞. Therefore, for any M ∈ R, there exists n ∈ N
s.t. s(n) > M . Since |as(n) | > s(n), it follows in particular that |as(n) | > M . Therefore,
(as(n) )n∈N is not bounded (cf. Definition 3.3).
We prove the subsequence criterion for convergent sequences stated at the end of Section 3.2.
Proof of Proposition 3.24. First, we prove that (A) implies that (an )n∈N is bounded. To
see it, suppose by contradiction that (an )n∈N is not bounded. Then, find n1 ∈ N s.t.
1 < |an1 | ≤ 1 + N1 for some N1 ∈ N \ {1}. Since (an )n∈N is not bounded, there exists
n2 ∈ N s.t. 2 < 1 + N1 < |an2 | < 1 + N1 + N2 for some N2 ∈ N \ {1}. We continue
like this and obtain a subsequence (bk )k∈N = (as(k) )k∈N , s(k) = nk , k ∈ N where for any
k ∈ N, |bk | > k. By Proposition A.6, (bk )k∈N can not have any convergent subsequence.
This contradicts (A). Hence, (A) implies that (an )n∈N is bounded. We verify that (A)
implies that limn→∞ an = a. Again, we consider an argument by contradiction and suppose
that (A) is true but limn→∞ an ̸= a. If limn→∞ an ̸= a, (A) implies that (an )n∈N can
not be convergent, since if (an )n∈N was convergent with limit L, then any subsequence of
(an )n∈N must converge to the same limit L and then (A) implies that L = limn→∞ an =
a. In summary, under the assumption that (A) holds and limn→∞ an ̸= a, (an )n∈N is
bounded but does not converge. Using Propositions 3.20 and 3.21, this implies that m =
lim inf n→
− ∞ an < lim supn→
− ∞ an = M , where m = limn→∞ mn and M = limn→∞ Mn
with mn = inf{ak : k ≥ n} and Mn = sup{ak : k ≥ n}, respectively (cf. Propositions 3.18
and 3.19). Thus, if we write as(n) = mn , n ∈ N, and as̃(n) = Mn , n ∈ N, we identify
two subsequences (as(n) )n∈N and (as̃(n) )n∈N of (an )n∈N with limit m and M , respectively.
But then, for any subsequence (at(s(n)) )n∈N and (at̃(s̃(n)) )n∈N of (as(n) )n∈N and (as̃(n) )n∈N ,
respectively, it follows that limn→∞ at(s(n)) = m and limn→∞ at̃(s̃(n)) = M . Since m ̸= M ,
(A) is violated and hence we arrive at a contradiction. We conclude that limn→∞ an = a.

A.4

Continuity

For this section, we use the notation ∥·∥m and ∥·∥k for the Euclidean distance on Rm and
Rk , respectively (cf. Definition 2.14).
Definition A.2. Let f : E → Rk , E ⊂ Rm . Then, f is continuous at a point x ∈ E, if for
any ε > 0, there exists δ > 0 s.t. for any y ∈ E, if ∥x − y∥m < δ, then ∥f (x) − f (y)∥k < ε.
Definition A.3. A function f : E → Rk , E ⊂ Rm is referred to as continuous (or continuous on E) if it is continuous at any point x ∈ E.
Example A.1. Let m = k = 1 and consider f (x) = x, x ∈ R. Then, clearly f : R → R is
continuous. For any ε > 0, let δ = ε, then |x − y| < δ implies that |f (x) − f (y)| < ε.
Example A.2. Let c ∈ R and f (x) = c for any x ∈ R. Then, clearly f : R → R is
continuous since for any ε > 0, |f (x) − f (y)| = 0 < ε.
The following is known as the intermediate value theorem, it supports our natural understanding of a continuous function defined on a closed interval.

125

Proposition A.7. Let f : [a, b] → R be continuous s.t. f (a) ̸= f (b). Suppose that γ is a
value s.t.


γ ∈ min{f (a), f (b)}, max{f (a), f (b)} ,
i.e., γ is between f (a) and f (b), then there exists s ∈ [a, b] s.t. f (s) = γ. That is, any value
γ between f (a) and f (b) is attained by f .


Proof. Let γ ∈ min{f (a), f (b)}, max{f (a), f (b)} . Assume that that f (a) < f (b). Suppose
that γ ∈ (f (a), f (b)), since if γ = f (a) or γ = f (b), the result follows. Define
A = {x ∈ [a, b] : f (x) < γ}.
A is not empty, since f (a) < γ. Clearly, since A is bounded, s = sup A < ∞. Further,
s ∈ [a, b]. There are three cases, f (s) < γ, f (s) > γ or f (s) = γ. We show that only
f (s) = γ is possible. Suppose first that that f (s) < γ, i.e., s ∈ A. In particular, s < b since
s = b is not possible (s = b implies with s ∈ A that γ > f (b)). Then, since f is continuous
on [a, b] and s ∈ [a, b], f is continuous at s, i.e., there exists δ > 0 s.t. for any x ∈ [a, b],
if |x − s| < δ, then |f (x) − f (s)| < γ − f (s) (recall that γ − f (s) > 0). In particular,
f (x) − f (s) ≤ |f (x) − f (s)| < γ − f (s) and hence, if x ∈ [a, b] s.t. |x − s| < δ, we obtain
f (x) < γ. Since s < b, we let ε > 0 s.t. s + ε ≤ b. Set x = s + min{(δ/2), ε}. Then, x ∈ [a, b]
and |x − s| < δ and hence f (x) < γ. This is a contradiction with s = sup A. Hence, the
case f (s) < γ is not possible. Assume now f (s) > γ. Using the same reasoning as before,
there exists δ > 0 s.t. for any x ∈ [a, b], if |x − s| < δ then f (x) > γ. Then, since s < ∞,
by Proposition 1.10, there exists x ∈ A s.t. x > s − δ. Since s ≥ x, that particular x is s.t.
f (x) > γ and f (x) < γ, which is again a contradiction. Hence, we obtain f (s) = γ and the
proposition is proven.
We prove the sequence criterion for continuous functions stated in Section 3.3.
Proof of Proposition 3.26. We first show that item (i) implies item (ii). Hence, let f be
continuous at x. Take any (xn )n∈N ⊂ E which is s.t. limn→∞ xn = x. Since f is continuous
at x, for any ε > 0, there exists δ > 0 s.t. ∥f (x) − f (y)∥k < ε if ∥x − y∥m < δ. Since
limn→∞ xn = x, there exists N ∈ N, s.t. ∥x − xn ∥m < δ for any n ≥ N . Therefore,
∥f (x) − f (xn )∥k < ε for any n ≥ N . Since ε > 0 was arbitrary, the result follows. For
the other direction, assume that item (ii) is true. Assume by contradiction that f is not
continuous at x. Hence, there exists ε > 0 s.t. for any δ > 0, there exists y ∈ E with
∥x − y∥m < δ but ∥f (x) − f (y)∥k ≥ ε. Let δ = 1/n, n ∈ N. For any n ∈ N, let yn be s.t.
∥x − yn ∥m < 1/n and ∥f (x) − f (yn )∥k ≥ ε. Then limn→∞ yn = y but limn→∞ f (yn ) ̸= f (x).
This contradicts item (ii), and hence the proof is complete.
Proposition A.8. Let f = (f1 , . . . , fk ) : E → Rk , E ⊂ Rm . Then, f is continuous at
x ∈ E if and only if fi is continuous at x for any i = 1, . . . , k.
Proof. This follows from Propositions 3.26 and 3.25.
Pk
Proof of Proposition 2.12. Let f : Rk → R, f (x) = i=1 xk , x = (x1 , . . . , xk ). Assume that
n→∞
(an )n∈N ∈ (Rk )N , an = (an1 , . . . , ank ), s.t. an −−−−→ x where x ∈ Rk . Then, by Proposition 3.25, limn→∞ ani = xi for any i = 1, . . . , k. Hence, using Proposition 3.4,
f (an ) =

k
X

n→∞

ani −−−−→

i=1

k
X

xk = f (x).

i=1

Therefore, by Proposition 3.26, f is continuous at x. Since x was arbitrary, f : Rk → R is
continuous. A similar argument shows that g und h are continuous.

126

Proposition A.9. Let f : A → B, A ⊂ Rm and B ⊂ Rk . Further, let g : B → C, C ⊂ Rl .
If f is continuous at x ∈ A and g is continuous at f (x), then g(f ) : A → C is continuous at
x.
Proof. Let (xn )n∈N ∈ AN s.t. limn→∞ xn = x. Since f is continuous at x, it follows that
limn→∞ f (xn ) = f (x). Then, since g is continuous at f (x), limn→∞ g(f )(xn ) = g(f )(x).
m
Example
A.3. Let fi : E
Pk
Qk→ R, E ⊂ R , i = 1, . . . , k, be continuous. Then, f =
i=1 fi : E → R and g =
i=1 fi : E → R are continuous as well. To see it, let x ∈ E. We
first use Proposition A.8 and conclude that x 7→ ψ(x) = (f1 (x), . . . , fk (x)) is continuous at
Pk
x. Further, by Proposition 2.12, given any y = (y1 , . . . , yk ) ∈ Rk , y 7→ s(y) = i=1 yi and
Qk
y 7→ p(y) = i=1 yi are continuous at y. Therefore, using Proposition A.9, it follows that
f (x) = s(ψ)(x) and g(x) = p(ψ)(x) are continuous at x. Since x ∈ E was arbitrary, the
result follows.

Proposition A.10. Let f : Rm → Rk . The following are equivalent:
(i) f is continuous;
(ii) for any open set U ⊂ Rk , f −1 (U ) is open in Rm .
Proof. To avoid confusion, we write Brm (a) and Brk (b) for an open ball with center a ∈ Rm
and b ∈ Rk , respectively. We first show that (i) implies (ii). Therefore, let U ⊂ Rk be an open
set. Let x ∈ f −1 (U ), i.e., f (x) ∈ U . Since U is open, there exists ε > 0, s.t. Bεk (f (x)) ⊂ U .
Since f is continuous at x, there exists δ > 0 s.t. if y ∈ Bδm (x), then f (y) ∈ Bεk (f (x)). Hence,
f (Bδm (x)) ⊂ Bεk (f (x)). Hence, Bδm (x) ⊂ f −1 (Bεk (f (x))) ⊂ f −1 (U ). Therefore, f −1 (U ) is
open in Rm . We show that (ii) implies (i). Let x ∈ Rm , ε > 0 and consider the open set
Bεk (f (x)). Then, by assumption, f −1 (Bεk (f (x))) is open in Rm . Clearly, x ∈ f −1 (Bεk (f (x))).
Hence, there exists δ > 0, s.t. Bδm (x) ⊂ f −1 (Bεk (f (x))). That is, f (Bδm (x)) ⊂ Bεk (f (x)).
This implies that f is continuous at x. Since x ∈ Rm was arbitrary, the result follows.
In accordance with Definition 2.16, we can define open sets in E, where E ⊂ Rm .
Definition A.4. Let E ⊂ Rm , E ̸= ∅. The Euclidean distance ∥·∥m restricted to E is
denoted with ∥·∥E . Given x ∈ E, we write BrE (x) = {y ∈ E : ∥y − x∥E < r} for an open ball
in E of radius r > 0 with center x. A set V ⊂ E is open if for any x ∈ V , there exists ε > 0
s.t. BεE (x) ⊂ V .
The latter definition leads to the following result.
Proposition A.11. Let E ⊂ Rm , E ̸= ∅. A function f : E → Rk is continuous if and only
if for any U ⊂ Rk open, f −1 (U ) is an open set in E.
Proof. We repeat the arguments given in Proposition A.10 (replace open balls in Rm with
open balls in E) and the result follows.
We prove Propositions 2.11 and 3.13.
Proof of Proposition 2.11. Using Proposition A.11, we show that a set V ⊂ E is open if and
only if there exists G ⊂ Rm which is open in Rm and s.t. V = G ∩ E. Let V ⊂ E. Suppose
that there exists G ⊂ Rm , open in Rm , s.t. V = G ∩ E. Let x ∈ V , then x ∈ G ∩ E, and since
G is open and x ∈ G, there exists Bεm (x) ⊂ G. Thus, Bεm (x) ∩ E = BεE (x) ⊂ G ∩ E = V .
This shows that V is open in E. For the other direction, let V ⊂ E be open in E. Then,
given any x ∈ V , there exists BεEx (x) s.t. BεEx (x) ⊂ V . We know that for any x ∈ V , Bεmx (x)
is open in Rm (cf. Example 2.16). Define
[
G=
Bεmx (x).
x∈V

127

It is clear that G is open in Rm , since given any y ∈ G, there exists x ∈ V , s.t. y ∈
Bεmx (x) ⊂ G. Certainly V ⊂ G and hence V = V ∩ E ⊂ G ∩ E. On the other hand,
G ∩ E = ∪x∈V BεEx (x) ⊂ V , since for any x ∈ V , BεEx (x) ⊂ V . Therefore, V = G ∩ E.
Proof of Proposition 3.13. We only show the existence of xM since the arguments for the
minimum are similar. Let S = supx∈R f (x). There are two cases, either S < ∞ or S = ∞. If
S = ∞, let (xn )n∈N be a sequence s.t. for any n ∈ N xn ∈ [a, b] and f (xn ) ≥ n (for example,
given any n ∈ N, set xn = min{x ∈ [a, b] : f (x) ≥ n}). Since xn ∈ [a, b] for any n ∈ N, it
follows that (xn )n∈N is bounded and hence by Proposition 3.12, there exists a subsequence
(xs(n) )n∈N s.t. limn→∞ xs(n) = ξ ∈ [a, b]. Notice that ξ ∈ [a, b], since a ≤ xn ≤ b for any
n ∈ N. In particular, since f is continuous on [a, b], it follows that limn→∞ f (xs(n) ) = f (ξ).
On the other hand, since for any n ∈ N, f (xn ) ≥ n, it follows that limn→∞ f (xs(n) ) = ∞.
Which gives a contradiction. Hence it must be the case that S < ∞. In this case, we set
an = S − 1/n, n ∈ N, and by Proposition 1.10, there exists (xn )n∈N s.t. for any n ∈ N xn ∈
[a, b] and f (xn ) > Sn . Again, we apply Proposition 3.12, and find a subsequence (xs(n) )n∈N
s.t. limn→∞ xs(n) = xM ∈ [a, b]. Since f is continuous on [a, b], limn→∞ f (xs(n) ) = f (xM ).
Then, we have that for any n ∈ N,
f (xs(n) ) ≥ S −

1
,
s(n)

and hence, limn→∞ f (xs(n) ) ≥ S. Clearly, limn→∞ f (xs(n) ) ≤ S as well and hence S =
f (xM ) = maxx∈[a,b] f (x). To see that f is bounded (cf. Definition 2.20), we apply Proposition A.9 and note that x 7→ |f (x)| is continuous on [a, b]. Therefore, for any x ∈ [a, b],
|f (x)| ≤ |f (xM )|.
Example A.4. We list some examples of continuous functions:
• x 7→ ex as a function from R to R;
• x 7→ log(x) as a function from (0, ∞) to R;
• x 7→ sin(x) as a function from R to R;
• x 7→ cos(x) as a function from R to R.

A.5

Limit points

Definition A.5. Let E ⊂ Rm be a nonempty set. A point a ∈ Rm is said to be a limit
or accumulation point of E if there exists a vector-valued sequence (xn )n∈N which satisfies
n→∞
xn ∈ E \ {a} for any n ∈ N and xn −−−−→ a.
For this section, unless stated otherwise, any sequence is a real-valued sequence according
to Definition 3.1.
Definition A.6. Let E ⊂ R be a nonempty set and f : E → R be a function. If a ∈ R is a
limit point of E, we write limx→a f (x) = L if there exists L ∈ R s.t. for any sequence (xn )n∈N
n→∞
n→∞
which satisfies xn ∈ E \ {a} for any n ∈ N and xn −−−−→ a, it follows that f (xn ) −−−−→ L.
Proposition A.12. Let E ⊂ R be a nonempty set and f : E → R be a function. Then,
limx→a f (x) = L if and only if for any ε > 0, there exists δ > 0 s.t. for any x ∈ E \ {a}, if
|x − a| < δ, |f (x) − L| < ε.
Proof. This is essentially the proof of the sequence criterion of continuous function where
the limit f (x) is replaced with L (cf. the proof of Proposition 3.26).

128

Definition A.7. Let E ⊂ R be a nonempty set and f : E → R be a function. If a ∈ R is
a limit point of E ∩ (−∞, a), we write limx↑a f (x) = Ll if there exists Ll ∈ R s.t. for any
sequence (xn )n∈N which is s.t.
n→∞

{xn : n ∈ N} ⊂ E ∩ (−∞, a) and xn −−−−→ a,
n→∞

it follows that f (xn ) −−−−→ Ll . Similarly, if a ∈ R is a limit point of E ∩ (a, ∞), we use the
notation limx↓a f (x) = Lr if there exists Lr ∈ R s.t. for any sequence (xn )n∈N which is s.t.
n→∞

{xn : n ∈ N} ⊂ E ∩ (a, ∞) and xn −−−−→ a,
n→∞

it follows that f (xn ) −−−−→ Lr . If they exists, Ll and Lr are referred to as the left-hand and
right-hand limit of f as x approaches a.
If we adapt the proof of Proposition 3.26 accordingly, we readily verify the following
result:
Proposition A.13. Let E ⊂ R be a nonempty set and f : E → R be a function. Then,
limx↑a f (x) = Ll if and only if for any ε > 0, there exists δl > 0 s.t. for any x ∈ E \ {a},
x ∈ (a − δl , a) implies that |f (x) − Ll | < ε. Similarly, limx↓a f (x) = Lr if and only if for any
ε > 0, there exists δr > 0 s.t. for any x ∈ E \ {a}, x ∈ (a, a + δl ) implies that |f (x) − Lr | < ε.
Proposition A.14. Let E ⊂ R be a nonempty set and f : E → R be a function. Then,
limx→a f (x) = L if and only if
lim f (x) = L = lim f (x).
x↑a

x↓a

Proof. Let δl and δr be as in Proposition A.13 and apply Proposition A.12 with δ =
min{δl , δr }.
Upon the definition of continuity (cf. Definition A.2), Proposition A.14 shows the following:
Proposition A.15. Let E ⊂ R be a nonempty set and f : E → R be a function. Then, f
is continuous at a point a ∈ E, if and only if limx↑a f (x) = f (a) = limx↓a f (x).
Proposition A.16. Let E ⊂ R be a nonempty set and f : E → R be a function. Then,
limx↑a f (x) = Ll if and only if
n→∞

(47)

n→∞

(48)

∀ (xn )n∈N s.t. xn ∈ E \ {a} ∀n ∈ N and xn ↑ a it follows that f (xn ) −−−−→ Ll .
Similarly, limx↓a f (x) = Lr if and only if
∀ (xn )n∈N s.t. xn ∈ E \ {a} ∀n ∈ N and xn ↓ a it follows that f (xn ) −−−−→ Lr .

Proof. We only show that (47) implies limx↑a f (x) = Ll and vice versa. The argument for
the right-hand limit is the same. By Definition A.7, if limx↑a f (x) = Ll , then, (47) holds.
Thus, suppose that (47) holds and let (xn )n∈N be a sequence s.t.
n→∞

{xn : n ∈ N} ⊂ E ∩ (−∞, a) and xn −−−−→ a.
n→∞

n→∞

Let (xs(n) )n∈N be any subsequence of (xn )n∈N . Since xn −−−−→ a, it follows that xs(n) −−−−→
a. In particular, (xs(n) )n∈N is bounded. Define xt(s(n)) = inf{xs(k) : k ≥ n}, n ∈ N.
Then, (xt(s(n)) )n∈N is increasing and s.t. xt(s(n)) ↑ a (cf. Exercise 3.7). Thus, by (47),
limn→∞ f (xt(s(n)) ) = Ll . Therefore, we have shown that for any subsequence (f (xs(n) ))n∈N
of (f (xn ))n∈N there exists a subsequence (f (xt(s(n)) ))n∈N s.t. limn→∞ f (xt(s(n)) ) = Ll . By
Proposition 3.24, limn→∞ f (xn ) = Ll and hence (47) implies that limx↑a f (x) = Ll .
129

Definition A.8. Let E ⊂ R be a nonempty set and f : E → R be a function. If E is not
bounded from above, we write limx→∞ f (x) = L if there exists L ∈ R s.t. for any sequence
n→∞
n→∞
(xn )n∈N which is s.t. {xn : n ∈ N} ⊂ E and xn −−−−→ ∞, it follows that f (xn ) −−−−→ L.
Similarly, if E is not bounded from below, we write limx→−∞ f (x) = L if there exists L ∈ R
n→∞
s.t. for any sequence (xn )n∈N which is s.t. {xn : n ∈ N} ⊂ E and xn −−−−→ −∞, it follows
n→∞
that f (xn ) −−−−→ L.
Proposition A.17. Let E ⊂ R be a nonempty set and f : E → R be a function. If E is
not bounded from above, then limx→∞ f (x) = L if and only if for any ε > 0 there exists
a real number M > 0 s.t. for any x ∈ E with x > M , |f (x) − L| < ε. Similarly, if E is
not bounded from below, limx→−∞ f (x) = L if and only if for any ε > 0 there exists a real
number M > 0 s.t. for any x ∈ E with x < −M , |f (x) − L| < ε.
Proof. Suppose that limx→∞ f (x) = L and there exists ε > 0 s.t. for any M > 0 there exists
x ∈ E s.t. x > M with |f (x) − L| ≥ ε. Let n1 = 1 and obtain n1 < x1 ≤ n2 which is s.t.
|f (x1 ) − L| ≥ ε. Then, find n2 < x2 ≤ n3 which also satisfies |f (x2 ) − L| ≥ ε. If we continue
like this, we obtain a sequence (xn )n∈N which is s.t. for any n ∈ N, |f (xn ) − L| ≥ ε. Since
n→∞
xn −−−−→ ∞ this contradicts limx→∞ f (x) = L. Therefore, limx→∞ f (x) = L implies that
for any ε > 0 there exists a real number M > 0 s.t. for any x ∈ E s.t. x > M , |f (x) − L| < ε.
For the other direction, suppose that for any ε > 0 there exists a real number M > 0 s.t.
for any x ∈ E with x > M , |f (x) − L| < ε. Let ε > 0 and consider {xn : n ∈ N} ⊂ E s.t.
n→∞
n→∞
xn −−−−→ ∞. Since xn −−−−→ ∞, there exists N ∈ N, s.t. for any n ≥ N , xn > M . Thus,
n→∞
by assumption, |f (xn ) − L| < ε, i.e., f (xn ) −−−−→ L. The argument for limx→−∞ f (x) = L
is similar and we consider the proposition as proven.
Similar to Proposition A.16, we have the following result:
Proposition A.18. Suppose that f : E → R is a function where E ⊂ R is a nonempty set.
Suppose that E is not bounded from above. Then, limx→∞ f (x) = L if and only if
n→∞

∀ (xn )n∈N s.t. xn ∈ E ∀n ∈ N and xn ↑ ∞ it follows that f (xn ) −−−−→ L.

(49)

Similarly, if E is not bounded from below, limx→−∞ f (x) = L if and only if
n→∞

∀ (xn )n∈N s.t. xn ∈ E ∀n ∈ N and xn ↓ −∞ it follows that f (xn ) −−−−→ L.

(50)

Proof. We only show that (50) implies that limx→−∞ f (x) = L and vice versa (the remaining
argument is similar). Suppose that E is not bounded from below. Clearly, if limx→−∞ f (x) =
L, then by Definition A.8, (50) is satisfied. Hence, suppose that (50) is satisfied. Assume by
contradiction that there exists ε > 0 s.t. for any M > 0 there exists x ∈ E s.t. x < −M with
|f (x) − L| ≥ ε. Let n1 = −1 and obtain n2 ≤ x1 < n1 which is s.t. |f (x1 ) − L| ≥ ε. Then,
find n3 ≤ x2 < n2 which also satisfies |f (x2 ) − L| ≥ ε. If we continue like this, we obtain
a sequence (xn )n∈N which is s.t. xn ↓ −∞ but limn→∞ f (xn ) ̸= L. This contradicts (50).
Hence, for any ε > 0 there exists a real number M > 0 s.t. for any x ∈ E with x < −M ,
|f (x) − L| < ε. By Proposition A.17 this implies that limx→−∞ f (x) = L.
Remark A.1. Notice that if E ⊂ Rm , a ∈ Rm is a limit point of E and f : E → Rk is
a function, limx→a f (x) = L, L ∈ Rk , is defined as in Definition A.6 with (xn )n∈N vectorvalued.

A.6

Differentiability in one variable and the mean value theorem

Definition A.9. Let f : [a, b] → R be a function. The derivative of f at x0 ∈ (a, b) is
defined as the limit


f (x) − f (x0 )
f (x0 + h) − f (x0 )
f ′ (x0 ) = lim
= lim
.
x→x0
h→0
x − x0
h
f is referred to as differentiable if f ′ (x0 ) ∈ R for any x0 ∈ (a, b), i.e., f ′ : (a, b) → R.
130

Remark A.2. If f : [a, b] → R is differentiable, then f is continuous on (a, b). In particular,
if f is continuous in a and b, f is continuous on the entire [a, b].
Proposition A.19. Let f : [a, b] → R be a differentiable function. Suppose that x0 ∈ (a, b)
is a maximum point (resp. minimum point) of f , i.e., f (x) ≤ f (x0 ) for any x ∈ [a, b] (resp.
f (x) ≥ f (x0 ) for any x ∈ [a, b]). Then, f ′ (x0 ) = 0.
Proof. Suppose that x0 ∈ (a, b) is a maximum point of f . By Proposition A.14, we know
that
≤0

≤0

z
}|
{
z
}|
{
f (x) − f (x0 )
f
(x)
−
f
(x
)
0
lim
= f ′ (x0 ) = lim
.
x↑x0
x↓x0
x − x0 }
x − x0 }
| {z }
| {z }
≤0

≥0

Hence, f ′ (x0 ) = 0. The same argument works if x0 ∈ (a, b) is a minimum point of f .
The next result is known as Rolle’s theorem.
Proposition A.20. Let f : [a, b] → R be continuous and differentiable. Suppose that f (a) =
f (b). Then, there exists x0 ∈ (a, b) s.t. f ′ (x0 ) = 0.
Proof. Since f (a) = f (b), there are three cases:
(i) for any x ∈ (a, b) f (x) = f (b);
(ii) there exists x ∈ (a, b) s.t. f (x) > f (b);
(iii) there exists x ∈ (a, b) s.t. f (x) < f (b).
In case (i), f is constant on (a, b), i.e., f ′ (x) = 0 for any x ∈ (a, b). If case (ii) is true, then,
since f is continuous on [a, b], there exists x0 ∈ [a, b] s.t. f (x0 ) ≥ f (y) for any y ∈ [a, b]
(cf. Proposition 3.13). We notice that x0 = a or x0 = b is not possible since this would
imply that f (x0 ) = f (a) = f (b) < x. Thus, the maximum point is s.t. x0 ∈ (a, b). By
Proposition A.19, f ′ (x0 ) = 0. Finally suppose that case (iii) holds. By Proposition 3.13
again, let x0 be a minimum point of [a, b]. Again, x0 ∈ (a, b) and hence, f ′ (x0 ) = 0.
The mean value theorem (or Lagrange theorem) reads as follows:
Proposition A.21. Let f : [a, b] → R be continuous and differentiable. Then, there exists
m ∈ (a, b) s.t.
f (b) − f (a) = f ′ (m)(b − a).
Proof. Define
g(x) = f (x) −

x−a
(f (b) − f (a)).
b−a

We notice that g is s.t. g(a) = g(b), g is continuous on [a, b] and the derivative of g exists
for any point x0 ∈ (a, b). Thus, by Proposition A.20, there exists m ∈ (a, b) s.t. g ′ (m) = 0.
That is,
0 = g ′ (m) = f ′ (m) −

131

f (b) − f (a)
.
b−a

Example A.5. Given any x ∈ R, 1 + x ≤ ex . Clearly, the inequality becomes an equality if
x = 0. Let x > 0 and consider the interval [0, x]. By the mean value theorem, there exists
m ∈ (0, x) s.t.
ex − e0 = ex −1 = em (x − 0) = em x.
Since m > 0, em > 1. Therefore, the previous display shows that ex −1 > x ⇔ 1 + x < ex .
If x < 0, then, again by the mean value theorem, there exists m ∈ (x, 0) s.t. 1 − ex = − em x.
Then, since m ∈ (x, 0) and −x > 0, we obtain with 0 < em < 1 that 1 − ex < −x ⇔
1 + x < ex .

A.7

Differentiability in several variables

Definition A.10. A function L : Rm → Rk is linear if for any v1 , v2 ∈ Rm and for any
λ1 , λ2 ∈ R,
L(λ1 v1 + λ2 v2 ) = λ1 L(v1 ) + λ2 L(v2 ).
Suppose that f : [a, b] → R is differentiable in x0 ∈ (a, b), i.e., the limit f ′ (x0 ) exists
according to Definition A.9. Define the map: Lx0 (h) = f ′ (x0 )h, h ∈ R. Then, Lx0 : R → R
is linear and
f (x0 + h) − f (x0 ) − Lx0 (h)
= 0.
(51)
lim
h→0
h
On the other hand if there exists a linear map Lx0 : R → R s.t. f satisfies (51) for some
x0 ∈ (a, b), then,
lim

h→0

f (x0 + h) − f (x0 ) − Lx0 (h)
f (x0 + h) − f (x0 )
= lim
+ Lx0 (1) = Lx0 (1),
h→0
h
h

that is f is differentiable in x0 according to Definition A.9. This shows that the following
definition is equivalent to Definition A.9.
Definition A.11. A function f : [a, b] → R is differentiable in x0 ∈ (a, b) if there exists a
linear map Lx0 : R → R s.t. (51) is satisfied.
In general, differentiability is defined as follows (again ∥·∥m and ∥·∥k denote the Euclidean
distance on Rm and Rk , respectively):
Definition A.12. Let U ⊂ Rm be an open set. A function f : U → Rk is differentiable in
x0 ∈ U if there exists a linear map Lx0 : Rm → Rk s.t.
lim

h→0

f (x0 + h) − f (x0 ) − Lx0 (h)
= 0.
∥h∥m

(52)

The map f is referred to as differentiable on U if f is differentiable for any x0 ∈ U . Further,
the linear map Lx0 is said to be differential of f in x0 .
Remark A.3. Let U ⊂ Rm be an open set and f : U → Rk be differentiable in x0 ∈ U .
Then the linear map Lx0 in (52) is unique. That is, if Lx0 and L̃x0 are two linear maps that
satisfy (52), then Lx0 = L̃x0 . To see it, if Lx0 and L̃x0 satisfy (52), then for any v ∈ Rm ,
v ̸= 0, by linearity and (52),
Lx0 (v/∥v∥m ) − L̃x0 (v/∥v∥m ) = 0.
Thus, Lx0 = L̃x0 .

132

Example A.6. Let f (x) = Ax + b, A ∈ Rk×m , b ∈ Rk . Let L(x) = Ax, x ∈ Rm . Given
any x0 ∈ Rm , we have that
f (x0 + h) − f (x0 ) − L(h)
= 0.
h→0
∥h∥m
lim

Therefore, f : Rm → Rk is differentiable with differential L (cf. Remark A.3).
The following proposition is of central importance:
Proposition A.22. Let U ⊂ Rm be an open set and f = (f1 , . . . , fk ) : U → Rk be a map.
Assume that x0 ∈ U . Then, f is differentiable in x0 if and only if any function fi : U → R,
i = 1, . . . , k, is differentiable in x0 . Further, if f is differentiable in x0 , the differential of f
in x0 is given by the map
Lx0 = (L1x0 , . . . , Lkx0 ),
where Lix0 : Rm → R is the differential of fi in x0 , i = 1, . . . , k.
Proof. Suppose first that f is differentiable in x0 , i.e., there exists a linear map Lx0 : Rm →
Rk s.t. (52) is satisfied. Define the linear map
Lix0 (v) =

m
X

aij vj ,

i = 1, . . . , k,

j=1

where A = (aij )1≤i≤k,1≤j≤m is the matrix representation of Lx0 . Notice that this implies
that
Av = (L1x0 (v), . . . , Lkx0 (v)),

v ∈ Rm .

Further, for any i = 1, . . . , k,
|fi (x0 + v) − fi (x0 ) − Lix0 (v)| ≤ ∥f (x0 + v) − f (x0 ) − Lx0 (v)∥k .
Thus, by (52),
|fi (x0 + v) − fi (x0 ) − Lix0 (v)|
= 0,
v→0
∥v∥m
√
and in particular (recall that t 7→ |t| = t2 is continuous),
lim

fi (x0 + v) − fi (x0 ) − Lix0 (v)
= 0.
v→0
∥v∥m
lim

For the other direction, suppose that for any i = 1, . . . , k, fi is differentiable in x0 with
differential Lix0 in x0 . Then, we define the map
Lx0 (v) = (L1x0 (v), . . . , Lkx0 (v)),

v ∈ Rm ,

and notice that Lx0 : Rm → Rk is linear since Lix0 , i = 1, . . . , k, are linear. Then, since for
any i = 1, . . . , k,
fi (x0 + v) − fi (x0 ) − Lix0 (v)
= 0,
v→0
∥v∥m
lim

it follows with
v
u k 
uX fi (x0 + v) − fi (x0 ) − Lix (v) 2
∥f (x0 + v) − f (x0 ) − Lx0 (v)∥k
0
=t
,
∥v∥m
∥v∥
m
i=1
133

that
lim

v→0

∥f (x0 + v) − f (x0 ) − Lx0 (v)∥k
= 0.
∥v∥m

In particular,
f (x0 + v) − f (x0 ) − Lx0 (v)
= 0,
v→0
∥v∥m
lim

and hence f is differentiable in x0 with differential Lx0 .
In the following, we aim to find an explicit description of the matrix representation of the
differential of a differentiable map. This matrix will be referred to as the Jacobian matrix.
Definition A.13. Let U ⊂ Rm be open, x0 ∈ U and f : U → R be a function. The
directional derivative of f in direction v ̸= 0 is defined as the limit (if it exists)
∂v f (x0 ) =

∂f
f (x0 + tv) − f (x0 )
(x0 ) = lim
.
t→0
∂v
t

Proposition A.23. Let U ⊂ Rm be an open set and f : U → R be differentiable in x0 ∈ U .
Then, for any v ̸= 0, the directional derivative ∂v f (x0 ) exists and is given by
∂f
(x0 ) = Lx0 (v).
∂v
Proof. By assumption, f is differentiable in x0 , hence there exists a linear map Lx0 : Rm → R
s.t. (52) is satisfied. Then, given any v ∈ Rm , v ̸= 0, we obtain
f (x0 + tv) − f (x0 )
f (x0 + tv) − f (x0 ) − Lx0 (tv) Lx0 (tv)
=
+
∥tv∥m
∥tv∥m
∥tv∥m
f (x0 + tv) − f (x0 ) − Lx0 (tv) Lx0 (tv)
=
+
.
∥tv∥m
∥tv∥m
By (52), it follows that
lim
t↓0

f (x0 + tv) − f (x0 )
Lx0 (v)
=
.
∥tv∥m
∥v∥m

Thus,
lim
t↓0

f (x0 + tv) − f (x0 )
f (x0 + tv) − f (x0 )
= ∥v∥m lim
= Lx0 (v).
t↓0
t
∥tv∥m

Similarly,
lim
t↑0

f (x0 + tv) − f (x0 )
= Lx0 (v),
t

and the result follows.
Definition A.14. Let U ⊂ Rm be open, x0 ∈ U and f : U → R be a function. Let e1 , . . . , em ,
be the standard basis of Rm , i.e.,
ej = (0, . . . , 0,

1 , 0, . . . , 0),
|{z}

j = 1, . . . , m.

position j

The directional derivatives of f in direction ej , j = 1, . . . , m, are referred to as the partial
derivatives of f in x0 . We use the notation
∂f
∂f
(x0 ) =
(x0 ) = ∂xj f (x0 ),
∂ej
∂xj
134

j = 1, . . . , m.

Remark A.4. Let U ⊂ Rm be an open set and x0 ∈ U . Suppose that f : U → R is
differentiable in x0 . Then, by Proposition A.23, the partial derivatives ∂xj f (x0 ) exists for
any j = 1, . . . , m. In particular, for any j = 1, . . . , m,
∂f
(x0 ) = Lx0 (ej ).
∂xj
Pm
Write v = j=1 vj ej , where vj ∈ R and e1 , . . . , em , is the standard basis of Rm . By linearity,
we obtain that
m
m
X
X
∂f
Lx0 (v) =
(x0 ).
(53)
vj Lx0 (ej ) =
vj
∂x
j
j=1
j=1
The identity (53) is the representation of the differential of f in x0 in terms of the partial
derivatives.
Definition A.15. Let f : U → Rk , U ⊂ Rm open. Suppose that the partial derivatives
∂xj fi (x0 ) exist for any j = 1, . . . , m and i = 1, . . . , k. Then, the matrix
 ∂f1

∂f1
∂f1
∂x1 (x0 )
∂x2 (x0 ) . . .
∂xm (x0 )


..
..
..
..
Jf (x0 ) = 

.
.
.
.
∂fk
∂fk
∂fk
∂x1 (x0 )
∂x2 (x0 ) . . .
∂xm (x0 )
is referred to as the Jacobian matrix of f in x0 .
We have all the tools to easily verify the following:
Proposition A.24. Let f : U → Rk , U ⊂ Rm open. Suppose that f is differentiable in
x0 ∈ U with differential Lx0 . Then, the matrix representation of the linear map Lx0 is given
by the Jacobian matrix Jf (x0 ).
Proof. Suppose that v ̸= 0 (for v = 0, the result is trivial). By Proposition A.22 and (53),
we have that
X

m
m
X
∂f1
∂fk
1
k
vj
Lx0 (v) = (Lx0 (v), . . . , Lx0 (v)) =
(x0 ), . . . ,
vj
(x0 ) = Jf (x0 )v.
∂xj
∂xj
j=1
j=1

Remark A.5. One can show that f : U → Rk , U ⊂ Rm open, is differentiable in x0 ∈ U
if for any v ∈ U , the partial derivatives ∂xj fi (v), j = 1, . . . , m, i = 1, . . . , k, exist and are
continuous in x0 . This provides a useful criterion to verify the differentiability of f in x0 .

B
B.1

Measure and integration
Inclusion-exclusion principle

The following is known as the inclusion-exclusion formula:
Proposition B.1. Let (Ω, F) be a measurable space and µ be a measure on F. Assume
that A1 , . . . , An ∈ F are s.t. µ(Ai ) < ∞ for any i = 1, . . . , n. We have that
!
[
 X
n
n
X
k−1
µ
Ai =
(−1)
µ(AI ) ,
(54)
i=1

I∈An
k

k=1

where
Ank = {I ⊂ {1, . . . , n} : #I = k},
and for any I ∈ Ank , µ(AI ) = µ(∩i∈I Ai ).
135

k = 1, . . . , n,

n ∈ N,

Proof of Proposition B.1. If n = 1, (54) is trivial. If n = 2, (54) states that
µ(A1 ∪ A2 ) = µ(A1 ) + µ(A2 ) − µ(A1 ∩ A2 ),
which is true since by item (iv) of Proposition 5.1, µ(A1 ∪ A2 ) + µ(A1 ∩ A2 ) = µ(A1 ) + µ(A2 )
and since µ(A1 ) and µ(A2 ) are assumed to be finite, we can subtract µ(A1 ∩ A2 ) on both
sides of the latter equation. By induction, assume that (54) holds for n ∈ N. We have that
 n+1
[

[

n
n
[ 
µ
Ai = µ
Ai + µ(An+1 ) − µ
(Ai ∩ An+1 )
i=1

i=1

=

i=1

!

n
X

X

(−1)k−1

+ µ(An+1 )
!

n
X

−

µ(AI )

I∈An
k

k=1

X

k−1

(−1)

(55)

µ(AI ∩ An+1 ) .

I∈An
k

k=1

Then, for any k = 1, . . . , n, Ank ⊂ An+1
, and therefore,
k
! n+1
!
n
X
X
X
X
k−1
k−1
(−1)
(−1)
µ(AI ))
µ(AI )) −
I∈An
k

k=1

=−

n
X

I∈An+1
k

k=1

!!
X

(−1)k−1

µ(AI ))

.

I∈(An+1
\An
k
k)

k=1

We notice that the latter sum is equal to
!!

n
X

− µ(An+1 ) −

(−1)

µ(AI ))

I∈(An+1
\An
k
k)

k=1

!!

n
X

= −µ(An+1 ) +

X

k+1−1

X

(−1)k−1

µ(AI ))

.

I∈(An+1
\An
k
k)

k=1

Further, for any I ∈ An+1
\ Ank , AI = AJ ∩ An+1 for J ∈ Ank . Hence, the latter sum reads as
k
!!
n
X
X
−µ(An+1 ) +
(−1)k−1
µ(AI ∩ An+1 ))
.
I∈An
k

k=1

If we add and subtract

Pn+1

k=1 ((−1)

k−1

P

I∈An+1
k

µ(AI ))) from (55), we obtain that

!
 n+1
[  n+1
X
X
k−1
µ
Ai =
(−1)
µ(AI )) .
i=1

B.2

I∈An+1
k

k=1

On measure extensions

Proof of Proposition 6.2. The finite case, i.e., there exists N ∈ N s.t.
∪i∈I (ai , bi ] = ∪N
i=1 (ai , bi ],

136

follows by induction. The base step of the induction is clear, if (a, b] ⊂ (c, d], then c ≤ a <
b ≤ d and hence b − a ≤ d − c. For the induction step assume that (11) holds for N − 1
PN
intervals. Let (a, b] ⊂ ∪N
i=1 (ai , bi ]. We want to show that b − a ≤
i=1 (bi − ai ). Notice first
that we can always assume that b1 ≤ b2 ≤ · · · ≤ bN . If not, we can just consider a relabeling
and the union would remain unchanged. Assume first that b ∈
/ (aN , bN ]. Then, b ≤ aN
since b > bN is not possible. To see this, assume by contradiction that b > bN . Then, since
b1 ≤ b2 ≤ · · · ≤ bN , b ∈
/ (ai , bi ] for any i = 1, . . . , N . Since b ∈ (a, b] ⊂ ∪N
i=1 (ai , bi ], this is
N −1
not possible. Hence, b ∈
/ (aN , bN ] ⇒ b ≤ aN . Hence, (a, b] ⊂ ∪i=1
(ai , bi ] since if y ∈ (a, b],
y ≤ b ≤ aN and hence y ∈
/ (aN , bN ]. By the induction hypothesis, the result follows. Thus,
in the remaining we assume that b ∈ (aN , bN ]. If aN ≤ a, then aN ≤ a < b ≤ bN and the
N −1
result follows. Hence, assume that a < aN . Then, (a, aN ] ⊂ ∪i=1
(ai , bi ]. This is because
y ∈ (a, aN ] implies that y ∈
/ (aN , bN ]. Further y ∈ (a, aN ] implies that a < y ≤ aN < b
(b ∈ (aN , bN ]) and hence (a, aN ] ⊂ (a, b]. Since (a, b] is a subset of ∪N
i=1 (ai , bi ] it follows
−1
that y ∈ (ai , bi ] for some i ̸= N , i.e., (a, aN ] ⊂ ∪N
(a
,
b
].
By
the
induction
hypothesis,
i
i
i=1
PN −1
PN
(b
−a
)
≥
a
−a.
Therefore,
(b
−a
)
≥
a
−a+b
−a
≥
a
−a+b−a
i
i
N
i
N
N
N
N
N = b−a.
i=1
i=1 i
We use the Heine-Borel theorem for intervals (cf. Proposition 2.9) to prove the infinite case,
∞
i.e., ∪i∈I (ai , bi ] = ∪∞
i=1 (ai , bi ]. Suppose that (a, b] ⊂ ∪i=1 (ai , bi ]. Let ε > 0 be s.t. b − a > ε.
This is possible since b ̸= a. Clearly, the family of intervals (ai , bi + ε2−i ), i ∈ N, are s.t.
[
[a + ε, b] ⊂
(ai , bi + ε2−i ).
i∈N

By Proposition 2.9 it follows that there exists i1 , . . . , iN , s.t.
[a + ε, b] ⊂

N
[

(aik , bik + ε2−ik ).

k=1

Hence, by the finite case,
b−a+ε≤
≤

N
X

(bik − aik + ε2

−ik

k=1
∞
X

∞
X

i=1

i=1

(bi − ai ) + ε

)=

2−i

By Exercise 3.14, we obtain that b − a + ε ≤
argument.

N
X

(bik − aik ) + ε

k=1
∞
X

N
X

2−ik

k=1
∞

ε X −i
2 .
(bi − ai ) +
=
2 i=0
i=1
P∞

i=1 (bi

− ai ) + ε. This completes the

Proof of Proposition 6.5. Given any ξ ∈ CA (A), A ∈ P(Ω), vρ (ξ) ≥ 0. It follows that
ρ∗ (A) ≥ 0 for any A ∈ P(Ω). By assumption, ∅ ∈ A. Hence we can take ξ = {∅} and have
that ξ is a covering of ∅ by sets from A. Further, since ρ(∅) = 0, it follows that vρ (ξ) = 0.
This shows that ρ∗ (∅) ≤ 0. Since ρ∗ (A) ≥ 0 for any A ∈ P(Ω), it follows that ρ∗ (∅) = 0.
Let A, B ∈ P(Ω) s.t. A ⊂ B. Since A ⊂ B, we have that
{vρ (ξ) : ξ ∈ CA (B)} ⊂ {vρ (ξ) : ξ ∈ CA (A)}.
This shows that inf ξ∈CA (A) vρ (ξ) ≤ inf ξ∈CA (B) vρ (ξ) (cf. Proposition 1.9). To complete the
argument, it remains to show that ρ∗ is countable subadditive on P(Ω). Let {An : n ∈ N} ⊂
P(Ω). We need to show that
ρ∗

[
∞


An

≤

n=1

∞
X

ρ∗ (An ).

n=1

P∞ ∗
Clearly, if there exists n ∈ N s.t. ρ∗ (An ) = ∞, ρ∗ (∪∞
n=1 An ) ≤
n=1 ρ (An ). Thus suppose
that for any n ∈ N, ρ∗ (An ) < ∞. Given n ∈ N, let ξεn = {Unk : k ∈ N} ∈ CA (An ) be a
137

covering of An by sets from A s.t.
vρ (ξεn ) < ρ∗ (An ) +

ε
.
2n

This is possible since inf ξ∈CA (An ) vρ (ξ) exists as an element of the real numbers (cf. Proposition 1.10). Since, {Unk : k ∈ N, n ∈ N} is a covering of ∪n∈N An by sets from A, it follows
that
[
 X
∞
∞
X
∗
ρ
An ≤
vρ (ξεn ) <
ρ∗ (An ) + ε.
n=1

n∈N

n=1

Since ε was arbitrary, the result follows (cf. Example 1.13).
Proposition B.2. Let µ∗ be an outer measure on P(Ω). Suppose that {Ai : i ∈ I} ⊂ M(µ∗ )
is disjoint, where I is either finite or countably infinite. Then, for any E ∈ P(Ω),
 [ 
 X
µ∗
Ai ∩ E =
µ∗ (Ai ∩ E).
i∈I

i∈I

Proof. Suppose first that I is finite, i.e., {Ai : i = 1, .P
. . , n} ⊂ M(µ∗ ), n ∈ N. We prove by
n
∗
n
induction that for any n ∈ N, µ ((∪i=1 Ai ) ∩ E) = i=1 µ∗ (Ai ∩ E). If n = 1, then the
result follows immediately. If n = 2, and A1 ∪ A2 = Ω, we have that A2 = Ac1 and since
A1 ∈ M(µ∗ ), it follows that
µ∗ (A1 ∩ E) + µ∗ (A2 ∩ E) = µ∗ (A1 ∩ E) + µ∗ (Ac1 ∩ E)
= µ∗ (Ω ∩ E) = µ∗ ((A1 ∪ A2 ) ∩ E).
Suppose that A1 ∪ A2 is a proper subset of Ω, i.e., Ω \ (A1 ∪ A2 ) ̸= ∅. Since A1 and A2 are
disjoint and Ac1 ⊂ A2 , we have that ((E∩(A1 ∪A2 ))∩A1 ) = E∪A1 and ((E∩(A1 ∪A2 ))∩Ac1 ) =
E ∪ A2 . Hence, since A1 ∈ M(µ∗ ), it follows that




(56)
µ∗ E ∩ (A1 ∪ A2 ) ∩ A1 + µ∗ E ∩ (A1 ∪ A2 ) ∩ Ac1 = µ∗ (E ∩ (A1 ∪ A2 )).
{z
} |
{z
}
|
=µ∗ (E∪A1 )

=µ∗ (E∪A2 )

Assume that µ∗ ((∪n−1
i=1 Ai ) ∩ E) =
µ∗

 [
n

Pn−1


Ai

µ∗ (Ai ∩ E). Using (56), we have that

i=1


∩E

= µ∗

i=1

 n−1
[


Ai ∪ An


∩E

i=1
∗

=µ

 n−1
[


Ai


∩E

+ µ∗ (An ∩ E).

i=1

Then, by the induction hypothesis, the result follows. Assume now that I is countably
infinite, i.e., ∪i∈I Ai = ∪i∈N Ai . Since µ∗ is an outer measure, it satisfies (ii) of Definition 6.2.
It follows that
 [ 

 [

 X
n
n
∗
∗
µ
Ai ∩ E ≥ µ
Ai ∩ E =
µ∗ (Ai ∩ E).
i=1

i∈N

i=1

If we let n →
− ∞, we obtain that
 [ 
 X
∗
µ
Ai ∩ E ≥
µ∗ (Ai ∩ E).
i∈N

i∈N

This completes the argument since the other inequality follows from the fact that µ∗ is
countable subadditive on P(Ω).
138

Proof of Proposition 6.6. We first notice that under the assumption that (I) is true, i.e.,
∗
M(µ∗ ) is a σ-field,
P item∗ (II) is to show that for any disjoint collection {Ai : i ∈ N} ⊂ M(µ ),
∗
µ (∪i∈N Ai ) =
i∈N µ (Ai ). This follows immediately from Proposition B.2 if we take
E = Ω. Hence, it remains to show that M(µ∗ ) is a σ-field. We need to verify that M(µ∗ )
satisfies the items of Definition 4.1. Let E ∈ P(Ω). We have that
µ∗ (Ω ∩ E) + µ∗ (Ωc ∩ E) = µ∗ (E).
Thus, Ω ∈ M(µ∗ ). Let A ∈ M(µ∗ ), then
µ∗ (Ac ∩ E) + µ∗ ((Ac )c ∩ E) = µ∗ (E),
since A ∈ M(µ∗ ). Thus, items (i) and (ii) of Definition 4.1 are clearly satisfied. We notice
that for any given A ∈ P(Ω),
E = Ω ∩ E = (A ∪ Ac ) ∩ E = (A ∩ E) ∪ (Ac ∩ E).
Hence, since µ∗ is an outer measure and therefore countable subadditive on P(Ω), it follows
that for any A ∈ P(Ω), µ∗ (E) ≤ µ∗ (A ∩ E) + µ∗ (Ac ∩ E). Thus, A is µ∗ measurable if A is
s.t. for any E ∈ P(Ω), µ∗ (E) ≥ µ∗ (A ∩ E) + µ∗ (Ac ∩ E). Hence, if µ∗ is an outer measure,
M(µ∗ ) = {A ∈ P(Ω) : µ∗ (A ∩ E) + µ∗ (Ac ∩ E) ≤ µ∗ (E) ∀ E ∈ P(Ω)}.
We show that if A, B ∈ M(µ∗ ), then A ∪ B ∈ M(µ∗ ). Since A ∈ M(µ∗ ),



µ∗ (A ∪ B) ∩ E = µ∗ A ∩ (A ∪ B) ∩ E + µ∗ Ac ∩ (A ∪ B) ∩ E


≤ µ∗ A ∩ E + µ∗ Ac ∩ B ∩ E .
It follows that


µ∗ (A ∪ B) ∩ E + µ∗ (A ∪ B)c ∩ E



≤ µ∗ A ∩ E + µ∗ Ac ∩ B ∩ E + µ∗ Ac ∩ B c ∩ E .
Since B ∈ M(µ∗ ), µ∗ (Ac ∩ E) = µ∗ (B c ∩ Ac ∩ E) + µ∗ (B ∩ Ac ∩ E). Hence,



µ∗ (A ∪ B) ∩ E + µ∗ (A ∪ B)c ∩ E ≤ µ∗ A ∩ E + µ∗ (Ac ∩ E) = µ∗ (E),
which shows that A ∪ B ∈ M(µ∗ ). By induction, if A1 , . . . , An ∈ M(µ∗ ), we have that
∪ni=1 Ai ∈ M(µ∗ ). To show (iii) of Definition 4.1, assume first that {Ai : i ∈ N} ⊂ M(µ∗ )
is disjoint. Write A = ∪i∈N Ai . We show that A ∈ M(µ∗ ). We know that for any n ∈ N,
∗
∗
∗
c
B.2, we
Fn = ∪ni=1 Ai ∈ M(µ∗ ), i.e.,
Pnµ (E) = µ (Fn ∩ E) + cµ (Fnc ∩ E). Using Proposition
∗
c
know that µ∗ (Fn ∩ E) = i=1 µ∗ (Ai ∩ E). Also,
A
⊂
F
(F
⊂
A).
Hence,
µ
(F
n
n
n ∩ E) ≥
Pn
∗
∗
c
µ∗ (Ac ∩ E). Therefore, we P
obtain, µ∗ (E) ≥
µ
(A
∩
E)
+
µ
(A
∩
E).
If we let
i
i=1
∞
n→
− ∞, we obtain µ∗ (E) ≥ i=1 µ∗ (Ai ∩ E) + µ∗ (Ac ∩ E). Thus, using Proposition B.2
again, we have that µ∗ (E) ≥ µ∗ (A ∩ E) + µ∗ (Ac ∩ E) and thus A ∈ M(µ∗ ). Let now
{Bi : i ∈ N} ⊂ M(µ∗ ), not necessarily disjoint. Write B = ∪i∈N Bi . We want to show that
B ∈ M(µ∗ ). Let A1 = B1 , A2 = B2 \ B1 = B2 ∩ B1c and so on until we define
Ai = B i \

 i−1
[


Bk

c
= Bi ∩ B1c ∩ . . . ∩ Bi−1
.

k=1

Then, see the proof of item (vii) in Proposition 5.1, {Ai : i ∈ N} is disjoint and s.t. for any
n ∈ N, ∪ni=1 Ai = ∪ni=1 Bi . In particular, ∪i∈N Ai = ∪i∈N Bi . Clearly, {Ai : i ∈ N} ⊂ M(µ∗ )
and hence, since {Ai : i ∈ N} is disjoint, ∪i∈N Ai ∈ M(µ∗ ) and therefore ∪i∈N Bi ∈ M(µ∗ )
as well. This completes the proof of item (I).
139

Proof of Proposition 6.7. Using Proposition 6.5, we know that the function
ρ∗ (A) =

inf
ξ∈CA (A)

vρ (ξ),

A ∈ P(Ω),

is an outer measure on P(Ω). We also know that M(ρ∗ ) is a σ-field and ρ∗ restricted to
M(ρ∗ ) is a measure (cf. Proposition 6.6). As a first step, we show that M(ρ∗ ) contains A,
i.e., A ⊂ M(ρ∗ ). Let A ∈ A. We need to show that for any E ∈ P(Ω),
(57)

ρ∗ (E) ≥ ρ∗ (A ∩ E) + ρ∗ (Ac ∩ E).

It is clear that if ρ∗ (E) = ∞, (57) is true. Thus consider the case where ρ∗ (E) < ∞. We
apply the same strategy as in the proof of Proposition
6.5 and choose for any ε > 0, a covering
P
ξε = {Un : n ∈ N} ∈ CA (E) s.t. vρ (ξ) = n∈N ρ(Un ) < ρ∗ (E) + ε. Since ξε ∈ CA (E), we
know that for any n ∈ N, Un ∈ A. In particular, since A is a semiring, Bn = A ∩ Un ∈ A
for any n ∈ N. Hence, since Bn ⊂ Un , we have that for any n ∈ N, the set Un \ Bn has the
n
form ∪m
k=1 Cnk where {Cnk : k = 1, . . . , mn } ⊂ A is disjoint. Now we notice the following,
n
1. Un = (Un \ Bn ) ∪ Bn = (∪m
k=1 Cnk ) ∪ Bn , where {Cn1 , . . . , Cnmn , Bn } is disjoint;

2. A ∩ E ⊂ A ∩ (∪n∈N Un ) = ∪n∈N (A ∩ Un ) = ∪n∈N Bn ;
3. Un \ Bn = Un ∩ Bnc = Un ∩ Ac ;
n
4. Ac ∩ E ⊂ Ac ∩ (∪n∈N Un ) = ∪n∈N (Ac ∩ Un ) = ∪n∈N (∪m
k=1 Cnk ).
Pmk
Therefore, by 1, since ρ is finitely additive on A, for any n ∈ N, k=1
ρ(Cnk ) + ρ(Bn ) =
mn
ρ((∪k=1 Cnk ) ∪ Bn ) = ρ(Un ). Then, using 2 and 4 and the fact that ρ∗ is an outer measure
it follows that
[

[m

[n
∗
∗
c
∗
∗
Bn + ρ
C nk
ρ (A ∩ E) + ρ (A ∩ E) ≤ ρ

n∈N

≤

X

n∈N

ρ∗ (Bn ) +

n∈N

≤

X
n∈N

=

mk
XX
n∈N

ρ(Bn ) +

n∈N
k=1
mk
X

n∈N

ρ∗ (Cnk )



k=1

mk
XX

X
ρ(Bn ) +

k=1


ρ(Cnk )


ρ(Cnk )

k=1

m
 X
X 
[n
Cnk
=
ρ Bn ∪
=
ρ(Un ) < ρ∗ (E) + ε.
n∈N

k=1

n∈N

Since ε > 0 was arbitrary, (57) is satisfied. Therefore, A ⊂ M(ρ∗ ). We show that ρ∗ (A) =
ρ(A) for any A ∈ A. Notice that we have already shown this for the special case where
ρ = ℓ (cf. Proposition 6.4 in Example 6.1). To see the general case, let A ∈ A and consider
any covering ξ = {Un : n ∈ N} ∈ CA (A). In particular, A ⊂ ∪n∈N Un , and therefore,
A = (∪n∈N Un ) ∩ A = ∪n∈N (UP
n ∩ A). Since ρ is countable subadditive on A, it follows that
ρ(A) = P
ρ(∪n∈N (Un ∩ A)) ≤ n∈N ρ(Un ∩ A). By Exercise 6.5, ρ is monotone and hence
ρ(A) ≤ n∈N ρ(Un ) = vρ (ξ). Therefore, it follows that ρ(A) ≤ inf ξ∈CA (A) vρ (ξ) = ρ∗ (A),
since ξ ∈ CA (A) was arbitrary. The other inequality follows immediately, since if A ∈ A,
{A} ∈ CA (A) and ρ(A) = vρ ({A}) ≥ ρ∗ (A). Hence, ρ∗ and ρ agree on A. By Proposition 6.6,
M(ρ∗ ) is a σ-filed. Further, M(ρ∗ ) contains A. By definition, σ(A) is the smallest σ-field
that contains A. Hence, σ(A) ⊂ M(ρ∗ ). Using Proposition 6.6 again, we know that ρ∗ |M(ρ∗ )
is a measure. Since σ(A) is a σ-field and σ(A) ⊂ M(ρ∗ ), it follows that ρ∗ |σ(A) is a measure
as well. Hence, we set ρ↑ = ρ∗ |σ(A) and obtain a measure on σ(A) which is s.t. for any
A ∈ A, ρ↑ (A) = ρ∗ |σ(A) (A) = ρ∗ (A) = ρ(A).
140

B.3

π-λ theorem

Definition B.1. Let Ω ̸= ∅. A collection P ⊂ P(Ω) is called a π-system if A, B ∈ P
implies that A ∩ B ∈ P.
Definition B.2. Let Ω ̸= ∅. A collection L ⊂ P(Ω) is called a λ-system if
(i) Ω ∈ L ;
(ii) A ∈ L implies that Ac ∈ L ;
(iii) if {Ai : i ∈ N} ⊂ L s.t. {Ai : i ∈ N} is disjoint, then ∪i∈N Ai ∈ L .
Proposition B.3. Let Ω ̸= ∅. If F is a π-system and a λ-system, then it is a σ-field on Ω.
Proof. Since F is a λ-system, it follows that Ω ∈ F and F is closed under the formation of
complements. Hence it remains to show item (iii) of Definition 4.1. Let {Ai : i ∈ N} ⊂ F.
Given i ∈ N, we write
B i = Ai \

 i−1
[


Aj

= Ai ∩ Ac1 ∩ . . . ∩ Aci−1 .

j=1

We already know that {Bi : i ∈ N} is disjoint (recall the proof of item (vii) of Proposition 5.1).
Since F is a π-system, Bi ∈ F for any i ∈ N and hence, by item (iii) of Definition B.2,
∪i∈N Bi ∈ F. Then, F is a σ-field, since for any n ∈ N, ∪ni=1 Bi = ∪ni=1 Ai and hence
∪i∈N Bi = ∪i∈N Ai .
The following is known as Dynkin’s π-λ theorem.
Proposition B.4. Let Ω ̸= ∅. If P is a π-system and L is a λ system then, if P ⊂ L ,
it follows that σ(P) ⊂ L .
Proof. Suppose that P ⊂ L . Define the set
C = {L : L is a λ-system s.t. P ⊂ L}.
Then, similar to the definition of the σ-field generated by a family of subsets of Ω, we set
\
L0 =
L.
L∈C

Again, L0 is not empty, since P(Ω) ∈ C . Further, L0 is a λ-system (cf. Exercise 4.5). Upon
the assumption that P ⊂ L , we obtain P ⊂ L0 ⊂ L . If L0 is a π-system, then L0 is a
σ-field on Ω (Proposition B.3). Hence, since σ(P) is the smallest σ-field that contains P, it
follows that σ(P) ⊂ L0 ⊂ L and we are done. Therefore, we prove that L0 is a π-system.
Given any A ∈ P(Ω) we define
LA = {B ∈ P(Ω) : A ∩ B ∈ L0 }.
Suppose that A ∈ P. Then LA is a λ-system. To see it, notice that Ω ∈ LA , since
A ∩ Ω = A ∈ L0 (recall that by definition of L0 , A ∈ P implies that A ∈ L for any L ∈ C ).
Suppose that B ∈ LA . Then, A∩B ∈ L0 . We also know that A∩Ω ∈ L0 . Hence, since L0 is
a λ-system, it contains (A∩Ω)∩(A∩B)c = (A∩Ω)\(A∩B) (notice that (A∩Ω)c ∩A∩B = ∅).
Then, since (A ∩ Ω) \ (A ∩ B) = A ∩ (Ω \ B), it follows that Ω \ B = B c ∈ LA . Suppose
that {Bi : i ∈ N} ⊂ LA disjoint, then {A ∩ Bi : i ∈ N} ⊂ L0 , where also {A ∩ Bi : i ∈ N} is
disjoint. Thus, since L0 is a λ-system, ∪i∈N (A∩Bi ) = A∩(∪i∈N Bi ) ∈ L0 , i.e., ∪i∈N Bi ∈ LA .
Therefore, we have shown that if A ∈ P, then LA is a λ-system. Further, if A ∈ P, then
P ⊂ LA , since in this case, for any B ∈ P, A ∩ B ∈ P (P is a π-system) and since
P ⊂ L0 , it follows that A ∩ B ∈ L0 , i.e., B ∈ LA . Then, since L0 is the smallest λ-system
141

that contains P, L0 ⊂ LA if A ∈ P. This means that if A ∈ P and B ∈ L0 , then B ∈ LA
and hence A ∈ LB . Notice that B ∈ LA if and only if A ∈ LB . Thus, B ∈ L0 implies that
P ⊂ LB . Then, since LB is a λ-system, it follows that B ∈ L0 implies that L0 ⊂ LB . In
conclusion, B ∈ L0 and C ∈ L0 imply that C ∈ LB and hence B ∩ C ∈ L0 . This shows
that L0 is a π-system.
Proof of Proposition 6.9. Assume that µ1 is σ-finite on A (otherwise µ2 is). With the terminology of Definition B.1, A is a π-system. Let B ∈ A s.t. µ1 (B) < ∞ (this is possible since
µ1 is σ-finite on A). Hence, since by assumption, µ1 and µ2 agree on A, µ1 (B) = µ2 (B).
Define
LB = {A ∈ σ(A) : µ1 (B ∩ A) = µ2 (B ∩ A)}.
Notice that A ⊂ LB since if A ∈ A, A ∩ B ∈ A (A is a π-system) and as µ1 and µ2 agree
on A, µ1 (B ∩ A) = µ2 (B ∩ A), i.e., A ∈ LB . We show that LB is a λ-system. Clearly,
Ω ∈ LB , since Ω ∈ σ(A) s.t. µ1 (B ∩ Ω) = µ1 (B) = µ2 (B) = µ2 (B ∩ Ω). If A ∈ LB , then
Ac ∈ σ(A). Then, since B ∩ Ac = B \ (B ∩ A) and µ1 (A ∩ B) = µ2 (A ∩ B) < ∞, we obtain
(cf. item (iii) of Proposition 5.1),
µ1 (B ∩ Ac ) = µ1 (B \ (B ∩ A)) = µ1 (B) − µ1 (B ∩ A) = µ2 (B) − µ2 (B ∩ A) = µ2 (B ∩ Ac ),
it follows that Ac ∈ LB . If {Ai : i ∈ N} ⊂ LB , disjoint, then ∪i∈N Ai ∈ σ(A) and {B∩Ai : i ∈
N} is disjoint as well. Then,
µ1 (B ∩ (∪i∈N Ai )) = µ1 (∪i∈N (B ∩ Ai ))
X
X
=
µ1 (B ∩ Ai ) =
µ2 (B ∩ Ai ) = µ2 (B ∩ (∪i∈N Ai )),
i∈N

i∈N

and hence ∪i∈N Ai ∈ LB . Thus, LB is a λ-system that contains the π-system A and with
Proposition B.4, we obtain that σ(A) ⊂ LB . Therefore, we have shown that σ(A) ⊂ LB
for any set B ∈ A for which µ1 (B) < ∞. We consider a collection {Bi : i ∈ N} ⊂ A
s.t. ∪i∈N Bi = Ω and for any i ∈ N, µ1 (Bi ) < ∞. In particular, given any n ∈ N and
I ⊂ {1, . . . , n}, since A is a π-system, ∩i∈I Bi ∈ A and µ1 (∩i∈I Bi ) < ∞. Therefore,
σ(A) ⊂ L∩i∈I Bi . This shows that for any A ∈ σ(A),
 \ 

 \ 

µ1
Bi ∩ A = µ2
Bi ∩ A .
i∈I

i∈I

Then, upon (Proposition B.1) we obtain that for any n ∈ N,


[
[
n
n
µ1
(Bi ∩ A) = µ2
(Bi ∩ A) .
i=1

i=1

Then, we apply item (v) of Proposition 5.1, and conclude that for any A ∈ σ(A),
[

[

µ1 (A) = µ1
(Bi ∩ A) = µ2
(Bi ∩ A)) = µ2 (A).
i∈N

B.4

i∈N

On measurable functions

Proof of Proposition 7.4. We first show that if for any i = 1, . . . , k, fi : Ω → R is F/B(R)
measurable, then, f is F/B(Rk ) measurable. By Exercise 4.8, we have that B(Rk ) = σ(R′k ),
where
R′k = {(−∞, x1 ] × · · · (−∞, xk ] : x = (x1 , . . . , xk ) ∈ Rk }.
142

Hence, by Proposition 7.1, it is sufficient to show that for any R ∈ R′k , f −1 (R) ∈ F.
Therefore, let R ∈ R′k , i.e.,
R = (−∞, x1 ] × · · · (−∞, xk ],

x = (x1 , . . . , xk ) ∈ Rk .

Then,
f −1 (R) = {ω ∈ Ω : f (ω) ∈ R} =

k
\

{ω ∈ Ω : fi (ω) ∈ (−∞, x1 ]} =

i=1

k
\

fi−1 ((−∞, x1 ]).

i=1

Then, since for any i = 1, . . . , k, (−∞, x1 ] ∈ B(R) and fi is F/B(R) measurable, it follows
that fi−1 ((−∞, x1 ]) ∈ F. Therefore, f −1 (R) ∈ F as well. For the other direction, assume
that f is F/B(Rk ) measurable. Given any i = 1, . . . , k, let
Ani = (−∞, n] × · · · × (−∞, x] × · · · × (−∞, n],
| {z }
position i

where x ∈ R is arbitrary. Then,
f −1 (Ani ) = f1−1 ((−∞, n]) ∩ · · · ∩ fi−1 ((−∞, x]) ∩ · · · ∩ fk−1 ((−∞, n]).
{z
}
|
position i

Then,
[
n∈N

Ani = R × · · · × (−∞, x] × · · · × R.
| {z }
position i

Therefore,
[

f −1 (Ani ) = f −1

n∈N

=

[

Ani

n∈N
−1
f1 (R) ∩ · · ·


∩ fi−1 ((−∞, x]) ∩ · · · ∩ fk−1 (R) = fi−1 ((−∞, x]).
|
{z
}
position i

Since f is F/B(Rk ) measurable, for any i = 1, . . . , k, ∪n∈N f −1 (Ani ) ∈ F. Thus, for any
i = 1, . . . , k and any x ∈ R, fi−1 ((−∞, x]) ∈ F. Then, B(R) = σ({(−∞, x] : x ∈ R}) and
hence, by Proposition 7.1, fi is F/B(R) measurable. This completes the proof.
Proof of Proposition 7.7. We show by induction (over n ≥ 2) that there exists m ∈ N, s.t.
f satisfies
f (ω) =

m
X

αi∗ 1A∗i (ω),

ω ∈ Ω,

i=1

where {A∗1 , . . . , A∗m } ⊂ F is disjoint. Let n = 2, i.e., f (ω) = α1 1A1 (ω) + α2 1A2 (ω), A1 , A2 ∈
F. We define the sets A∗1 = A1 \ A2 , A∗2 = A2 \ A1 and A∗3 = A1 ∩ A2 . Further, we set
α1∗ = α1 , α2∗ = α2 and α3∗ = α1 + α2 . Then, {A∗1 , A∗2 , A∗3 } ⊂ F is disjoint. Also, for any
ω ∈ Ω,
f (ω) = α1∗ 1A∗1 (ω) + α2∗ 1A∗2 (ω) + α3∗ 1A∗3 (ω).
Pn−1
With regard to the induction step, assume that f (ω) = i=1 αi 1Ai (ω)+αn 1An (ω), Ai ∈ F,
i = 1, . . . , n, and the induction hypothesis is that {A1 , . . . , An−1 } ⊂ F is disjoint. Then, we
set
A∗i = Ai \ An ,

i = 1, . . . , n − 1,
143

A∗n = An \ (∪n−1
i=1 Ai ),

and
A∗n+i = An ∩ Ai ,

i = 1, . . . , n − 1.

It follows that
{A∗1 , . . . , A∗n , A∗n+1 , . . . , A∗2n−1 } ⊂ F
∗
is disjoint. We set αi∗ = αi , i = 1, . . . , n, and αn+i
= αn + αi , i = 1, . . . , n − 1. It follows
that for any ω ∈ Ω,

f (ω) =

2n−1
X

αi∗ 1A∗i (ω).

i=1

This completes the induction step. Finally, we notice that
f (ω) =

2n−1
X

∗
αi∗ 1A∗i (ω) + α2n
1A∗2n (ω),

i=1
∗
∗
2n
∗
∗
with α2n
= 0 and A∗2n = Ω \ (∪2n−1
i=1 Ai ). Thus, ∪i=1 Ai = Ω and {Ai : i = 1, . . . , 2n} ⊂ F is
disjoint.

Proof of Proposition 7.8. We have that
{ω ∈ Ω : f (ω) < g(ω)} =

[

{ω ∈ Ω : f (ω) < q < g(ω)}.

q∈Q

To see it, take any ω in the left set of the above equation. Then, by Proposition 1.6, there
exists q ∈ Q s.t. f (ω) < q < g(ω). Notice that is is also true if g(ω) = ∞. Clearly, if there
exists q ∈ Q s.t. f (ω) < q < g(ω), then f (ω) < g(ω). Then, we have that for any q ∈ Q,
{ω ∈ Ω : f (ω) < q < g(ω)} = {ω ∈ Ω : f (ω) < q} ∩ {ω ∈ Ω : g(ω) > q}.
Since f and g are both F measurable, {ω ∈ Ω : f (ω) < q} and {ω ∈ Ω : g(ω) > q} are
members of F. This shows that {ω ∈ Ω : f (ω) < g(ω)} ∈ F since Q is countable. A similar
argument can be used to show that {ω ∈ Ω : f (ω) > g(ω)} ∈ F. Therefore,
c
F ∋ {ω ∈ Ω : f (ω) = g(ω)} = {ω ∈ Ω : f (ω) < g(ω)} ∪ {ω ∈ Ω : f (ω) > g(ω)} .

Proof of Proposition 7.9. Let x ∈ R. We have that
{ω ∈ Ω : sup fn (ω) ≤ x} = ∩n∈E {ω ∈ Ω : fn (ω) ≤ x}.
n∈E

Hence, for any x ∈ R, {ω ∈ Ω : supn∈E fn ≤ x} ∈ F since we have assumed that fn is F
measurable for any n ∈ E. We notice that
{ω ∈ Ω : sup fn (ω) < ∞} = {ω ∈ Ω : sup fn (ω) ≤ C},
n∈E

n∈E

for some C ∈ R. Therefore, {ω ∈ Ω : supn∈E fn (ω) < ∞} ∈ F. Hence,
{ω ∈ Ω : sup fn (ω) = ∞} = {ω ∈ Ω : sup fn (ω) < ∞}c ∈ F.
n∈E

n∈E

144

Also,
{ω ∈ Ω : sup fn (ω) = −∞} = {ω ∈ Ω : sup fn (ω) ≤ −∞}
n∈E

n∈E

= ∩n∈E {ω ∈ Ω : fn (ω) = −∞}.
Thus, since for any n ∈ E, fn is F measurable, we have that{ω ∈ Ω : fn (ω) = −∞} ∈ F.
Therefore {ω ∈ Ω : supn∈E fn (ω) = −∞} ∈ F. As in the solution of Exercise 7.4, we define
F = {ω ∈ Ω : sup fn (ω) ∈ R},
n∈E

and set
f ∗ (ω) = sup fn (ω)1F (ω),

ω ∈ Ω.

n∈E

We notice that F ∈ F. Also, since for any x ∈ R, {ω ∈ Ω : supn∈E fn (ω) ≤ x} ∈ F, we
obtain that
{ω ∈ Ω : f ∗ (ω) ≤ x} ∈ F.
Hence, f ∗ is F/B(R) measurable (cf. Proposition 7.3). Let A ∈ B(R). We obtain

{ω ∈ Ω : sup fn (ω) ∈ A} = {ω ∈ Ω : f ∗ (ω) ∈ A} ∩ F ∪ ({ω ∈ Ω : sup fn (ω) ∈ A} ∩ F c )
n∈E

n∈E
∗

= {ω ∈ Ω : f (ω) ∈ A} ∩ F ∈ F.
This shows that ω 7→ supn∈E fn (ω) is F measurable. A similar argument shows that ω 7→
inf n∈E fn (ω) is F measurable. With respect to (ii) of Proposition 7.9, we have that
ω 7→ (lim inf fn )(ω) = sup( inf fn )(ω),
n→
−∞
n∈N k≥n
and
ω 7→ (lim sup fn )(ω) = inf (sup fn )(ω),
n∈N k≥n
n→
−∞
are F measurable as a consequence of item (i) (cf. Exercise 7.2). Item (iii) is a consequence
of Proposition 3.23, we have that
{ω ∈ Ω : lim fn (ω) = −∞}
n→∞

= {ω ∈ Ω : (lim inf fn )(ω) = −∞} ∩ {ω ∈ Ω : (lim sup fn )(ω) = −∞}.
n→
−∞
n→
−∞
Therefore, since lim inf n→
− ∞ fn and lim supn→
− ∞ fn are F measurable, we conclude that
{ω ∈ Ω : lim fn (ω) = −∞} ∈ F.
n→∞

Similarly, we obtain
{ω ∈ Ω : lim fn (ω) = ∞}
n→∞

= {ω ∈ Ω : (lim inf fn )(ω) = ∞} ∩ {ω ∈ Ω : (lim sup fn )(ω) = ∞} ∈ F.
n→
−∞
n→
−∞
Let A ∈ B(R), we have that
{ω ∈ Ω : lim fn (ω) ∈ A}
n→∞

= {ω ∈ Ω : (lim inf fn )(ω) = (lim sup fn )(ω)} ∩ {ω ∈ Ω : (lim inf fn )(ω) ∈ A}.
n→
−∞
n→
−∞
n→
−∞
145

Then, {ω ∈ Ω : limn→∞ fn (ω) ∈ A} ∈ F (cf. Proposition 7.8). Using Propositions 3.21
and 7.8, we obtain
{ω ∈ Ω : (fn (ω))n∈N converges} = {ω ∈ Ω : (lim inf fn )(ω) = (lim sup fn )(ω)} ∈ F.
n→
−∞
n→
−∞
This shows item (iv). Finally, to see item (v), we use again Proposition 3.23 and conclude
that
n→∞

{ω ∈ Ω : fn (ω) −−−−→ f (ω)}
= {ω ∈ Ω : (lim inf fn )(ω) = f (ω)} ∩ {ω ∈ Ω : (lim sup fn )(ω) = f (ω)}.
n→
−∞
n→
−∞
Then, since by assumption f is F measurable, the sets {ω ∈ Ω : (lim inf n→
− ∞ fn )(ω) = f (ω)}
and {ω ∈ Ω : (lim supn→
f
)(ω)
=
f
(ω)}
are
both
elements
of
F
(cf.
Proposition
7.8). This
−∞ n
completes the proof of the proposition.
Proof of Proposition 7.10. The proof is to find such an approximating sequence of simple
functions. Given any n ∈ N, we partition [0, n) as follows:
n

 
 

 n
 n2
[ i − 1 i 
1
1 2
n2 − 1 n2n
0, n = 0, n ∪ n , n ∪ · · · ∪
, n =
,
.
2
2 2
2n
2
2n 2n
i=1

Then, we label,

In,i =


i−1 i
,
,
2n 2n

i = 1, . . . , n2n ,

and In = [n, ∞) ∪ {∞}. Accordingly, we define the sets
An,i = {ω ∈ Ω : f (ω) ∈ In,i },

i = 1, . . . , n2n ,

and An = {ω ∈ Ω : f (ω) ∈ In }. We let
n

fn (ω) =

n2
X
i−1
i=1

2n

1An,i (ω) + n1An (ω).

Clearly, for any ω ∈ Ω, fn (ω) ≤ fn+1 (ω) and for any n ∈ N, fn is F measurable. Suppose
first that f (ω) = ∞. Then, for any n ∈ N, fn (ω) = n, i.e., fn (ω) ↑ f (ω). Assume that
f (ω) ∈ [0, ∞). Then, there exists N ∈ N s.t. f (ω) < N . Hence, there exists precisely
one i ∈ {1, . . . , N 2N }, s.t. f (ω) ∈ IN,i , i.e., (i − 1)2−N ≤ f (ω) < i2−N . In particular,
f (ω) ≥ (i − 1)2−N = fN (ω). Therefore,
|f (ω) − fN (ω)| = f (ω) − fN (ω) <

i
i−1
1
− N = N.
2N
2
2

Then, for any n ≥ N , f (ω) < N ≤ n. Hence, we repeat the above argument and conclude
that for any n ≥ N , there is precisely one k ∈ {1, . . . , n2n } s.t. f (ω) ∈ In,k and |f (ω) −
fn (ω)| < 2−n . Therefore, limn→∞ fn (ω) = f (ω). The proof is complete upon application of
Proposition 7.7, i.e., for any n ∈ N there exists a standard simple function gn s.t. for any
ω ∈ Ω, fn (ω) = gn (ω).
Proof of Proposition 7.13. Let g : Rk → R be B(Rk ) measurable and s.t. h(ω) = g(f (ω)).
Then, h is σ(f ) measurable (Exercise 7.9). For the other direction, we prove the claim in
two steps, first we show it for the case where h is a standard simple function and then we
approximate a general h with simple functions. Thus, suppose that h is a simple function
in standard form (cf. Definition 7.4 with F = σ(f )). Then, there exists g : Rk → R which is
B(Rk ) measurable and s.t. h(ω) = g(f (ω)) (Exercise 7.10). Let h : Ω → R be a general σ(f )
146

measurable function. By Proposition 7.11, we find a sequence of σ(f ) measurable standard
n→∞
simple functions (hn )n∈N s.t. hn −−−−→ h. By the previous case, for each n ∈ N, there exists
k
a B(R ) measurable function gn s.t. for any ω ∈ Ω, hn (ω) = gn (f (ω)). Consider the set
A = {x ∈ Rk : (gn (x))n∈N converges}. Since for any n ∈ N, gn is B(Rk ) measurable, it
follows that A ∈ B(Rk ) (cf. item (iv) of Proposition 7.9). Define
(
limn→∞ gn (x), if x ∈ A,
g(x) =
0,
otherwise.
We have that g(x) = limn→∞ gn (x)1A (x) and hence, g is B(Rk ) measurable by item (iii) of
Proposition 7.9. Let ω ∈ Ω, then f (ω) is s.t.
lim gn (f (ω)) = lim hn (ω) = h(ω).

n→∞

n→∞

Thus, f (ω) ∈ A for any ω ∈ Ω. Hence, for any ω ∈ Ω,
h(ω) = lim hn (ω) = lim gn (f (ω)) = lim gn (f (ω))1A (f (ω)) = g(f (ω)).
n→∞

B.5

n→∞

n→∞

The integral

Proof of Proposition 8.1. Notice first that we have seen in Example 7.7 that f is F measurable. Let η = {Bj : j = 1, . . . , M } ∈ Z0F . Since η ∈ Z0F , we can represent the atoms of ξ
using the atoms of η and vice versa, i.e.,
Ai = Ai ∩ Ω =

M
[

(Ai ∩ Bj ),

i = 1, . . . , N,

j=1

and
Bj =

N
[

(Ai ∩ Bj ),

j = 1, . . . , M.

i=1

Further, since ξ is disjoint, it follows that for any j = 1, . . . , M , {Ai ∩ Bj : i = 1, . . . , N } is
disjoint. Therefore,
µ(Bj ) =

N
X

µ(Ai ∩ Bj ).

i=1

Further, given any (j, i) ∈ {1, . . . , M } × {1, . . . , N }, either Ai ∩ Bj ̸= ∅, then




inf f (ω) µ(Ai ∩ Bj ) ≤
inf f (ω) µ(Ai ∩ Bj ) = αi µ(Ai ∩ Bj ),
ω∈Bj ∩Ai

ω∈Bj

or Ai ∩ Bj = ∅, then, (inf ω∈Bj f (ω))µ(Ai ∩ Bj ) = 0 = αi µ(Ai ∩ Bj ). Hence,
Sµf (η)

=

M 
X
j=1

≤

inf f (ω)

ω∈Bj

M X
N
X
j=1

i=1

N
 X



µ(Ai ∩ Bj ) =

i=1

M X
N 
X
j=1

i=1



inf f (ω) µ(Ai ∩ Bj )

ω∈Bj

N
M
N
 X
X
 X
αi µ(Ai ∩ Bj ) =
αi
µ(Ai ∩ Bj ) =
αi µ(Ai ).
i=1

147

j=1

i=1

This shows that
Z

f (ω)µ(dω) = sup Sµf (η) ≤
η∈Z0F

Ω

N
X

αi µ(Ai ).

i=1

The reverse inequality follows from the fact that ξ is s.t. ξ ∈ Z0F and Sµf (ξ) =

PN

i=1

αi µ(Ai ).

We prove the monotone convergence theorem for nonnegative functions.
Proof of Proposition 8.2. First of all, using the result of the latter exercise, we have that for
any n ∈ N,
Z
Z
fn (ω)µ(dω) ≤
fn+1 (ω)µ(dω)
Ω

Ω

and
Z

 Z
fn (ω)µ(dω) ≤
f (ω)µ(dω).

sup
n∈N

Ω

Ω

Hence, using Proposition 3.8,
Z
lim

n→∞

 Z
fn (ω)µ(dω) ≤
f (ω)µ(dω).

Ω

Ω

Thus, it remains to show that
Z
lim

n→∞

 Z
fn (ω)µ(dω) ≥
f (ω)µ(dω).

Ω

Ω

That is, we need to show that for any ξ = {Ai : i = 1, . . . , N } ∈ Z0F ,
Z

lim
fn (ω)µ(dω) ≥ Sµf (ξ).
n→∞

(58)

Ω

Hence, let ξ = {Ai : i = 1, . . . , N } ∈ Z0F . We use the notation
Sµf (ξ) =

N
X

ai µ(Ai ),

ai = inf f (ω), i = 1, . . . , N.
ω∈Ai

i=1

First we consider the case where ξ is s.t. Sµf (ξ) < ∞ and for any i = 1, . . . , N , 0 < ai < ∞
and 0 < µ(Ai ) < ∞. Let ε > 0, s.t. ε < min{ai : i = 1, . . . , N } and
ε < PN

δ

i=1

µ(Ai )

,

(59)

where δ > 0 is arbitrary but nonnegative. Define the sets
Ai,n = {ω ∈ Ai : fn (ω) > ai − ε},

i = 1, . . . , N, n ∈ N.

Since (fn (ω))n∈N is increasing, we observe that for any i = 1, . . . , N , Ai,n ⊂ Ai,n+1 . Further,
for any i = 1, . . . , N ,
[
Ai,n = Ai .
n∈N

148

Clearly, if ω ′ ∈ ∪n∈N Ai,n , ω ′ ∈ Ai . For the other direction, suppose that ω ′ ∈ Ai , then,
since fn (ω ′ ) ↑ f (ω ′ ), there exists K ∈ N s.t. for any n ≥ K,
f (ω ′ ) − fn (ω ′ ) = |f (ω ′ ) − fn (ω ′ )| < ε.
Therefore,
fn (ω ′ ) > f (ω ′ ) − ε ≥ inf f (ω) − ε.
ω∈Ai

Given any n ∈ N, consider the partition


ξn = Ai,n : i = 1, . . . , N ∪ Ω \ (∪N
i=1 Ai,n ) .
We notice that since fn is F measurable, ξn ∈ Z0F . Hence,
Z

fn (ω)µ(dω) ≥ Sµfn (ξn ) =

Ω

X 
A∈ξn

≥

N
X

N 


X
inf fn (ω) µ(A) ≥
inf fn (ω) µ(Ai,n )

ω∈A

i=1

ω∈Ai,n


ai − ε µ(Ai,n ).

i=1

Then, using item (v) of Proposition 5.1, we obtain that
N
X

N
N
X
X


ai − ε µ(Ai,n ) ↑
ai − ε µ(Ai ) = Sµf (ξ) − ε
µ(Ai ).

i=1

i=1

i=1

Therefore,

N
X
f
fn (ω)µ(dω) ≥ Sµ (ξ) − ε
µ(Ai ).

Z
lim

n→∞

Ω

i=1

Hence, by (59),
Z
lim

n→∞


fn (ω)µ(dω) ≥ Sµf (ξ) − δ.

Ω

Since δ > 0 was arbitrary, (58) is shown. Consider now the case, where ξ is s.t. Sµf (ξ) < ∞.
This implies that for any i = 1, . . . , N , ai µ(Ai ) < ∞. Clearly, if for any i = 1, . . . , N ,
ai µ(Ai ) = 0, then (58) is true. Thus, suppose that there exists i1 , . . . , iN0 ∈ {1, . . . , N },
N0 ≤ N , s.t. aij µ(Aij ) > 0 for any j = 1, . . . , N0 , and ai µ(Ai ) = 0 for any i ∈ {1, . . . , N } \
{i1 , . . . , iN0 }. Hence, since µ is a measure, aij > 0 and µ(Aij ) > 0 for any j = 1, . . . , N0 .
Therefore, we obtain
Sµf (ξ) =

N0
X

aij µ(Aij ),

j=1

and proceed towards (58) as in the previous case. Finally, we consider the case where ξ is
s.t. Sµf (ξ) = ∞. We need to show that
Z

lim
fn (ω)µ(dω) = ∞.
(60)
n→∞

Ω

Since
= ∞, there exists j ∈ {1, . . . , N } s.t. aj µ(Aj ) = ∞. Hence, aj > 0 and
µ(Aj ) > 0 and either aj = ∞ or µ(Aj ) = ∞. Let p, q > 0 s.t. 0 < p < aj ≤ ∞ and
0 < q < µ(Aj ) ≤ ∞. Set
Sµf (ξ)

Aj,n = {ω ∈ Aj : fn (ω) > p}.
149

We have that Aj,n ⊂ Aj,n+1 and Aj = ∪n∈N Aj,n . We notice that Aj ⊂ ∪n∈N Aj,n follows
from the fact that if ω ∈ Aj , then since fn (ω) ↑ f (ω), it follows that there exists K ∈ N s.t. for
any n ≥ K, f (ω) − fn (ω) < aj − p, i.e., fn (ω) > f (ω) − aj + p ≥ p. Therefore, using item (v)
of Proposition 5.1 there exists K0 ∈ N s.t. for any n ≥ K0 , µ(Aj ) − µ(Aj,n ) < µ(Aj ) − q.
That is, µ(Aj,n ) > q for any n ≥ K0 . Then, consider the partition ξn composed of the sets
Aj,n and Acj,n . We have that for any n ≥ K0 ,
Z
fn (ω)µ(dω) ≥ Sµfn (ξn ) ≥ pµ(Aj,n ) > pq.
Ω

Therefore,
Z
lim

n→∞


fn (ω)µ(dω) ≥ pq.

Ω

Since either aj = ∞ or µ(Aj ) = ∞, either p or q can be made arbitrary large and (60)
follows.
We show the linearity propoerty of the integral for nonnegative functions.
PN
Proof of Proposition 8.3. Suppose that f = i=1 αi 1Ai , αi ∈ [0, ∞), {Ai : i = 1, . . . , N } ⊂
PM
F, i = 1, . . . , N , and g = j=1 βj 1Bj , βj ∈ [0, ∞), {Bj : j = 1, . . . , M } ⊂ F, j = 1, . . . , M ,
i.e., f and g are nonnegative, F measurable simple functions (cf. Definition 7.3). According
to Proposition 7.7, we assume that f and g are already in standard form, i.e., ∪N
i=1 Ai =
∪M
j=1 Bj = Ω. We write
αf =

N
X

ααi 1Ai =

N
X

ααi

X
M

i=1

i=1



1Ai ∩Bj ,

j=1

and
βg =

M
X

ββi 1Bj =

M
X

ββj

X
N

j=1

j=1



1Bj ∩Ai .

i=1

Hence,
αf + βg =

=

N
X

ααi

X
M

i=1

j=1

N
X

X
M

ααi

i=1

=

=



1Ai ∩Bj +

M
X

ββj

X
N

ααi 1Ai ∩Bj



j=1

+

1Bj ∩Ai



1Ai ∩Bj



ββj 1Ai ∩Bj



j=1

i=1

N
X

X
M

ββj

i=1

j=1

N X
M
X
i=1



1Ai ∩Bj +

j=1

N X
M
X
i=1

j=1

N X
M
X


(ααi + ββj )1Ai ∩Bj .

i=1

j=1

Assume that N ≥ M and set Bj = ∅ for j = M + 1, . . . , N (if M ≥ N , we set Ai = ∅ for
i = N + 1, . . . , M ). Then, we write
αf + βg =

N
X
i,j=1

150

γi,j 1Ci,j ,

where γi,j = ααi + ββj and Ci,j = Ai ∩ Bj , i, j = 1, . . . , N . Therefore, αf + βg is a standard
simple function. Using Proposition 8.1, we obtain
Z
(αf + βg)(ω)µ(dω) =
Ω

N
X

γi,j µ(Ci,j )

i,j=1

=α

N
X

αi µ(Ai ) + β

i=1

M
X

Z
=α

βj µ(Bj )

j=1

Z
f (ω)µ(dω) + β

Ω

g(ω)µ(dω).
Ω

At this point we remark that α or β equal to ∞, would not change the latter result. For
the general case, assume that f and g are nonnegative and F measurable. Using Proposition 7.10, there exists sequences of nonnegative standard simple functions (fn ) and (gn ) s.t.
fn (ω) ↑ f (ω) and gn (ω) ↑ g(ω), ω ∈ Ω. That is, (αfn + βgn )(ω) ↑ αf + βg. Then, we rely
on Proposition 8.2 and conclude that

Z
Z
(αfn + βgn )(ω)µ(dω)
(αf + βg)(ω)µ(dω) = lim
n→∞
Ω
ΩZ

Z

= α lim
fn (ω)µ(dω) + β lim
gn (ω)µ(dω)
n→∞
n→∞
Ω
Ω
Z
Z
=α
f (ω)µ(dω) + β
g(ω)µ(dω).
Ω

Ω

Proof of Proposition 8.5. Let Ai = {ω : f (ω) ≥ 1/i}, i ∈ N. Then, clearly ∪i∈N Ai =
{ω : f (ω) > 0}. Using item (v) of Proposition 5.1, µ(An ) ↑ µ({ω : f (ω) > 0}). Thus,
since µ({ω : f (ω) > 0}) > 0, let ε > 0 s.t. ε < µ({ω : f (ω) > 0}). We write δ =
µ({ω : f (ω) > 0}) − ε. Then, there exists N ∈ N s.t. µ({ω : f (ω) > 0}) − µ(AN ) ≤ ε,
i.e., Rµ(AN ) ≥ µ({ω : f (ω) > 0}) − ε = δ > 0. Now consider ξ = {AN , AcN }. Then, ξ ∈ Z0F
and Ω f (ω)µ(dω) ≥ Sµf (ξ) ≥ N1 µ(AN ) ≥
R δ/N > 0. This completes the proof of (i). Regarding (ii), suppose by contradiction that Ω f (ω)µ(dω) < ∞ but µ({ω : f (ω) = ∞}) > 0, i.e.,
the negation of f < ∞ µ a.e. Then, we consider ξ = {A, Ac }, where A = {ω : f (ω) = ∞}.
We have that Sµf (ξ) ≥ ∞ · µ({ω : f (ω) = ∞}) = ∞, which gives a contradiction. In order
to verify (iii), let G = {ω : f (ω) ≤ g(ω)}. Let ξ = {A1 , . . . , AN } ∈ Z0F . Then, we consider
ξ ∗ = {A1 ∩ G, . . . , AN ∩ G} ∪ {Gc } and have that ξ ∗ ∈ Z0F . In particular,
Z
Sµf (ξ) ≤ Sµf (ξ ∗ ) ≤ Sµg (ξ ∗ ) ≤
g(ω)µ(dω),
Ω

where the second inequality follows since by assumption on G, for any A ∈ ξ, µ(A) =
c
Rµ(A ∩ G) + µ(AR ∩ G ) = µ(A ∩ G). This shows (iii) and in particular (iv) (then also
g(ω)µ(dω) ≤ Ω f (ω)µ(dω)).
Ω
Proof of Proposition 8.7. We notice that
{ω : f + (ω) ≤ g + (ω)} ∩ {ω : f − (ω) ≥ g − (ω)} = {ω : f (ω) ≤ g(ω)}.
This follows from the definition of f + and f −1 , since if ω is s.t. f (ω) ≤ g(ω), then,
max{f (ω), 0} ≤ max{g(ω), 0} and max{−f (ω), 0} ≥ max{−g(ω), 0}. We obtain
{ω : f + (ω) ≤ g + (ω)}c ∪ {ω : f − (ω) ≥ g − (ω)}c = {ω : f (ω) ≤ g(ω)}c

151

Hence, if f ≤ g Ra.e., then, f + ≤ Rg + a.e. and f − ≥ Rg − a.e. Therefore,R using (iii) in
Proposition 8.5, Ω f + (ω)µ(dω) ≤ Ω g + (ω)µ(dω) and Ω f − (ω)µ(dω) ≥ Ω g − (ω)µ(dω),
which makes
Z
Z
Z
f (ω)µ(dω) =
f + (ω)µ(dω) −
f − (ω)µ(dω)
Ω
Ω
Ω
Z
Z
Z
+
−
≤
g (ω)µ(dω) −
g (ω)µ(dω) =
g(ω)µ(dω).
Ω

Ω

Ω

We show that the integral for integrable functions is linear.
Proof of Proposition 8.8. Notice first that for any ω ∈ Ω,
|(αf + βg)(ω)| ≤ |α||f (ω)| + |β||g(ω)|,
R
R
by the triangular inequality. Thus, since |α| Ω |f (ω)|µ(dω) and |β| Ω |g(ω)|µ(dω) are finite
upon the integrability of f and g (cf. Proposition 8.6),
αf + βg is integrable
as well (cf.
R
R
Exercise 8.1 and Proposition 8.3). Notice first that Ω αf (ω)µ(dω) = α Ω f (ω)µ(dω). We
can see it by considering the cases: α > 0, α < 0 and α = 0. If α = 0, then, for any ω ∈ Ω,
(αf )+ (ω) = (αf )− (ω) = 0 = αf − (ω) = αf + (ω). If α > 0, then,
(
(
αf (ω), if αf (ω) ≥ 0,
f (ω), if f (ω) ≥ 0,
+
(αf ) (ω) =
=α
= αf + (ω),
0,
if αf (ω) < 0,
0,
if f (ω) < 0,
and
(

(
−αf (ω), if −αf (ω) ≥ 0,
−f (ω), if −f (ω) ≥ 0,
=α
= αf − (ω),
0,
if −αf (ω) < 0,
0,
if −f (ω) < 0,

−

(αf ) (ω) =

Similarly, if α < 0, then (αf )+ (ω) = −αf − (ω) and (αf )− (ω) = −αf + (ω). Hence, in each
case, we use Proposition 8.3 and obtain
Z
Z
Z
αf (ω)µ(dω) = (αf )+ (ω)µ(dω) − (αf )− (ω)µ(dω)
Ω
Ω
Z
ZΩ
Z
+
−
=α
f (ω)µ(dω) − α
f (ω)µ(dω) = α
f (ω)µ(dω).
Ω

Ω

Ω

Of course the same argument applies for Ω βg(ω)µ(dω). Hence, if we show that
Z
Z
Z
(αf + βg)(ω)µ(dω) =
αf (ω)µ(dω) +
βg(ω)µ(dω),
R

Ω

Ω

(61)

Ω

we are done. Write f∗ = αf and g∗ = βg. We know that (f∗ + g∗ )+ − (f∗ + g∗ )− = f∗ + g∗
(cf. Exercise 7.5). Hence, (f∗ + g∗ )+ − (f∗ + g∗ )− = f∗+ − f∗− + g∗+ − g∗− . This shows that
(f∗ + g∗ )+ + f∗− + g∗− = (f∗ + g∗ )− + f∗+ + g∗+ . Hence,
Z
Z


(f∗ + g∗ )+ + f∗− + g∗− (ω)µ(dω) =
(f∗ + g∗ )− + f∗+ + g∗+ (ω)µ(dω),
Ω

Ω

which gives (cf. Proposition 8.3)
Z
Z
+
(f∗ + g∗ ) (ω)µ(dω) − (f∗ + g∗ )− (ω)µ(dω)
Ω
Ω
Z
Z
Z
Z
+
−
=
f∗ (ω)µ(dω) −
f∗ (ω)µ(dω) +
g∗+ (ω)µ(dω) −
g∗− (ω)µ(dω)
Ω
Ω
ZΩ
Z Ω
=
f (ω)µ(dω) +
g(ω)µ(dω).
Ω

Ω

This shows (61) and the proof of the proposition is complete.
152

We prove Fatou’s lemma and Lebesgue’s dominated convergence theorem.
Proof of Proposition 8.9. Define gn = inf k≥n fk , thenR(gn )n∈N is a sequence
of F measurR
able and nonnegative functions s.t. for any n ∈ N, Ω gn (ω)µ(dω) ≤ Ω fn (ω)µ(dω) (cf.
Exercise 8.1), Therefore,
Z
Z
lim inf
gn (ω)µ(dω) ≤ lim inf
f (ω)µ(dω).
n→
−∞ Ω
n→
−∞ Ω n
Further, for any Rω ∈ Ω, gn (ω) ↑ lim
− ∞ fn (ω) (cf. Proposition A.5). Therefore, using
R inf n→
Proposition 8.2, Ω gn (ω)µ(dω) ↑ Ω lim inf n→
− ∞ fn (ω)µ(dω). In conclusion, using Proposition 3.23, we obtain
Z
Z
Z
lim inf fn (ω)µ(dω) = lim inf
g (ω)µ(dω) ≤ lim inf
f (ω)µ(dω).
−∞
n→
−∞ Ω n
n→
−∞ Ω n
Ω n→
R
Proof of Proposition 8.10. Notice that f is integrable, i.e., Ω |f (ω)|µ(dω) < ∞. To see it,
we notice that (compare also to Proposition 3.26),
\

{ω : |fn (ω)| ≤ g(ω)} ⊂ {ω : f (ω) ≤ g(ω)}.
A = {ω : lim fn (ω) = f (ω)} ∩
n→∞
|
{z
}
{z
}
|
n∈N
=A
2,n

=A1

Then, upon Proposition 5.1, since µ(Ac1 ) = 0 and µ(Ac2,n ) = 0 for any n ∈ N,
X

µ(Ac ) ≤
µ(Ac1 ) + µ(Ac2,n ) = 0.
n∈N

Thus, f ≤ g a.e. and hence f is integrable by Exercise 8.4. Similarly f ∗ = lim supn→
− ∞ fn
and f∗ = lim inf n→
f
are
integrable.
Then,
we
notice
that
(g
+
f
)
and
(g
−
fn )n∈N
−∞ n
n n∈N
are nonnegative and F measurable sequences of functions. Given any ω ∈ A, we rely on
Proposition A.4 and obtain
(g + f∗ )(ω) = g(ω) + lim inf fn (ω) = lim inf (g + fn )(ω),
n→
−∞
n→
−∞
and
(g − f ∗ )(ω) = lim inf (g − fn )(ω).
n→
−∞
∗
Hence, g + f∗ = lim inf n→
− ∞ (g + fn ) a.e. and g − f = lim inf n→
− ∞ (g − fn ) a.e. Therefore,
we use Proposition 8.9 and obtain
Z
Z
Z
g(ω)µ(dω) +
f∗ (ω)µ(dω) = (g + f∗ )(ω)µ(dω)
Ω
Ω
ZΩ
=
lim inf (g + fn )(ω)µ(dω)
−∞
Ω n→
Z
≤ lim inf (g + fn )(ω)µ(dω)
n→
−∞ Ω
Z
Z
=
g(ω)µ(dω) + lim inf
f (ω)µ(dω),
n→
−∞ Ω n
Ω

where the last equality again follows from Proposition A.4. Similarly, we obtain
Z
Z
Z
∗
g(ω)µ(dω) −
f (ω)µ(dω) =
lim inf (g − fn )(ω)µ(dω)
−∞
Ω
Ω
Ω n→
Z
≤ lim inf (g − fn )(ω)µ(dω)
n→
−∞ Ω
Z
Z
=
g(ω)µ(dω) − lim sup
fn (ω)µ(dω).
n→
−∞ Ω
Ω
153

This makes (cf. Proposition 3.20)
Z
Z
lim inf fn (ω)µ(dω) ≤ lim inf
f (ω)µ(dω)
−∞
n→
−∞ Ω n
Ω n→
Z
Z
≤ lim sup
fn (ω)µ(dω) ≤
lim sup fn (ω)µ(dω).
n→
−∞ Ω
−∞
Ω n→
Since fn →
− f a.e. it follows that lim inf n→
− ∞ fn = lim supn→
− ∞ fn = f a.e. and hence upon
the previous display,
Z
Z
Z
lim inf
f (ω)µ(dω) = lim sup
fn (ω)µ(dω) =
f (ω)µ(dω),
n→
−∞ Ω n
n→
−∞ Ω
Ω
and therefore (cf. Proposition 3.23),
Z
Z
lim
fn (ω)µ(dω) =
f (ω)µ(dω).
n→∞

Ω

Ω

In order to verify that integration can be interchanged with differentiation, Lebesgue’s
dominated convergence theorem is a key tool.
Proposition B.5. Let (Ω, F, µ) be a measure space and f : (a, b) × Ω → R be a function
where (a, b) ⊂ R is an open interval. Let u0 ∈ (a, b). Suppose that
(i) for any u ∈ (a, b) ω 7→ f (u, ω) is F measurable and integrable with respect to µ;
(ii) There exists a set F ∈ F s.t. µ(F c ) = 0 and for any ω ∈ F , the map u 7→ f (u, ω) is
differentiable in u0 with derivative (∂f /∂u)(u0 , ω) (that is, u 7→ f (u, ω) is differentiable
in u0 µ a.e.);
R
(iii) there exists a F measurable and nonnegative function g : Ω → R s.t. Ω g(ω)µ(dω) < ∞
and for any u ∈ (a, b) (u ̸= u0 ) we have that µ a.e.,
|f (u, ω) − f (u0 , ω)| ≤ g(ω)|u − u0 |.
Then, the function F (u) =

R

f (u, ω)µ(dω) is differentiable in u0 with derivative
Z
F ′ (u0 ) = (∂f /∂u)(u0 , ω)µ(dω),

Ω

Ω

i.e., we are allowed to interchange integration with differentiation.
n→∞

Proof. Let (un )n∈N be a sequence in (a, b) \ {u0 } s.t. un −−−−→ u0 and define
φn (u0 , ω) =

f (un , ω) − f (u0 , ω)
,
un − u0

ω ∈ Ω.

Let fn,u0 and fu0 be the map ω 7→ φn (u0 , ω) and ω 7→ (∂f /∂u)(u0 , ω)1F (ω), respectively.
n→∞
By item (ii), we have that µ a.e., fn,u0 −−−−→ fu0 . Further, by item (iii), for any n ∈ N,
|fn,u0 | ≤ g(ω),
and
that

R
Ω

µ a.e.,

|g(ω)|µ(dω) < ∞. Hence, we are in position to apply Proposition 8.10, and deduce
F (un ) − F (u0 )
= lim
lim
n→∞
n→∞
un − u0

Z

Z
fn,u0 (ω)µ(dω) =

Ω

(∂f /∂u)(u0 , ω)µ(dω).
Ω

154

We remark that stronger conditions as given in Proposition B.5 can be of interest for
practical applications.
Proposition B.6. Let (Ω, F, µ) and f : (a, b) × Ω → R be as in Proposition B.5. Suppose
that
(i) for any u ∈ (a, b) ω 7→ f (u, ω) is F measurable and integrable with respect to µ;
(ii) for any ω ∈ Ω, the map fω (u) = f (u, ω), u ∈ (a, b) is differentiable (cf. Definition A.9)
with derivative fω′ that satisfies
|fω′ (u0 )| ≤ g(ω),

u0 ∈ (a, b),

R
where g : Ω → R is nonnegative and F measurable and s.t. Ω g(ω)µ(dω) < ∞.
R
Then, the function F (u) = Ω f (u, ω)µ(dω), u ∈ (a, b), is differentiable with derivative
Z
′
F (u0 ) = (∂f /∂u)(u0 , ω)µ(dω), u0 ∈ (a, b).
Ω

Proof. Clearly, item (ii) of Proposition B.5 is s satisfied. We show that also (iii) holds. It
is a consequence of the mean value theorem (cf. Proposition A.21). Let u0 ∈ (a, b). Then,
for any u ∈ (a, b) (u ̸= u0 ), either u > u0 or u < u0 . If u > u0 , we apply the mean value
theorem and obtain m1 ∈ (u0 , u) s.t. for any ω ∈ Ω,
fω (u) − fω (u0 ) = fω′ (m1 )(u − u0 ).
If u < u0 , we obtain m2 ∈ (u, u0 ) s.t.
fω (u0 ) − fω (u) = fω′ (m2 )(u0 − u).
In particular, for any ω ∈ Ω,
|fω (u) − fω (u0 )| ≤ max{fω′ (m1 ), fω′ (m2 )}|u − u0 | ≤ g(ω)|u − u0 |,
and hence (iii) of Proposition B.5 is satisfied. This completes the proof.

B.6

On the Riemann and the Lebesgue integral

Proof of Proposition 9.4. Since f is Riemann integrable, let ε > 0 and choose δ > 0 s.t. for
any partition a = a1 < a2 < · · · < aN +1 = b of [a, b] with λ([ai , ai+1 ]) < δ and xi ∈ [ai , ai+1 ],
i = 1, . . . , N , we obtain
If (a, b) −

N
X

f (xi )λ([ai , ai+1 ]) < ε.

(62)

i=1

In particular,
If (a, b) − ε <

N
X

f (xi )λ([ai , ai+1 ]) < If (a, b) + ε,

i=1

where x1 , . . . , xN is any collection of points s.t. xi ∈ [ai , bi ]. Let

Ai = f (x)λ([ai , ai+1 ]) : x ∈ [ai , bi ] , i = 1, . . . , N.
By (62),
If (a, b) − ε < sup(A1 + · · · + AN ) < If (a, b) + ε.
155

(63)

Then, we rely on Proposition A.3 and conclude that for any i = 1, . . . , N , sup Ai < ∞ and
sup(A1 + · · · + AN ) = sup A1 + · · · + sup AN .
In particular, upon Proposition A.2, for any i = 1, . . . , N , supx∈[ai ,bi ] f (x) < ∞. Therefore,
since a = a1 < a2 < · · · < aN +1 = b is a partition of [a, b], supx∈[a,b] f (x) < M for some
M ∈ R. Hence, we have shown that (62) implies that
N
X

If (a, b) −

Mi λ([ai , ai+1 ]) < ε,

(64)

i=1

where Mi = supx∈[ai ,bi ] f (x), i = 1, . . . , N . Upon the same reasoning, we find m ∈ R, s.t.
inf x∈[a,b] f (x) > m and deduce that (62) also implies that
If (a, b) −

N
X

mi λ([ai , ai+1 ]) < ε,

(65)

i=1

where mi = inf x∈[ai ,bi ] f (x), i = 1, . . . , N . In particular, for any x ∈ [a, b], |f (x)| <
max{−m, M }. Thus, since λ([a, b]) < ∞, it follows from (b) of Exercise 8.4, that f : [a, b] →
R is Lebesgue integrable. We define the simple functions
g(x) =

N
X

Mi 1[ai ,bi ] (x),

x ∈ [a, b],

mi 1[ai ,bi ] (x),

x ∈ [a, b].

i=1

and
h(x) =

N
X
i=1

Rb
Rb
PN
PN
We have that, a g(x)dx = i=1 Mi λ([ai , ai+1 ]) and a h(x)dx = i=1 mi λ([ai , ai+1 ]) (cf.
Exercise 8.5). Further for any x ∈ [a, b], h(x) ≤ f (x) ≤ g(x). Hence, by (64) and (65),
Z
If (a, b) − ε ≤

b

Z
h(x)dx ≤

a

b

Z

b

f (x)dx ≤
a

g(x)dx ≤ If (a, b) + ε.
a

Proof of Proposition 9.5. Let (bn )n∈N be any sequence which is s.t. bn ↑ u and a < bn < u
for any n ∈ N. We define the function x 7→ fn (x) = 1[a,bn ) (x)f (x), n ∈ N. It follows that for
any x ∈ [a, u), fn (x) ↑ f (x). Since f is nonnegative, we apply Proposition 8.2 and conclude
that
Z bn
Z u
lim
f (x) =
f (x)dx.
n→∞

a

a

Then, upon Proposition 9.4, for any a < b < u, If (a, b) =

Rb

f (x)dx. Hence, the assumption
Rb
limb↑u If (a, b) = If (a, u) becomes equivalent to the assumption that limb↑u a f (x)dx =
Ru
If (a, u). Hence, by Proposition A.16 we obtain that a f (x)dx = If (a, u).

B.7

a

Fubini-Tonnelli-Lebesgue

Proposition B.7. Let (Xi , Xi ), i = 1, . . . , n, be n measurable spaces and fi : Xi → R be
Xi measurable for any i = 1, . . . , n.

156

(i) The map f : X1 × · · · × Xn → R given by
f (x1 , . . . , xn ) =

n
Y

f (xi ),

i=1

is X1 ⊗ · · · ⊗ Xn measurable;
(ii) if for any i = 1, . . . , n, gi = (gi1 , . . . , gik ) : Xi → Rk is Xi measurable, then, the map
s(x1 , . . . , xn ) =

n
X

gi (xi ) =

i=1

X
n

gi1 (xi ), · · · ,

n
X

i=1


gik (xi ) ,

i=1

is X1 ⊗ · · · ⊗ Xn measurable.
Proof. Let i = 1, . . . , n, and define the map f˜i : X1 × · · · × Xn → R by
f˜i (x1 , . . . , xn ) = fi (xi ),

(x1 , . . . , xn ) ∈ X1 × · · · × Xn .

Then, if either B ∈ B(R), B = {∞} or B = {−∞}, we have that
f˜i−1 (B) = X1 × · · · × fi−1 (B) × · · · × Xn ∈ X1 ⊗ · · · ⊗ Xn ,
| {z }
position i

since by assumption fi : Xi → R is Xi measurable. This shows that for any i = 1, . . . , n,
the map f˜i : X1 × · · · × Xn → R is X1 ⊗ · · · ⊗ Xn measurable. By Proposition 7.12 the map
f is X1 ⊗ · · · ⊗ Xn measurable as well. This shows item (i). The proof for item (ii) follows
the same reasoning (recall also Proposition 7.4).
Proposition B.8. Let (X, X ) and (Y, Y ) be two measurable spaces. If E ∈ X ⊗ Y , then
for any x ∈ X, {y ∈ Y : (x, y) ∈ E} ∈ Y and for any y ∈ Y , {x ∈ X : (x, y) ∈ E} ∈ X .
Proof. Let x ∈ X, and define the map y 7→ gx (y) = (x, y). Suppose that E = A × B,
A ∈ X , B ∈ Y . Then,
(
B, if x ∈ A,
gx−1 (E) =
∅, otherwise.
Hence, in this case gx−1 (E) ∈ Y . Since X ⊗Y is generated by the sets A×B, A ∈ X , B ∈ Y ,
g is Y /(X ⊗ Y ) measurable according to Proposition 7.1. Therefore, {y ∈ Y : (x, y) ∈
E} = gx−1 (E) ∈ Y for any E ∈ X ⊗ Y . We adapt the same reasoning to show that
{x ∈ X : (x, y) ∈ E} ∈ X for any E ∈ X ⊗ Y .
Proposition B.9. Let (X, X ) and (Y, Y ) be two measurable spaces. Let f : X × Y → R
and define for any x ∈ X, y 7→ fx (y) = f (x, y) and for any y ∈ Y , x 7→ fy (x) = f (x, y).
Then, if f is X ⊗Y measurable, fx is Y measurable for any x ∈ X and fy is X measurable
for any y ∈ Y .
Proof. Define y 7→ gx (y) = (x, y) as in the proof of the latter proposition. By assumption,
f : X × Y → R is X ⊗ Y measurable and by the latter proof, gx is Y /(X ⊗ Y ) measurable.
This shows that for any x ∈ X, fx (y) = f (gx (y)) = f (x, y) is Y measurable (cf. Exercise 7.2).
Similarly, we show that for any y ∈ Y , fy is X measurable.
Proposition B.10. Let (X, X ) and (Y, Y ) be two measurable spaces. Then, the collection
P = {A × B : A ∈ X , B ∈ Y },
is a π-system.
157

Proof. Let E, F ∈ P, i.e., E = A × B, and F = C × D, A, C ∈ X , B, D ∈ Y . We readily
see that E ∩ F = A ∩ C × B ∩ D. Therefore, E ∩ F ∈ P.
Proof of Proposition 9.10. Suppose first that µ and ν are finite measures on X and Y ,
respectively. That is, µ(X) < ∞ and ν(Y ) < ∞. Define the collection
L = {E ∈ X ⊗ Y : X ∋ x 7→ ν({y ∈ Y : (x, y) ∈ E}) is X measurable}.
We show that L is a λ-system on X × Y . In order to simplify the notation, we write
fE (x) = ν({y ∈ Y : (x, y) ∈ E}), E ∈ X ⊗Y . Notice that for any E ∈ X ⊗Y , fE : X → R,
since ν is assumed to be finite. If E = X × Y , then we observe that for any x ∈ X,
fX×Y (x) = ν(Y ). Thus, x 7→ fX×Y (x) is X measurable since it is constant. Hence,
X × Y ∈ L . Suppose that E ∈ L . Then, fE is X measurable. We observe that for any
A ∈ B(R), since ν is finite,
c
fE−1
c (A) = {x ∈ X : ν({y ∈ Y : (x, y) ∈ E }) ∈ A}

= {x ∈ X : ν({y ∈ Y : (x, y) ∈ E}c ) ∈ A}
= {x ∈ X : ν(Y ) − ν({y ∈ Y : (x, y) ∈ E}) ∈ A}
= {x ∈ X : ν(Y ) − fE (x) ∈ A} ∈ X ,
since ν(Y )−fE is X measurable. This shows that fE c is X measurable and hence E c ∈ L .
Let {Ei : i ∈ N} ⊂ L disjoint. We have that for any A ∈ B(R),
f∪−1
(A) = {x ∈ X : ν({y ∈ Y : (x, y) ∈ ∪i∈N Ei }) ∈ A}
i∈N Ei
= {x ∈ X : ν(∪i∈N {y ∈ Y : (x, y) ∈ Ei }) ∈ A}
X
= {x ∈ X :
ν({y ∈ Y : (x, y) ∈ Ei }) ∈ A}
i∈N

= {x ∈ X :

X

fEi (x) ∈ A} ∈ X ,

i∈N

since

P

i∈N

fEi = limn→∞

Pn

i=1

fEi is X measurable (cf. Proposition 7.9). Let

P = {A × B : A ∈ X , B ∈ Y }.
We know that P is a π-system (cf. Proposition B.10). Further, given E = A × B ∈ P,
fA×B (x) = ν({y ∈ Y : (x, y) ∈ A × B}) = 1A (x)ν(B),
and hence fA×B is X measurable. Thus, P ⊂ L . Therefore, L is a λ-system on X × Y
which contains the π-system P. Using Proposition B.4, σ(P) = X ⊗ Y ⊂ L . Clearly, by
definition of L , L ⊂ X ⊗ Y and hence, L = X ⊗ Y . Therefore, given any E ∈ X ⊗ Y ,
fE is X measurable and we define
Z
π1 (E) =
fE (x)µ(dx).
(66)
X

We readily check that π1 is a measure on X ⊗ Y . Further, π1 (X × Y ) = µ(X)ν(Y ) < ∞,
i.e., π1 is finite. We repeat the previous arguments with the function gE (y) = µ({x ∈
X : (x, y) ∈ E}), and obtain a finite measure π2 :
Z
π2 (E) =
gE (y)ν(dy).
(67)
Y

Then, for any E = A × B ∈ P, π1 (A × B) = π2 (A × B) = µ(A)ν(B). If we now set
L∗ = {E ∈ X ⊗ Y : π1 (E) = π2 (E)},
158

then, we verify, as in the proof of Proposition 6.9, that L∗ is a λ-system. In conclusion,
since P ⊂ L∗ , we obtain with Proposition B.4, X ⊗ Y ⊂ L∗ . Thus, π1 and π2 agree on
X ⊗ Y and we define µ ⊗ ν = π1 on X ⊗ Y . Finally, we notice that by Proposition 6.9,
µ ⊗ ν is the only measure on X ⊗ Y which is s.t. µ ⊗ ν(A × B) = µ(A)ν(B) for any
A × B ∈ P. Clearly, µ ⊗ ν is finite since X × Y ∈ P and µ and ν are assumed to be
finite. For the remaining case, assume that µ and ν are not necessarily finite but σ-finite
on X ⊗ Y . Since ν is σ-finite on Y , there exists {Bn : n ∈ N} ⊂ Y s.t. ν(Bn ) < ∞
for any n ∈ N and Y = ∪n∈N Bn . As in the proof of item (vii) of Proposition 5.1, we
define Cn = Bn \ (∪n−1
k=1 Bk ), n ∈ N, and obtain a disjoint collection {Cn : n ∈ N} ⊂ Y s.t.
ν(Cn ) < ∞ for any n ∈ N and Y = ∪n∈N Cn . Define νn (B) = ν(B ∩ Cn ), B ∈ Y . Then,
for any n ∈ N, νn is a finite measure on Y . Thus, we rely on the finite case and deduce
that for any E ∈ X ⊗ Y , x 7→ fEn (x) = νn ({y ∈ Y : (x, y) ∈ E}) is X measurable for any
n ∈ N. We adapt the same strategy for the measure µ and find {Am : m ∈ N} ⊂ X disjoint
s.t. ∪m∈N Am = X and µ(Am ) < ∞ for any m ∈ N. Then, via µm (A) = µ(A ∩ Am ), A ∈ X ,
m
m
we obtain with y 7→ gE
(y) = µm ({x ∈ X : (x, y) ∈ E}), E ∈ X ⊗ Y , that (gE
)m∈N is a
sequencePof Y measurable functions for any E ∈ X ⊗ Y . We notice that since for any
B ∈ Y , n∈N νn (B) = ν(B), it follows that for any x ∈ X and E ∈ X ⊗ Y ,
lim

n
X

n→∞

X

fEn (x) =

i=1

fEn (x) = ν({y ∈ Y : (x, y) ∈ E}),

n∈N

which is X measurable by Proposition 7.9. Hence, as in the previous case,
Z
π̃1 (E) =
ν({y ∈ Y : (x, y) ∈ E})µ(dx), E ∈ X ⊗ Y ,
X

is a well defined measure on X ⊗ Y . Notice that in this case, π̃1 is σ-finite on X ⊗ Y
since ∪m,n∈N (Am × Cn ) = X × Y and π̃1 (Am × Cn ) = µ(Am )ν(Cn ) < ∞ for any m, n ∈ N.
Similarly, we deduce that
Z
π̃2 (E) =
µ({x ∈ X : (x, y) ∈ E})ν(dy), E ∈ X ⊗ Y ,
Y

is a σ-finite measure on X ⊗ Y . We show that π̃1 (E) = π̃2 (E) for any E ∈ X ⊗ Y . Define
Z
π1nm (E) =
fEn (x)µm (dx), E ∈ X ⊗ Y ,
X

and
π2mn (E)

Z

m
gE
(y)νn (dy),

=

E ∈X ⊗Y ,

Y

We observe that
π1nm (A × B) =

Z

1Am (x)1A (x)νn (B)µ(dx) = µm (A)νn (B) = π2nm (A × B),

(68)

X

for any A × B be s.t. A ∈ X and B ∈ Y (cf. Exercise 8.8). Hence, as in the finite case,
since P is a π-system, we deduce that for any E ∈ X ⊗ Y , π1mn (E) = π2mn (E), m, n ∈ N.
We also observe that for any E ∈ X ⊗ Y ,
 X Z X


X X
π1nm (E) =
fEn (x) µm (dx)
m∈N

n∈N

m∈N

=

m∈N

=

X

X Z

n∈N


ν({y ∈ Y : (x, y) ∈ E})µm (dx)

X

X Z
m∈N


ν({y ∈ Y : (x, y) ∈ E})µ(dx)

Am

Z
ν({y ∈ Y : (x, y) ∈ E})µ(dx) = π̃1 (E),

=
X

159

P
P
P
P
and similarly, n∈N ( m∈N π2nm (E)) = m∈N ( n∈N π2nm (E)) = π̃2 (E) (cf. Example 8.7).
Therefore, by (68), π̃1 (E) = π̃2 (E) for any E ∈ X ⊗ Y . Hence, again, we define µ ⊗ ν(E) =
π̃1 (E), E ∈ X ⊗ Y , and observe that for any A × B s.t. A ∈ X and B ∈ Y ,
 X X

X X
µ ⊗ ν(A × B) =
π1nm (A × B) =
µm (A)νn (B) = µ(A)ν(B). (69)
m∈N

n∈N

m∈N

n∈N

It remains to show that µ ⊗ ν is the unique measure on X ⊗ Y that satisfies (69). This
follows, as in the finite case, from the fact that P generates X ⊗ Y , i.e, we rely on
Proposition 6.9.
Proof of Proposition 9.11. Suppose that f = 1E , where E ∈ X ⊗ Y . Then, for any x ∈
X, we obtain that 1E (x, y) = 1{y∈Y : (x,y)∈E} (y). Similarly, for any y ∈ Y , 1E (x, y) =
1{x∈X : (x,y)∈E} (x) Hence,
Z
f (x, y)ν(dy) = ν({y ∈ Y : (x, y) ∈ E}).
Y

and
Z
f (x, y)µ(dx) = µ({x ∈ X : (x, y) ∈ E}).
X

R
As already
shown in the proof of Proposition 9.10, the functions x 7→ Y f (x, y)ν(dy) and
R
y 7→ X f (x, y)µ(dx) are X and Y measurable, respectively, and
Z
f (x, y)(µ ⊗ ν)(d(x, y)) = µ ⊗ ν(E)
X×Y
Z
=
ν({y ∈ Y : (x, y) ∈ E})µ(dx)
ZX
=
µ({x ∈ X : (x, y) ∈ E})ν(dy).
Y

PN
Thus, the proposition is already verified for f = 1E , E ∈ X ⊗ Y . If f =
i=1 αi 1Ei
is a nonnegative simple function, where Ei ∈ X ⊗ Y for any i = 1, . . . , N , we apply
Proposition 8.3 and the result is deduced from the previous case. Finally, if f is any X ⊗
Y measurable and nonnegative function, we apply Proposition 8.2 and the proposition is
proven.
R
R
Proof of Proposition 9.12. We focus on Y f (x, y)ν(dy), the arguments for X f (x, y)µ(dx)
are the same. Since f is X ⊗ Y measurable, |f | is a nonnegative and X ⊗ Y measurable
function. By Proposition 9.11,

Z
Z Z
f (x, y) µ ⊗ ν(d(x, y)) =
f (x, y) ν(dy) µ(dx).
(70)
X×Y

X

Y

Thus, by (ii) of Proposition 8.5, Y f (x, y) ν(dy) < ∞ µ a.e. Thus, we define


Z
FX = x ∈ X :
f (x, y) ν(dy) < ∞ ,
R

Y

Then, given any x ∈ FX ,
Z
Z
Z
+
f (x, y)ν(dy) =
f (x, y)ν(dy) −
f − (x, y)ν(dy).
Y

Y

(71)

Y

Then, we again apply Proposition 8.5 and
R deduce that the right hand side of (71) is X
measurable. Therefore, for any x ∈ FX , Y f (x, y)ν(dy) is X measurable. Further, for any
160

R
R
R
R
x ∈ FX , since Y f + (x, y)ν(dy) ≤ Y |f (x, y)|ν(dy) and Y f − (x, y)ν(dy) ≤ Y |f (x, y)|ν(dy),
+
−
it
R follows from (70), that f and f are µ integrable on FX . Hence, for
R any x ∈ FX ,
f
(x,
y)ν(dy)
is
integrable
with
respect
to
µ.
We
define
g(x)
=
1
(x)
f (x, y)ν(dy),
F
X
Y
Y
R
x ∈ X, and have that g(x) = Y f (x, y)ν(dy) µ a.e. By Exercise 8.3,
Z Z
f (x, y)ν(dy) µ(dx) < ∞,
X

and

Z Z
X

Y


Z
f (x, y)ν(dy) µ(dx) =

Y

Z

FX


f (x, y)ν(dy) µ(dx).

(72)

Y

On FX , we apply Proposition 9.11 to f + and f − and obtain

Z
Z Z
+
+
f (x, y)µ ⊗ ν(d(x, y)) =
f (x, y)ν(dy) µ(dx),
FX ×Y

FX

Y

and
Z

Z

Z

−


f (x, y)ν(dy) µ(dx),
−

f (x, y)µ ⊗ ν(d(x, y)) =
FX ×Y

Hence,

FX

Z

Y

Z

Z


f (x, y)ν(dy) µ(dx).

f (x, y)µ ⊗ ν(d(x, y)) =
FX ×Y

FX

(73)

Y

R R
By (72), the right-hand side of the latter display is equal to X ( Y f (x, y)ν(dy))µ(dx). Then,
c
we readily see that (FX × Y )c = (FX × Y c ) ∪ (FX
× Y ) and hence

c
µ ⊗ ν (FX × Y )c = µ(FX )ν(Y c ) + µ(FX
)ν(Y ) = 0.
R
Thus the right-hand side of (73) is equal to X×Y f (x, y)µ ⊗ ν(d(x, y)) and the proof is
complete.

B.8

Summation: Integration with respect to the counting measure

We use Propositions 9.11 and 9.12 to prove Proposition 3.11.
Proof of Proposition 3.11. Let I × J ⊂ N × N and f : I × J → R, f (i, j) = aij . Consider the
measure spaces (I, P(I), µI ) and (J, P(J), µJ ), where µI is the counting measure on P(I)
and µJ is the counting measure and P(J). Clearly, µI is σ-finite on I: It is finite if I is
finite and if I is not finite, then since I is countable, we write
I = {ik : k ∈ N} = ∪n∈N {i1 , . . . , in },
and observe that µI ({i1 , . . . , in }) < ∞ for any n ∈ N. Thus, µI and µJ are σ-finite measures
on (I, P(I), µI ) and (J, P(J), µJ ), respectively. Further, we observe that for any B ∈ B(R),
f −1 (B) ∈ P(I × J) = P(I) ⊗ P(J) (cf. Example 9.6). That is, f is P(I) ⊗ P(J) measurable.
Suppose that f (i, j) ≥ 0 for any (i, j) ∈ I × J. By Proposition 9.11, we know that
Z
f (i, j)µI ⊗ µJ (d(i, j))
I×J


Z Z
Z Z
=
f (i, j)µJ (dj) µI (di) =
f (i, j)µI (di) µJ (dj).
(74)
I

J

J

I

Given any i ∈ I, let N ∋ j 7→ f˜(i, j) = f (i, j)1J (j). Notice that for any i ∈ I, j 7→ f˜(i, j) is
P(J) measurable by Proposition B.9. We obtain,
Z
Z
Z
f (i, j)µJ (dj) =
f (i, j)µ(dj) =
f˜(i, j)µ(dj),
J

J

N

161

where µ is the counting measure on P(N). Then, by Example 8.6, we know that
Z
X
X
X
f (i, j)1J (j) =
f (i, j).
f˜(i, j)µ(dj) =
f˜(i, j) =
N

j∈N

j∈J

j∈N

Hence, by (74), we get
XX
i∈I


aij

=

j∈J

XX
j∈J


aij .

i∈I

It remains to show that
Z

X

f (i, j)µI ⊗ µJ (d(i, j)) =
I×J

aij

(i,j)∈I×J

First, µ ⊗ µ = µ2 , where µ2 is the counting measure on P(N × N) (cf. Example 9.7). Let
A ∈ P(I) and B ∈ P(J), then,
µI ⊗ µJ (A × B) = µI (A)µJ (B) = µ(A)µ(B).
Also,
(µ ⊗ µ)|I×J (A × B) = µ2 |I×J (A × B) = µ(A)µ(B).
Hence, µ2 |I×J = µI ⊗ µJ . We write f (i, j) = f (i, j)1I×J (i, j), (i, j) ∈ N × N. Then,
Z
Z
f (i, j)µI ⊗ µJ (d(i, j)) =
f (i, j)µ2 (d(i, j)).
I×J

N×N

We then repeat the arguments given in Example 8.6 with
f n (i, j) = f (i, j)1{1,...,n}×{1,...,n} ,
and the decomposition


2



[

N =

{i, j} ∪ N2 \ {1, . . . , n}2 ,

(i,j)∈{1,...,n}2

and obtain
Z
f n (i, j)µ2 (d(i, j)) =
N×N

X

X

f n (i, j) =

(i,j)∈{1,...,n}2

f (i, j),

(i,j)∈{1,...,n}2

where
Z
lim

n→∞


f n (i, j)µ2 (d(i, j))

=

N×N

(i,j)∈{1,...,n}2

f (i, j)µ2 (d(i, j)).
N×N

This conludes the argument since


X
lim
f (i, j) =
n→∞

Z

X
(i,j)∈N2

f (i, j) =

X

f (i, j).

(i,j)∈I×J

P
Assume now that (i,j)∈I×J |f (i, j)| < ∞. Then, by the previous arguments, we know that
R
this implies that I×J |f (i, j)|µI ⊗ µJ (d(i, j)) < ∞. Then, we rely on Proposition 9.12 and
Proposition 3.11 is proven.
162

Upon the latter proof, we deduce the following result:
Proposition B.11. Let E1 , . . . , En be countable sets. Suppose that f : E1 × · · · × En → R
is a nonnegative function. Let E = E1 × · · · × En . Then,
 X


X
X  
X
f (x1 , . . . , xn ) =
···
f (x1 , . . . , xn )
··· ,
(75)
x1 ∈E1

x∈E

xn−1 ∈En−1

xn ∈En

where the sum in theP
latter display can be computed in arbitrary order. If f is not necessarily
nonnegative but s.t. x∈E |f (x1 , . . . , xn )| < ∞, (75) remains valid.
Proof. If f : E → R is nonnegative, this is a consequence of Proposition 9.11. We notice
that since E1 , . . . , En are assumed to be countable, there exists a bijection g : I1 × · · · × In →
E1 × · · · × En s.t. for any (x1 , . . . , xn ) ∈ E1 × · · · × En ,
f (x1 , . . . , xn ) = f (g(i1 , . . . , in )),
Thus, if we write h = f ◦ g, we obtain
X
f (x1 , . . . , xn ) =
x∈E

(i1 , . . . , in ) ∈ I1 × · · · × In .

X

h(i1 , . . . , in ).

(76)

(i1 ,...,in )∈I1 ×···×In

Then, we rely on the same reasoning as in the proof of Proposition 3.11 and verify that the
right hand side of (76) equals
Z
h(i1 , . . . , in )1I1 ×···×In (i1 , . . . , in )µ ⊗ · · · ⊗ µ(d(i1 , . . . , in )),
N×···×N

where µ is the counting measure on P(N).
P Therefore, (75) follows from Proposition 9.11. In
particular, under the assumption that x∈E |f (x1 , . . . , xn )| < ∞, (75) follows from Proposition 9.12.

C
C.1

Probability
On the distribution function

Proof of Proposition 10.5. Upon Proposition A.15, FX is continuous at a point t ∈ R, if and
only limy↑t FX (y) = F (t) = limy↓t FX (y). We have that
lim FX (y) = lim PX ((−∞, y]).
y↑t

y↑t

Take any sequence of real numbers (yn )n∈N s.t. yn ↑ t (yn ̸= t for any n ∈ N). By Proposition 5.1, we have that
[

lim FX (yn ) = lim PX ((−∞, yn ]) = PX
(−∞, yn ] .
n→∞

n→∞

n∈N

Then, we observe that
[

(−∞, yn ] = (−∞, t).

n∈N

To see it, let y ∈ (−∞, t), i.e., there exists ε > 0, s.t. y ≤ t − ε. Then, since yn ↑ t, there
exists N ∈ N s.t. t − yn ≤ ε for any n ≥ N . Thus, yN ≥ t − ε ≥ y, i.e., y ∈ ∪n∈N (−∞, yn ].
The other inclusion is obvious. Hence,
lim FX (yn ) = PX ((−∞, t)).

n→∞

163

This shows that limy↑t FX (y) = PX ((−∞, t)) (cf. Proposition A.16). Similarly, we deduce
that
lim FX (y) = PX ((−∞, t]) = FX (t).
y↓t

Notice that in this case, the argument relies on the fact that for any sequence (yn )n∈N s.t.
yn ↓ t, ∩n∈N (−∞, yn ] = (−∞, t]. Here, the inclusion (−∞, t] ⊂ ∩n∈N (−∞, yn ] is obvious.
For the other inclusion, suppose that y ∈ ∩n∈N (−∞, yn ]. Then, for any n ∈ N, y ≤ yn .
Since yn ↓ t, it follows that y ≤ limn→∞ yn = t (cf. Exercise 4.13). In conclusion,
lim FX (y) − lim FX (y) = PX ((−∞, t]) − PX ((−∞, t)) = P(X = t).
y↓t

y↑t

Hence, FX is continuous at t if and only if P(X = t) = 0.
Remark C.1. We remark that Proposition 10.5 shows that if X is continuous, the distribution function FX is continuous on R. Further, in the proof of Proposition 10.5 we deduced
that
lim FX (y) − lim FX (y) = P(X = t),
y↓t

y↑t

i.e., the points of discontinuity of FX are given by the t ∈ R for which P(X = t) ̸= 0.
In addition, we have seen that for any t ∈ R, the right-hand limit limy↓t FX (y) is equal to
FX (t), that is to say that FX is right-continuous. By definition, FX is increasing. Further,
limy→−∞ FX (y) = 0 and limy→∞ FX (y) = 1 (cf. Proposition A.18). In summary, FX is
right-continuous with jumps at the points t ∈ R for which P(X = t) ̸= 0.
Remark C.2. Notice that the set E in Proposition 10.6 is not empty. To see it, let p ∈ (0, 1).
Choose ε > 0 s.t. ε < p < 1−ε. Since limy→−∞ FX (y) = 0 there exists a real number M1 > 0
s.t. if y < −M1 , FX (y) < ε (cf. Proposition A.17). Further, since limy→∞ FX (y) = 1,
there exists a real number M2 > 0 s.t. if y > M2 , |FX (y) − 1| < ε ⇔ FX (y) > 1 − ε.
Let ya < −M1 and yb > M2 . We define a = FX (ya ) and b = FX (yb ) and obtain that
p ∈ (a, b). By the intermediate value theorem (cf. Proposition A.7), there exists t ∈ [ya , yb ]
s.t. FX |[ya ,yb ] (t) = FX (t) = p. In particular, there exists t ∈ R s.t. 0 < FX (t) < 1.
Proof of Proposition 10.6. We aim to apply Proposition 2.2. Therefore, it remains to show
that FX |E (E) = (0, 1). By definition of E, FX |E (E) ⊂ (0, 1). For the other inclusion, we
have seen in Remark C.2 that for any p ∈ (0, 1) there exists t ∈ R s.t. FX (t) = p. But this
implies that t ∈ E and hence, FX |E (t) = p.

C.2

Second moments

Proof of Proposition 10.8. Notice first that if E[X 2 ] = E[Y 2 ] = 0, then P(X = 0) = P(Y =
0) = 1, i.e., (31) is an equality (cf. Proposition 8.5). Hence, we suppose that E[X 2 ] > 0
(otherwise choose E[Y 2 ] > 0). Let a ∈ R. We have that
0 ≤ E[(a|X| + |Y |)2 ] = E[a2 X 2 + 2a|X||Y | + Y 2 ] = a2 E[X 2 ] + 2aE[|XY |] + E[Y 2 ].

(77)

Define the quadratic function
q(a) = a2 E[X 2 ] + 2aE[|XY |] + E[Y 2 ],

a ∈ R.

(78)

By (77), q(a) ≥ 0 for any a ∈ R. This implies that the discriminant dq = 4(E[|XY |])2 −
4E[X 2 ]E[Y 2 ] defined by q has to be smaller or equal to zero. To see it, by the assumption
that E[X 2 ] > 0, the second derivative of q with respect to a is strictly positive and hence,
q admits a unique and global minimum at zero. Therefore, dq > 0 is not possible as it
would imply that the equation q(a) = 0 has two different real solutions. Hence, the result
is proven.
164

Proof of Proposition 10.9. We have that
 X
2    X
2
k
k
t
Var(v X) = E
vi Xi
− E
vi Xi
i=1

i=1

X
  X

k X
k
k X
k
=E
vi vj Xi Xj
−
vi vj E[Xi ]E[Xj ]
i=1

=

=

k
X

vi

j=1

X
k

i=1

j=1

k
X

X
k

vi

i=1

C.3

i=1

j=1


vj (E[Xi Xj ] − E[Xi ]E[Xj ])

vj Σ(X)i,j

= v t Σ(X)v.

j=1

Uniqueness theorem of the characteristic function

Proof of Proposition 10.11. Let σ = 0. Since X = µ P a.s., it follows that for any v ∈ R,
ΦX (v) = E[eivX ] = E[eivµ ] = eiµv .
Therefore, it remains to show the proposition for the case where σ > 0. Assume that µ = 0
and σ = 1. Let v ∈ R. We have that
Z
x2
1
√ e− 2 eivx dx.
ΦX (v) =
2π
R
Then, upon Euler’s Formula, i.e., eivx = cos(vx) + i sin(vx), we have that
Z
x2
1
√ e− 2 cos(vx)dx,
ΦX (v) =
2π
R
R −x2 /2
since the integral R e
sin(vx)dx is equal to zero (cf. Example 9.4). Let (a, b) ⊂ R be
an open interval. For any x ∈ R, we set
fx (v) = e−

x2
2

cos(vx),

v ∈ (a, b).

Then, for any x ∈ R, fx is differentiable with derivative
fx′ (v) = −x e−

x2
2

sin(vx),

v ∈ (a, b).
2

We notice that for any v0 ∈R(a, b), |fx′ (v0 )| ≤ g(x), with g(x) = |x| e−x /2 , x ∈ R. By
Example 10.18 we know that R g(x)dx < ∞. Hence, Proposition B.6 applies and we obtain
that for any v ∈ (a, b),
Z
x2
1
√ x e− 2 sin(vx)dx.
Φ′X (v) = −
(79)
2π
R
Since the interval (a, b) was arbitrary (79) holds for any v ∈ R. We apply integration by
parts and readily deduce that
Z
x2
1
√ e− 2 v cos(vx)dx = −vΦX (v), v ∈ R.
Φ′X (v) =
2π
R
2

This shows that ΦX (v) = e−v /2 for any v ∈ R. Notice that a general σ > 0 does not change
2 2
the argument and hence, if X ∼ N (0, σ 2 ), ΦX (v) = e−(σ v )/2 . Then, if X ∼ N (µ, σ 2 ),
2
Y = X − µ ∼ N (0, σ ) (cf. Exercise 10.4) and we obtain
ΦX (v) = ΦY +µ (v) = E[eiv(Y +µ) ] = eivµ E[eivY ] = eiµv−

165

σ2 v2
2

.

In order to verify the uniqueness theorem of the characteristic function, we first consider
some helpful results.
Definition C.1. We define
(
d(x, A) =

inf a∈A ∥x − a∥,
1,

if (x, A) ∈ R × P(Rk ) \ ∅,
otherwise,

as the distance from x ∈ R to a set A ∈ P(Rk ).
Proposition C.1. Given A ∈ P(Rk ), x 7→ d(x, A) is continuous.
Proof. Suppose that A = ∅, then, by Definition C.1, |d(x, A) − d(y, A)| ≤ ∥x − y∥. Suppose
that A ̸= ∅ and let x, y ∈ Rk . Given any a ∈ A, we obtain
d(x, A) ≤ ∥x − a∥ ≤ ∥x − y∥ + ∥y − a∥.
Since a ∈ A was arbitrary we take the infimum on the right of the latter inequality and
deduce that d(x, A) ≤ ∥x − y∥ + d(y, A). That is, d(x, A) − d(y, A) ≤ ∥x − y∥. Similarly,
givan a ∈ A,
d(y, A) ≤ ∥y − a∥ ≤ ∥y − x∥ + ∥x − a∥,
and hence d(y, A) ≤ ∥y − x∥ + d(x, A), i.e., d(y, A) − d(x, A) ≤ ∥y − x∥. In conclusion, for
any x, y ∈ Rk ,
|d(x, A) − d(y, A)| ≤ ∥x − y∥,

A ∈ P(Rk ).

Therefore, by Definition A.2, for any A ∈ P(Rk ), x 7→ d(x, A) is continuous.
Proposition C.2. Let U ⊂ Rk be an open set. Then, there exists a sequence of continuous
functions gn : Rk → R s.t. for any x ∈ Rk , 0 ≤ gn (x) ≤ 1 and gn (x) ↑ 1U (x).
Proof. Let U ⊂ Rk , open. Set An = {y ∈ Rk : d(y, U c ) ≥ 1/n}, n ∈ N. Then, for any
n ∈ N, U c ⊂ Acn and hence An ⊂ U . Further, An ⊂ An+1 and ∪n∈N An = U (notice that
∩n∈N Acn = U c ). Define
gn (x) =

d(x, U c )
,
d(x, U c ) + d(x, An )

x ∈ Rk .

Then, for any x ∈ Rk , 0 ≤ gn (x) ≤ 1 and gn (x) ≤ gn+1 (x). It remains to show that for any
x ∈ Rk , limn→∞ gn (x) = 1U (x). Let x ∈ U , then, since ∪n∈N An = U , there exists N ∈ N,
s.t. x ∈ An for any n ≥ N , i.e., gn (x) = 1 for any n ≥ N . If x ∈
/ U , then, x ∈ Acn for any
n→∞
n ∈ N. That is d(x, U c ) < 1/n for any n ∈ N and hence, gn (x) −−−−→ 0.
Proof of Proposition 10.12. Let k = 1. Define
hσ (x) = √

1

x2

2πσ 2

e− 2σ2 ,

x ∈ R,

i.e., hσ is the probability density function of a N (0, σ 2 ) distribution. Let µ be a probability
measure on B(R). Define
Z
fσ (x) =
hσ (x − y)µ(dy)
R

µσ (dx) = fσ (x)dx.

166

By the Fubini-Tonnelli theorem (cf. Proposition 9.11), the map x 7→ fσ (x) is B(R) measurable. Clearly, fσ is nonnegative and we recall that µσ is the measure on B(R) defined by
(cf. Proposition 9.2)
Z
µσ (A) =
fσ (x)dx.
A

By the Fubini-Tonnelli theorem again,


Z Z
Z Z
Z
µσ (R) =
hσ (x − y)µ(dy) dx =
hσ (x − y)dx µ(dy) =
µ(dy) = 1,
R

R

R

R

R

that is for any σ > 0, µσ is a probability measure on B(R). Define
Cb (R) = {g : g : R → R g continuous and bounded}.
Introduce the following conditions:
(1) If ν is another probability measure on B(R) s.t. νb(v) = µ
b(v) for any v ∈ R, then
νσ = µσ ;
R
R
(2) for any g ∈ Cb (R), limσ→0 R g(x)µσ (dx) = R g(x)µ(dx).
Suppose that (1) and (2) are satisfied and let P and P ′ as in the statement of the proposition.
Condition (1) shows that for any σ > 0, Pσ = Pσ′ . Then, upon (2), for any g ∈ Cb (R),
Z
Z
g(x)P (dx) =
g(x)P ′ (dx).
R

R

By Proposition C.2, for any open set U ⊂ R, there exists a sequence of continuous, bounded
and nonnegative functions gn : R → R s.t. for any x ∈ R, gn (x) ↑ 1U (x). We conclude with Proposition 8.2, that P (U ) = P ′ (U ) for any U ⊂ R, open. Since B(R) =
σ({U : U ⊂ R open}) we apply Proposition 6.9 and conclude that P = P ′ . Hence it remains
to verify (1) and (2). In order to show (1), we use Proposition 10.11 and obtain that for any
x ∈ R,
Z
√
x2
− 2σ
2
=
eixt h1/σ (t)dt.
2πσhσ (x) = e
R

Further, we notice that |ei(x−y)t h1/σ (t)| = |h1/σ (t)| for any x, y, t ∈ R and therefore,
Z
Z
Z
i(x−y)t
|e
h1/σ (t)|λ ⊗ µ(d(t, y)) =
|h1/σ (t)|λ ⊗ µ(d(t, y)) = µ(R) |h1/σ (t)|dt,
R2

R2

R

where we used Fubini-Tonnelli for the last equality. Therefore, since t 7→ h1/σ (t) is integrable
with respect to the Lebesgue measure, (t, y) 7→ ei(x−y)t h1/σ (t) is integrable with respect to
the product measure λ ⊗ µ on B(R2 ). Hence, upon Fubini-Lebesgue (cf. Proposition 9.12),
the following is justified
Z
fσ (x) =
hσ (x − y)µ(dy)
R

Z Z
1
=√
ei(x−y)t h1/σ (t)dt µ(dy)
2πσ R
R
Z

Z
1
=√
eixt h1/σ (t)
e−ity µ(dy) dt
2πσ R
R
Z
1
=√
eixt h1/σ (t)b
µ(−t)dt.
2πσ R
167

This shows (1). We verify (2). Using again Fubini-Lebesgue, we write for any g ∈ Cb (R),
Z

Z
Z
Z
Z
g(x)µσ (dx) =
g(x)fσ (x)dx =
g(x)
hσ (x − y)µ(dy) dx = (hσ ∗ g)(y)µ(dy),
R

R

R

R

R

where we recall Example 8.5. If we use the substitution u = (x − y)/σ, we deduce that for
any y ∈ R,
Z
Z
u2
1
√ e− 2 g(σu + y)du.
hσ ∗ g(y) =
hσ (x − y)g(x)dx =
2π
R
R
√
R
u2
Since g is bounded and (1/( 2π)) R e− 2 du = 1, we obtain upon Lebesgue’s dominated
convergence theorem (cf. Proposition 8.10) that for any y ∈ R,
lim hσ ∗ g(y) = g(y).

σ→0

Keep in mind that g is assumed to be continuous. Then, we also notice that for any y ∈ R
(cf. Exercise 8.6),
Z
Z
hσ ∗ g(y) ≤
hσ (x − y)g(x) dx ≤ C
hσ (x − y)dx = C,
R

R

where C ∈ R s.t. for any x ∈ R, |g(x)| ≤ C (upon the assumption that g is bounded). Hence
if we apply Lebesgue’s dominated convergence again, we get that
Z
Z
lim
g(x)µσ (dx) =
g(x)µ(dx).
σ→0

R

R

This completes the proof for the case where k = 1. If k ∈ N we replace hσ (x), x ∈ R, with
the function
hkσ (x) =

k
Y

hσ (xi ),

x = (x1 , . . . , xk ) ∈ Rk ,

i=1

and condition (2) with
Qk
(2′ ) for any function g : Rk → R whichRis s.t. g(x1 , . . . , xkR) = i=1 gi (xi ), with gi ∈ Cb (R),
i = 1, . . . , k, we have that limσ→0 Rk g(x)µσ (dx) = Rk g(x)µ(dx).
Notice that for any x ∈ Rk ,
(2π)k/2 σ k hkσ (x) =

Z

eix

Rk

t

w

hk1/σ (w)dw.

Hence, we proceed as before and conclude that for any g as in (2′ ),
Z
Z
g(x)P (dx) =
g(x)P ′ (dx).
Rk

(80)

Rk

Let (a1 , b1 ) ⊂ R be an open interval of R. Then, by Proposition C.2, there exists a sequence
of functions (g1n )n∈N which is s.t. g1n ∈ Cb (R) for any n ∈ N and gin (x) ↑ 1(a1 ,b1 ) (x), x ∈ R.
Qk
Therefore, by (80), if we define gn (x) = g1n (x1 ) i=2 gi (xi ), gi ∈ Cb (R) for any i = 2, . . . , k,
we obtain with Proposition 8.2,
Z
Rk

1(a1 ,b1 ) (x1 )

k
Y

Z
gi (xi )P (dx) =
Rk

i=2

168

1(a1 ,b1 ) (x1 )

k
Y
i=2

gi (xi )P ′ (dx).

Upon k iterations of the previous argument, we deduce that P (A) = P ′ (A) for any A ∈ G,
where
G = {A ⊂ Rk : A =

k
Y

(ai , bi ), ai , bi ∈ R, i = 1, . . . , k} ∪ {∅}.

i=1

We know that B(Rk ) = σ(Rk ), where
k
Y

Rk = A : A =
(ai , bi ], ai , bi ∈ R, i = 1, . . . , k ∪ {∅}.
i=1

Since for any Rk ∋ A =

Qk

i=1

(ai , bi ],
k
\ Y

A=

ai , bi + 1/n




,

i=1

n∈N

we readily see that B(Rk ) = σ(G). Hence, we apply Proposition 6.9 and deduce that
P (A) = P ′ (A) for any A ∈ B(Rk ).

C.4

Results on independence

Proof of Proposition 11.2. By Remark 11.4, the map X(ω) = (X1 (ω), . . . , Xn (ω)) is
F/(B(Rk1 ) ⊗ · · · ⊗ B(Rkn ))
measurable. Suppose first that for any i = 1, . . . , n, fi is nonnegative and B(Rki ) measurable. Upon Proposition B.7, the map f : Rk1 × · · · × Rkn → R defined by
f (x1 , . . . , xn ) =

n
Y

fi (xi ),

(x1 , . . . , xn ) ∈ Rk1 × · · · × Rkn ,

(81)

i=1

is B(Rk1 ) ⊗ · · · ⊗ B(Rkn ) measurable. We thus apply (35) of Remark 11.4 and deduce that

Y
Z
n
fi (Xi ) = E[f (X)] =
E

f (x)PX (dx).

Rk1 ×···×Rkn

i=1

(82)

By Proposition 11.1, PX = PX1 ⊗ · · · ⊗ PX1 and hence we use Fubini-Tonnelli (cf. Proposition 9.11) and obtain
Y
 Z
n
E
fi (Xi ) =

Rk1 ×···×Rkn

i=1

=

n Z
Y
i=1

Rki

f (x)PX1 ⊗ · · · ⊗ PX1 (dx)

 Y
n


f (xi )PXi (dxi ) =
E fi (Xi ) .
i=1

For the remaining case, assume that E[|fi (Xi )|] < ∞ for any i = 1, . . . , n. With f as in (81),
we obatin
n
Y


E[|f (X)|] =
E |fi (Xi )| < ∞,
i=1

by the previous case. Thus, upon Remark 11.4, (82) remains valid and the proposition is
proven.
169

Proof of Proposition 11.5. By Definition 10.14, the Fourier transform of PX1 ⊗ · · · ⊗ PXn is
given by
Y
n

Z
PX1 ⊗\
· · · ⊗ PXn (v) =
Rn

eivi xi


PX1 ⊗ · · · ⊗ PXn (d(x1 , . . . , xn )).

i=1

If we write eivi xi = cos(vi xi ) + i sin(vi xi ), i = 1, . . . , n, we recall Definition 10.13, apply
Fubini-Lebesgue (cf. Proposition 9.14) and obtain
PX1

⊗\
· · · ⊗ PXn (v) =

n Z
Y
i=1

e

ivi xi

 Y
n
PXi (dxi ) =
PbXi (vi ).

R

i=1

This concludes the proof of the proposition since by Proposition 11.1, X1 , . . . , Xn are independent if and only if the law of X is the product measure on B(Rn ).
Proof of Proposition 11.8. By item (i) of Proposition 11.7, the law of Z is given by
−1

PX1 ∗ · · · ∗ PXn = PX1 ⊗ · · · ⊗ PXn s

,

s(x1 , . . . , xn ) =

n
X

xi .

i=1

Hence, the characteristic function of Z is given by the Fourier transform of the latter measure,
i.e., for any v ∈ Rk ,
ΦZ (v) = PX1 ∗\
· · · ∗ PXn (v)
Z
t
=
eiv z PX1 ∗ · · · ∗ PXn (dz)
k
ZR
t
=
eiv z PX1 ⊗ · · · ⊗ PXn s−1 (dz)
k
ZR
t
=
eiv (x1 +···xn )) PX1 ⊗ · · · ⊗ PXn (d(x1 , . . . , xn ))
=

Rk ×···×Rk
n
YZ

eiv

i=1

C.5

t

xi

 Y
n
ΦXi (v).
PXi (dxi ) =

Rk

i=1

Grouping of independent random vectors

Proposition C.3. Let f : Ω → Ω∗ . Suppose that G ⊂ P(Ω∗ ) is a family of subsets of Ω∗ .
Then,
σ(f ) = {f −1 (A) : A ∈ σ(G)} = σ({f −1 (G) : G ∈ G})
Proof. By Exercise 4.9, we know that σ(f ) is a σ-field on Ω. Thus, since G ⊂ σ(G), it follows
readily that σ({f −1 (G) : G ∈ G}) ⊂ σ(f ). With regard to the other inclusion, we note that
for any G ∈ G, f −1 (G) ∈ σ({f −1 (G) : G ∈ G}). Then, by Proposition 7.1, for any A ∈ σ(G),
f −1 (A) ∈ σ({f −1 (G) : G ∈ G}). That is σ(f ) ⊂ σ({f −1 (G) : G ∈ G}).
Definition C.2. Let (Ω, F, P) be a probability space and G1 , . . . , Gn be n families of subsets
of Ω where for any i = 1, . . . , n, Gi ⊂ F, i.e., G1 , . . . , Gn are subsets of measurable sets of
Ω. The families G1 , . . . , Gn are said to be independent if
P(Gk1 ∩ · · · ∩ Gkj ) = P(Gk1 ) · . . . · P(Gkj ),
for any choice Gk1 ∈ Gk1 , . . . , Gkj ∈ Gkj , 1 ≤ k1 < k2 < · · · < kj ≤ n, 2 ≤ j ≤ n.
170

Proposition C.4. Let (Ω, F, P) be a probability space and G1 , . . . , Gn be n families of subsets
of Ω where for any i = 1, . . . , n, Gi ⊂ F. Suppose that G1 , . . . , Gn are independent and for
any i = 1, . . . , n, Gi is a π-system (cf. Definition B.1). Then, the σ-fields σ(G1 ), . . . , σ(Gn )
are independent.
Proof. Define Bi = Gi ∪ {Ω}, i = 1, . . . , n. That is, we adjoin the set Ω to each Gi . Then,
for any i = 1, . . . , n, Bi is a π-system and B1 , . . . , Bn remain independent. We notice that
σ(Bi ) = σ(Gi ) for any i = 1, . . . , n. Fix sets B2 ∈ B2 , . . . , Bn ∈ Bn and define the class
LB2 ,...,Bn = {B ∈ F : P(B ∩ B2 ∩ · · · ∩ Bn ) = P(B) · P(B2 ) · . . . · P(Bn )}.
Then, LB2 ,...,Bn is a λ-system (cf. Definition B.2). Clearly, by Definition C.2, Ω ∈ LB2 ,...,Bn .
Further, if A ∈ LB2 ,...,Bn , we write B2 ∩· · ·∩Bn = C and obtain with Ω∩C \(A∩C) = Ac ∩C
that Ac ∈ LB2 ,...,Bn . Also, if {Ai : i ∈ N} ⊂ LB2 ,...,Bn is disjoint, then with C = B2 ∩· · ·∩Bn
X
P((∪i∈N Ai ) ∩ C) =
P(Ai ∩ C) = P(∪i∈N Ai )P(C).
i∈N

Clearly, B1 ⊂ LB2 ,...,Bn . Therefore, since LB2 ,...,Bn is a λ-system that contains the π-system
B1 , it follows by Dynkin’s π − λ theorem (cf. Proposition B.4) that σ(B1 ) = σ(G1 ) ⊂
LB2 ,...,Bn . This shows that the families σ(B1 ), B2 , . . . , Bn are independent. Then, we recycle
the previous argument for the π-systems σ(B1 ), B2 , . . . , Bn and deduce that
σ(B1 ), σ(B2 ), B3 , . . . , Bn
are independent. Finally, upon a finite number of iterations, the σ-fields σ(G1 ), . . . , σ(Gn )
are independent.
Proof of Proposition 11.6. We define the π-systems
G1 = {X1−1 (B1 ) ∩ · · · ∩ Xn−1
(Bn1 ) : B1 ∈ B(Rk1 ), . . . , Bn1 ∈ B(Rkn1 )}
1
|
{z
}
={Y1−1 (B1 ×···×Bn1 ) : B1 ∈B(Rk1 ),...,Bn1 ∈B(Rkn1 )}

..
.
Gp = {Xn−1
(Bnp−1 +1 ) ∩ · · · ∩ Xn−1 (Bn ) : Bnp−1 +1 ∈ B(Rknp−1 +1 ), . . . , Bn ∈ B(Rkn )} .
p−1 +1
{z
}
|
kn
p−1 +1 ),...,B

={Yp−1 (Bnp−1 +1 ×···×Bn ) : Bnp−1 +1 ∈B(R

k
n ∈B(R n )}

We notice that since by assumption X1 , . . . , Xn are independent, G1 , . . . , Gp are independent
according to Definition C.2 (cf. Remark 11.2). By Proposition C.4, σ(G1 ), . . . , σ(Gp ) are
independent as well. Then, we apply Proposition C.3 and conclude that σ(Y1 ), . . . , σ(Yp )
are independent (cf. Definition 11.3). In order to show the remaining part of the proposition,
if fi : Rkni +1 ×· · ·×Rkni+1 → R, i = 0, . . . , p−1, are B(Rkni +1 )⊗· · ·⊗B(Rkni+1 ) measurable,
then for any B1 , . . . , Bp ∈ B(R), since Y1 , . . . , Yp are independent,
P(T1 ∈ B1 , . . . , Tp ∈ Bp ) = P(Y1 ∈ f1−1 (B1 ), . . . , Yp ∈ fp−1 (Bp ))
= P(Y1 ∈ f1−1 (B1 )) · . . . · P(Yp ∈ fp−1 (Bp ))
= P(T1 ∈ B1 ) · . . . · P(Tp ∈ Bp ).
Hence, the random variables T1 , . . . , Tp are independent.

C.6

On the law of a Gauss vector

Proposition C.5. Suppose that Σ ∈ Rk×k is symmetric and positive semidefinite. Then,
there exists a symmetric and positive semidefinite matrix B s.t. BB = Σ.
171

Proof. Since Σ is symmetric there exists an orthogonal matrix Q (Qt Q = I) s.t. Σ = QDQt ,
where D is diagonal s.t. Di,i = λi , where λi is an eigenvalue of Σ, i = 1, . . . , k. Since Σ is
positive semidefinite, we define B = QD1/2 Qt , with

√
λ1 √0
...
0
 0
λ2 . . .
0 


D1/2 =  .
.
..  .
.
..
..

 ..
√.
λk
0
0
...
Then, we obtain BB = QD1/2 Qt QD1/2 Qt = Σ.
Remark C.3.
√ The matrix B in Proposition C.5 is referred to as a square root of Σ. It is
denoted with Σ.
√
√
Remark C.4. If Σ ∈ Rk×k is symmetric
semidefinite,
det Σ = det Σ.
√
√
√then,
√ √ and positive
To see it, notice that det Σ = det Σ Σ = det Σ det Σ = (det Σ)2 .
k×k
Proposition C.6. Let Σ ∈ R
be symmetric and positive semidefinite and µ ∈ Rk . Then,
√
the random vector X = µ + ΣN , with N ∼ N (0, I), is s.t. X ∼ N (µ, Σ).

Proof. Let v ∈ Rk . We apply Proposition 11.9 and deduce that
ΦX (v) = E[eiv

t

X

= E[eiv

t

µ+iv t

iv t µ

=e

= eiv

t

= eiv

t

µ
µ

]

E[e

iv

√

ΣN

√
t

E[ei((v
ΦN ((v

t

ΣN

√

]
]

Σ)t )t N

√
t

]

Σ)t ) = eiv

t

µ −

e

vt

√

ΣI(v t
2

√

Σ)t

= eiv

t

µ −v

e

t √Σ√Σt v
2

= eiv

t

µ −v

e

t Σv
2

.

Hence, by Proposition 10.12, X ∼ N (µ, Σ).
Remark C.5. Notice that if N1 , . . . , Nk are k independent random variables s.t. for any
i = 1, . . . , k, Ni ∼ N (0, 1), then N = (N1 , . . . , Nk ) is a Gauss vector (cf. item (iii) of
Remark 11.11). In particular, N ∼ N (0, I). Thus, the latter proposition shows how to
construct (given appropriate µ and Σ) a Gauss vector X ∼ N (µ, Σ), upon a collection of
independent standard Gaussian random variables.
Proof of Proposition
11.11. In order to simplify the notation we set Σ = Σ(X). Define
√
e = µ + ΣN , with N ∼ N (0, I). By Proposition C.6, X and X
e have the same law.
X
√
k
e
Thus, we may omit the distinction and let X = X. Define T (w) = µ + Σw,
√w ∈ R .
k
k
By Example A.6, T : R → R is differentiable
with Jacobian
√
√matrix JT (w0 ) = Σ for any
w0 ∈ Rk (cf. Proposition A.24). Since Σ is invertible, det Σ ̸= 0. Further, T (Rk ) = Rk
since for any y ∈ Rk , there exists a unique w0 ∈ Rk which solves T (w0 ) = y. In particular,
T : Rk → Rk is bijective. Let f : Rk → R be any nonnegative and B(Rk ) measurable
function. We have with Proposition 11.1,
E[f (X)] = E[f (T (N )]
Z
=
f (T (w))PN1 ⊗ · · · ⊗ PN1 (dw)
Rk
Z
wt w
1
=p
f (T (w)) e− 2 dw
(2π)k Rk
Z
√
wt w
1
1
√
=p
f (T (w)) det Σ e− 2 dw.
(2π)k det Σ Rk
172

Define
g(y) = f (y) e−

(y−µ)t Σ−1 (y−µ)
2

,

y ∈ Rk .

√ √
t
Then, for any w ∈ Rk , g(T (w)) = f (T (w)) e−(w w)/2 . Notice that Σ−1 = ( Σ Σ)−1 =
√ −1 √ −1
Σ
Σ . Therefore, by Proposition 9.9, we obtain:
Z
1
1
√
g(y)dy
E[f (X)] = p
(2π)k det Σ Rk
Z
(y−µ)t Σ−1 (y−µ)
1
1
2
√
=p
dy.
f (y) e−
(2π)k det Σ Rk
Finally, we rely on Remark C.4 and the proposition is proven.

C.7

On Kolmogorov’s Zero-One law and the law of large numbers

We remain in the setting of Section 11.
Definition C.3. Let (Xn )n∈N be a sequence of random variables. The σ-field generated by
the latter sequence is defined as
σ((Xn )n∈N ) = σ({(X1 , . . . , Xk )−1 (B) : B ∈ B(Rk ), k ∈ N)}).
Proposition C.7. Let (Xn )n∈N be a sequence of random variables. We have that
σ((Xn )n∈N ) = σ

[
∞


σ(Yk ) ,

Yk = (X1 , . . . , Xk ),

k ∈ N.

k=1

Proof. Let A ∈ {(X1 , . . . , Xk )−1 (B) : B ∈ B(Rk ), k ∈ N)}. Then, there exists k ∈ N and
B ∈ B(Rk ) s.t. A = Yk−1 (B), Yk = (X1 , . . . , Xk ). By definition of σ(Yk ), it follows that
∞
A ∈ σ(Yk ). In particular, A ∈ σ(∪∞
k=1 σ(Yk )). This shows that σ((Xn )n∈N ) ⊂ σ(∪k=1 σ(Yk )).
∞
Let A ∈ ∪k=1 σ(Yk ), then there exists k ∈ N s.t. A ∈ σ(Yk ). Thus, there exists B ∈
B(Rk ) s.t. A = Yk−1 (B), Yk = (X1 , . . . , Xk ). This shows that A ∈ σ((Xn )n∈N ). Therefore,
σ(∪∞
k=1 σ(Yk )) ⊂ σ((Xn )n∈N ).
Proposition C.8. Let (Xn )n∈N be a sequence of independent random variables (cf. Definition 11.4). Let Yk = (X1 , . . . , Xk ), k ∈ N. Then, for any k ∈ N, σ(Yk ) is independent of
σ((Xk+j )j∈N ).
Proof. Since (Xn )n∈N is an independent sequence of random variables, it follows from Proposition 11.6 that for any j ∈ N, σ(Yk ) is independent of σ((Xk+1 , . . . , Xk+j )). In particular,
σ(Yk ) is independent of ∪∞
j=1 σ((Xk+1 , . . . , Xk+j )). Since the latter union is a π-system, we
apply Proposition C.4 and get that σ(Yk ) is independent of σ(∪∞
j=1 σ((Xk+1 , . . . , Xk+j ))).
Then, we apply Proposition C.7 and the proposition is proven.
Kolmogorov’s Zero-One law (for sequences of random variables) reads as follows:
Proposition C.9. Let (Xn )n∈N be a sequence of independent random variables. Define the
σ-field,
F∞ =

∞
\

σ((Xk+j )j∈N ).

k=0

Then, for any A ∈ F∞ , P(A) is either zero or one.

173

Proof. By Proposition C.8, for any k ∈ N, σ((Xk+j )j∈N ) is independent of σ(Yk ). In particular, since F∞ ⊂ σ((Xk+j )j∈N ) for any k ∈ N, we deduce that σ(Yk ) is independent of F∞
for any k ∈ N. Thus, we apply Propositions C.4 and C.7 and deduce that F∞ is independent
of σ((Xn )n∈N ). Let A ∈ F∞ , then, A ∈ σ((Xn )n∈N ) and we get that
P(A) = P(A ∩ A) = P(A)2 ,
since F∞ is independent of σ((Xn )n∈N ). This shows that P(A) is either zero or one.
Pn
Proof of Proposition 12.9. Let S0 (ω) = 0 for any ω ∈ Ω and set Sn = i=1 Xi , n ∈ N.
Consider a ∈ R s.t. a > E[X1 ]. Define Ma = supn∈Z+ (Sn − na), where Z+ = N ∪ {0}.
To simplify the notation, we write M = Ma . By Proposition 7.9, M is a random variable,
i.e., M is F measurable. Notice that M = max{supn∈N (Sn − na), 0}. In particular, M is
nonnegative. We aim to show that
(83)

P(M < ∞) = 1.
Let k ∈ N. We observe that (cf. Propositions 8.5 and 8.6),
{M < ∞} = { sup (Sn − na) < ∞} = {sup(Sn − Sk − na) < ∞}.
n∈Z+

n≥k

Then, the event {supn≥k (Sn − Sk − na) < ∞} is an element of σ((Xk+j )j∈N ) (cf. Proposition 7.13). Since k ∈ N was arbitrary, we conclude that {M < ∞} ∈ F∞ , where F∞ is as
in Proposition C.9. That is, P(M < ∞) is either zero or one. To show (83), it is therefore
sufficient to show that P(M < ∞) > 0. We show that,
(84)

P(M = ∞) < 1,
from which P(M < ∞) > 0 follows. Given any m ∈ N, we define the random variables:
Mm = sup (Sn − na),
0≤n≤m
′
Mm

= sup (Sn+1 − S1 − na).
0≤n≤m

We notice that for any n ∈ N, n ≥ 2, since (Xi )i∈N is an i.i.d. sequence of random variables, the law of (X1 , . . . , Xn ) is the same as the law of (X2 , . . . , Xn+1 ) (recall also Proposi′
tion 11.1). Thus, upon Proposition 10.3, for any m ∈ N, Mm and Mm
have the same law. We
′
′
further observe that for any m ∈ N and ω ∈ Ω, Mm (ω) ≤ Mm+1 (ω) and Mm
(ω) ≤ Mm+1
(ω).
′
′
Clearly, M = limm→∞ Mm and we define M = limm→∞ Mm . Given any x ∈ R,

 \
∞
′
′
{Mm
≤ x} = lim P(Mm
≤ x) = lim P(Mm ≤ x) = P(M ≤ x).
P(M ′ ≤ x) = P
m=1

m→∞

m→∞

Thus, M and M ′ have the same law. In addition, we verify that
′
′
Mm+1 = Mm
− min{a − X1 , Mm
}.
′
Notice that if Mm
(ω) ≤ a − X1 (ω), it follows that Mm+1 (ω) = 0 (recall that Mm+1 is
nonnegative). Given the previous display, we deduce that
′
′
E[min{a − X1 , Mm
}] = E[Mm
] − E[Mm+1 ] = E[Mm ] − E[Mm+1 ] ≤ 0.
′
Then, since for any ω ∈ Ω, min{a − X1 , Mm
}(ω) ≤ (a − X1 )(ω) ≤ |a − X1 |(ω), and
E[|a−X1 |] < ∞, we apply Lebesgue’s dominated convergence theorem (cf. Proposition 8.10)
and deduce that
′
E[min{a − X1 , M ′ }] = lim E[min{a − X1 , Mm
}] ≤ 0.
m→∞

174

(85)

Suppose now by contradiction that P(M = ∞) = 1. Then, since M ′ and M have the same
law, we must have that P(M ′ = ∞) = 1. Thus, with P probability one, min{a − X1 , M ′ } =
a − X1 . Thus, by (85), E[a − X1 ] ≤ 0. This gives a contradiction with the assumption that
a > E[X1 ]. Hence, we have verified (84) and thus (83) follows. To complete the proof, let
an = E[X1 ] + 1/n, n ∈ N. Then, for any n ∈ N, Sn ≤ nan + Man and by (83) P a.s.,


Sn
nan + Man
lim sup
≤ lim sup
= E[X1 ].
n
n
n→∞
n→∞
ei = −Xi , i ∈ N, and Sen =
Define X
conclude that with P probability one,
lim sup
n→∞

Therefore, lim inf n→∞

Pn

i=1

ei . We repeat the previous arguments and
X

Sen
e1 ] = −E[X1 ].
≤ E[X
n

≥ E[X1 ] P a.s. In conclusion,


Sn
Sn
= E[X1 ] = lim sup
= 1,
P lim inf
n→∞ n
n
n→∞

Sn
n

and the proposition is proven.

References
[1] Patrick Billingsley, Probability and measure, 4 ed., Wiley Series in Probability and Statistics, John Wiley & Sons, Inc., Hoboken, NJ, 2012.
[2] Jean-François Le Gall, Measure theory, probability, and stochastic processes, Graduate
Texts in Mathematics, vol. 295, Springer, Cham, 2022.

175

